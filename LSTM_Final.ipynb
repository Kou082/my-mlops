{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "sxcDxWDc6SO8"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import LSTM, Dense"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "ZaYwQ4SR7vXs"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "df = pd.read_excel('LNG (High).xlsx')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kT5UgcbL8vFF",
        "outputId": "799c2eb2-5d8c-48b9-c4b5-00a196ec19c3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "        Date  Price\n",
            "0 2024-06-01  2.799\n",
            "1 2024-05-01  2.924\n",
            "2 2024-04-01  2.092\n",
            "3 2024-03-01  2.009\n",
            "4 2024-02-01  2.177\n"
          ]
        }
      ],
      "source": [
        "# Convert the 'Date' column to datetime format\n",
        "df['Date'] = pd.to_datetime(df['Date'], format='%b-%y')\n",
        "\n",
        "# Explore the data (e.g., check for missing values, summary statistics)\n",
        "print(df.head())  # Display the first few rows"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eC6ZznNytVdH",
        "outputId": "9f7d6e98-6596-4cc2-976e-1f52b777b540"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "          Date  Price\n",
            "148 2012-02-01  2.733\n",
            "147 2012-03-01  2.597\n",
            "146 2012-04-01  2.320\n",
            "145 2012-05-01  2.759\n",
            "144 2012-06-01  2.946\n",
            "..         ...    ...\n",
            "4   2024-02-01  2.177\n",
            "3   2024-03-01  2.009\n",
            "2   2024-04-01  2.092\n",
            "1   2024-05-01  2.924\n",
            "0   2024-06-01  2.799\n",
            "\n",
            "[149 rows x 2 columns]\n"
          ]
        }
      ],
      "source": [
        "df = df.sort_values(by=\"Date\", ascending=True)\n",
        "\n",
        "print(df)\n",
        "#print items"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "M3hLWely82y9"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import LSTM, Dense"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-vVlOrsVKvq7",
        "outputId": "c7e7f64d-9a29-40fd-8610-e8ce0b1b1a86"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/50\n",
            "4/4 [==============================] - 2s 94ms/step - loss: 13.2808 - val_loss: 34.7768\n",
            "Epoch 2/50\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 9.5102 - val_loss: 22.1230\n",
            "Epoch 3/50\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 6.5911 - val_loss: 13.9763\n",
            "Epoch 4/50\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 4.8236 - val_loss: 9.7302\n",
            "Epoch 5/50\n",
            "4/4 [==============================] - 0s 13ms/step - loss: 4.0081 - val_loss: 8.6152\n",
            "Epoch 6/50\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 3.8394 - val_loss: 9.2265\n",
            "Epoch 7/50\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 3.9075 - val_loss: 9.6988\n",
            "Epoch 8/50\n",
            "4/4 [==============================] - 0s 13ms/step - loss: 3.8233 - val_loss: 9.3199\n",
            "Epoch 9/50\n",
            "4/4 [==============================] - 0s 13ms/step - loss: 3.5736 - val_loss: 8.8329\n",
            "Epoch 10/50\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 3.3369 - val_loss: 8.5881\n",
            "Epoch 11/50\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 3.1125 - val_loss: 8.6277\n",
            "Epoch 12/50\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 2.9108 - val_loss: 8.7405\n",
            "Epoch 13/50\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 2.7414 - val_loss: 8.8036\n",
            "Epoch 14/50\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 2.5728 - val_loss: 8.8432\n",
            "Epoch 15/50\n",
            "4/4 [==============================] - 0s 13ms/step - loss: 2.4298 - val_loss: 8.8559\n",
            "Epoch 16/50\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 2.3357 - val_loss: 9.0480\n",
            "Epoch 17/50\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 2.2047 - val_loss: 9.4518\n",
            "Epoch 18/50\n",
            "4/4 [==============================] - 0s 14ms/step - loss: 2.1007 - val_loss: 9.8487\n",
            "Epoch 19/50\n",
            "4/4 [==============================] - 0s 13ms/step - loss: 2.0215 - val_loss: 10.0856\n",
            "Epoch 20/50\n",
            "4/4 [==============================] - 0s 13ms/step - loss: 1.9577 - val_loss: 10.0718\n",
            "Epoch 21/50\n",
            "4/4 [==============================] - 0s 13ms/step - loss: 1.8904 - val_loss: 10.1298\n",
            "Epoch 22/50\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 1.8247 - val_loss: 10.2700\n",
            "Epoch 23/50\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 1.7697 - val_loss: 10.4041\n",
            "Epoch 24/50\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 1.7137 - val_loss: 10.4453\n",
            "Epoch 25/50\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 1.6649 - val_loss: 10.3760\n",
            "Epoch 26/50\n",
            "4/4 [==============================] - 0s 13ms/step - loss: 1.6186 - val_loss: 10.2887\n",
            "Epoch 27/50\n",
            "4/4 [==============================] - 0s 13ms/step - loss: 1.5709 - val_loss: 10.2029\n",
            "Epoch 28/50\n",
            "4/4 [==============================] - 0s 14ms/step - loss: 1.5234 - val_loss: 10.1615\n",
            "Epoch 29/50\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 1.4845 - val_loss: 10.1823\n",
            "Epoch 30/50\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 1.4422 - val_loss: 10.0195\n",
            "Epoch 31/50\n",
            "4/4 [==============================] - 0s 13ms/step - loss: 1.4050 - val_loss: 9.9181\n",
            "Epoch 32/50\n",
            "4/4 [==============================] - 0s 13ms/step - loss: 1.3609 - val_loss: 9.8545\n",
            "Epoch 33/50\n",
            "4/4 [==============================] - 0s 13ms/step - loss: 1.3287 - val_loss: 9.8172\n",
            "Epoch 34/50\n",
            "4/4 [==============================] - 0s 13ms/step - loss: 1.2940 - val_loss: 9.8321\n",
            "Epoch 35/50\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 1.2589 - val_loss: 9.8303\n",
            "Epoch 36/50\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 1.2265 - val_loss: 9.7319\n",
            "Epoch 37/50\n",
            "4/4 [==============================] - 0s 15ms/step - loss: 1.1969 - val_loss: 9.6323\n",
            "Epoch 38/50\n",
            "4/4 [==============================] - 0s 23ms/step - loss: 1.1700 - val_loss: 9.6124\n",
            "Epoch 39/50\n",
            "4/4 [==============================] - 0s 19ms/step - loss: 1.1425 - val_loss: 9.5129\n",
            "Epoch 40/50\n",
            "4/4 [==============================] - 0s 24ms/step - loss: 1.1178 - val_loss: 9.5084\n",
            "Epoch 41/50\n",
            "4/4 [==============================] - 0s 18ms/step - loss: 1.0905 - val_loss: 9.5376\n",
            "Epoch 42/50\n",
            "4/4 [==============================] - 0s 19ms/step - loss: 1.0670 - val_loss: 9.5737\n",
            "Epoch 43/50\n",
            "4/4 [==============================] - 0s 20ms/step - loss: 1.0441 - val_loss: 9.5441\n",
            "Epoch 44/50\n",
            "4/4 [==============================] - 0s 22ms/step - loss: 1.0240 - val_loss: 9.4604\n",
            "Epoch 45/50\n",
            "4/4 [==============================] - 0s 19ms/step - loss: 1.0023 - val_loss: 9.4412\n",
            "Epoch 46/50\n",
            "4/4 [==============================] - 0s 23ms/step - loss: 0.9828 - val_loss: 9.4445\n",
            "Epoch 47/50\n",
            "4/4 [==============================] - 0s 17ms/step - loss: 0.9652 - val_loss: 9.4344\n",
            "Epoch 48/50\n",
            "4/4 [==============================] - 0s 22ms/step - loss: 0.9531 - val_loss: 9.4247\n",
            "Epoch 49/50\n",
            "4/4 [==============================] - 0s 18ms/step - loss: 0.9354 - val_loss: 9.4746\n",
            "Epoch 50/50\n",
            "4/4 [==============================] - 0s 18ms/step - loss: 0.9177 - val_loss: 9.4925\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "<keras.src.callbacks.History at 0x7b3996ced5d0>"
            ]
          },
          "execution_count": 9,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Prepare data for training\n",
        "# Reshape data to fit LSTM input requirements (samples, timesteps, features)\n",
        "X = np.arange(len(df)).reshape(-1, 1, 1)\n",
        "y = df['Price'].values\n",
        "\n",
        "# Split data into train and validation sets\n",
        "train_size = int(0.8 * len(df))\n",
        "X_train, y_train = X[:train_size], y[:train_size]\n",
        "X_val, y_val = X[train_size:], y[train_size:]\n",
        "\n",
        "# Define the LSTM model\n",
        "model = Sequential()\n",
        "model.add(LSTM(64, activation='relu', input_shape=(1, 1)))  # Adjust units as needed\n",
        "model.add(Dense(1))  # Output layer\n",
        "\n",
        "# Compile the model\n",
        "model.compile(optimizer='adam', loss='mean_squared_error')\n",
        "\n",
        "# Train the model\n",
        "model.fit(X_train, y_train, epochs=50, validation_data=(X_val, y_val))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iee72gK0857g",
        "outputId": "c09319da-34e8-4187-c0d9-67e642b967c3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/50\n",
            "4/4 [==============================] - 2s 104ms/step - loss: 16.9614 - val_loss: 39.7143\n",
            "Epoch 2/50\n",
            "4/4 [==============================] - 0s 13ms/step - loss: 14.7700 - val_loss: 35.1106\n",
            "Epoch 3/50\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 12.8744 - val_loss: 31.2304\n",
            "Epoch 4/50\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 11.2652 - val_loss: 27.6787\n",
            "Epoch 5/50\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 9.8089 - val_loss: 24.2908\n",
            "Epoch 6/50\n",
            "4/4 [==============================] - 0s 13ms/step - loss: 8.3865 - val_loss: 20.9429\n",
            "Epoch 7/50\n",
            "4/4 [==============================] - 0s 13ms/step - loss: 6.9913 - val_loss: 17.5422\n",
            "Epoch 8/50\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 5.6616 - val_loss: 14.2446\n",
            "Epoch 9/50\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 4.3604 - val_loss: 11.4079\n",
            "Epoch 10/50\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 3.3594 - val_loss: 9.4136\n",
            "Epoch 11/50\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 2.6745 - val_loss: 8.7012\n",
            "Epoch 12/50\n",
            "4/4 [==============================] - 0s 13ms/step - loss: 2.5611 - val_loss: 8.8270\n",
            "Epoch 13/50\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 2.5016 - val_loss: 8.6522\n",
            "Epoch 14/50\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 2.3028 - val_loss: 8.5769\n",
            "Epoch 15/50\n",
            "4/4 [==============================] - 0s 13ms/step - loss: 2.0368 - val_loss: 8.7490\n",
            "Epoch 16/50\n",
            "4/4 [==============================] - 0s 14ms/step - loss: 1.8503 - val_loss: 9.0060\n",
            "Epoch 17/50\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 1.7176 - val_loss: 9.1984\n",
            "Epoch 18/50\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 1.5960 - val_loss: 9.3929\n",
            "Epoch 19/50\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 1.5023 - val_loss: 9.5345\n",
            "Epoch 20/50\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 1.4343 - val_loss: 9.6633\n",
            "Epoch 21/50\n",
            "4/4 [==============================] - 0s 15ms/step - loss: 1.3882 - val_loss: 9.8093\n",
            "Epoch 22/50\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 1.3370 - val_loss: 9.9584\n",
            "Epoch 23/50\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 1.2964 - val_loss: 10.0757\n",
            "Epoch 24/50\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 1.2599 - val_loss: 10.0558\n",
            "Epoch 25/50\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 1.2285 - val_loss: 10.0000\n",
            "Epoch 26/50\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 1.1938 - val_loss: 9.9025\n",
            "Epoch 27/50\n",
            "4/4 [==============================] - 0s 13ms/step - loss: 1.1581 - val_loss: 9.8360\n",
            "Epoch 28/50\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 1.1331 - val_loss: 9.7904\n",
            "Epoch 29/50\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 1.1020 - val_loss: 9.6765\n",
            "Epoch 30/50\n",
            "4/4 [==============================] - 0s 16ms/step - loss: 1.0737 - val_loss: 9.5675\n",
            "Epoch 31/50\n",
            "4/4 [==============================] - 0s 13ms/step - loss: 1.0459 - val_loss: 9.5302\n",
            "Epoch 32/50\n",
            "4/4 [==============================] - 0s 13ms/step - loss: 1.0210 - val_loss: 9.4934\n",
            "Epoch 33/50\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 1.0009 - val_loss: 9.4441\n",
            "Epoch 34/50\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 0.9792 - val_loss: 9.3994\n",
            "Epoch 35/50\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 0.9580 - val_loss: 9.3897\n",
            "Epoch 36/50\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 0.9405 - val_loss: 9.3954\n",
            "Epoch 37/50\n",
            "4/4 [==============================] - 0s 13ms/step - loss: 0.9203 - val_loss: 9.3675\n",
            "Epoch 38/50\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 0.9060 - val_loss: 9.3350\n",
            "Epoch 39/50\n",
            "4/4 [==============================] - 0s 13ms/step - loss: 0.8898 - val_loss: 9.2971\n",
            "Epoch 40/50\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 0.8733 - val_loss: 9.2802\n",
            "Epoch 41/50\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 0.8640 - val_loss: 9.2648\n",
            "Epoch 42/50\n",
            "4/4 [==============================] - 0s 21ms/step - loss: 0.8489 - val_loss: 9.2741\n",
            "Epoch 43/50\n",
            "4/4 [==============================] - 0s 14ms/step - loss: 0.8359 - val_loss: 9.2682\n",
            "Epoch 44/50\n",
            "4/4 [==============================] - 0s 13ms/step - loss: 0.8256 - val_loss: 9.2528\n",
            "Epoch 45/50\n",
            "4/4 [==============================] - 0s 13ms/step - loss: 0.8153 - val_loss: 9.2549\n",
            "Epoch 46/50\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 0.8053 - val_loss: 9.2454\n",
            "Epoch 47/50\n",
            "4/4 [==============================] - 0s 13ms/step - loss: 0.7997 - val_loss: 9.2471\n",
            "Epoch 48/50\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 0.7892 - val_loss: 9.2478\n",
            "Epoch 49/50\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 0.7821 - val_loss: 9.2210\n",
            "Epoch 50/50\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 0.7740 - val_loss: 9.2029\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "<keras.src.callbacks.History at 0x7b39969b8c10>"
            ]
          },
          "execution_count": 10,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Reshape data to fit LSTM input requirements (samples, timesteps, features)\n",
        "X_train = X_train.reshape(X_train.shape[0], 1, 1)\n",
        "X_val = X_val.reshape(X_val.shape[0], 1, 1)\n",
        "\n",
        "# Define the LSTM model\n",
        "model = Sequential()\n",
        "model.add(LSTM(64, activation='relu', input_shape=(1, 1)))  # Adjust units as needed\n",
        "model.add(Dense(1))  # Output layer\n",
        "\n",
        "# Compile the model\n",
        "model.compile(optimizer='adam', loss='mean_squared_error')\n",
        "\n",
        "# Train the model\n",
        "model.fit(X_train, y_train, epochs=50, validation_data=(X_val, y_val))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1_zEsJdECwDI",
        "outputId": "5be417e9-23c6-4fd7-87a1-fa5c1edc892d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "1/1 [==============================] - 0s 288ms/step\n",
            "Predicted prices for the next 12 months:\n",
            "Month 1: 4.804\n",
            "Month 2: 4.836\n",
            "Month 3: 4.869\n",
            "Month 4: 4.901\n",
            "Month 5: 4.933\n",
            "Month 6: 4.965\n",
            "Month 7: 4.998\n",
            "Month 8: 5.030\n",
            "Month 9: 5.062\n",
            "Month 10: 5.095\n",
            "Month 11: 5.127\n",
            "Month 12: 5.159\n"
          ]
        }
      ],
      "source": [
        "# Generate predictions\n",
        "X_future = np.arange(len(df), len(df) + 12)  # Predict next 12 months (adjust as needed)\n",
        "X_future = X_future.reshape(-1, 1, 1)  # Reshape for LSTM input\n",
        "y_pred = model.predict(X_future)\n",
        "\n",
        "# Print predicted prices\n",
        "print(\"Predicted prices for the next 12 months:\")\n",
        "for month, price in zip(range(1, 13), y_pred.flatten()):\n",
        "    print(f\"Month {month}: {price:.3f}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gn-iQdRhEciR"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6UN3ayl0GcUn"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import LSTM, Dense"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tktY1Rx9GzSW",
        "outputId": "99fecbe8-c577-437d-bee6-c6e53715c462"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2/2 [==============================] - 0s 8ms/step\n",
            "Predicted prices from 2024-04-01 to 2028-12-01:\n",
            "2024-04-01: 4.804\n",
            "2024-05-01: 4.836\n",
            "2024-06-01: 4.869\n",
            "2024-07-01: 4.901\n",
            "2024-08-01: 4.933\n",
            "2024-09-01: 4.965\n",
            "2024-10-01: 4.998\n",
            "2024-11-01: 5.030\n",
            "2024-12-01: 5.062\n",
            "2025-01-01: 5.095\n",
            "2025-02-01: 5.127\n",
            "2025-03-01: 5.159\n",
            "2025-04-01: 5.192\n",
            "2025-05-01: 5.224\n",
            "2025-06-01: 5.256\n",
            "2025-07-01: 5.289\n",
            "2025-08-01: 5.321\n",
            "2025-09-01: 5.353\n",
            "2025-10-01: 5.386\n",
            "2025-11-01: 5.418\n",
            "2025-12-01: 5.450\n",
            "2026-01-01: 5.483\n",
            "2026-02-01: 5.515\n",
            "2026-03-01: 5.548\n",
            "2026-04-01: 5.580\n",
            "2026-05-01: 5.612\n",
            "2026-06-01: 5.645\n",
            "2026-07-01: 5.677\n",
            "2026-08-01: 5.709\n",
            "2026-09-01: 5.742\n",
            "2026-10-01: 5.774\n",
            "2026-11-01: 5.806\n",
            "2026-12-01: 5.839\n",
            "2027-01-01: 5.871\n",
            "2027-02-01: 5.903\n",
            "2027-03-01: 5.936\n",
            "2027-04-01: 5.968\n",
            "2027-05-01: 6.000\n",
            "2027-06-01: 6.033\n",
            "2027-07-01: 6.065\n",
            "2027-08-01: 6.097\n",
            "2027-09-01: 6.130\n",
            "2027-10-01: 6.162\n",
            "2027-11-01: 6.194\n",
            "2027-12-01: 6.226\n",
            "2028-01-01: 6.259\n",
            "2028-02-01: 6.291\n",
            "2028-03-01: 6.323\n",
            "2028-04-01: 6.355\n",
            "2028-05-01: 6.388\n",
            "2028-06-01: 6.420\n",
            "2028-07-01: 6.452\n",
            "2028-08-01: 6.484\n",
            "2028-09-01: 6.516\n",
            "2028-10-01: 6.549\n",
            "2028-11-01: 6.581\n",
            "2028-12-01: 6.613\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from datetime import datetime\n",
        "\n",
        "# Function to calculate the number of months between two dates\n",
        "def months_between(start_date, end_date):\n",
        "    start_date = datetime.strptime(start_date, \"%Y-%m-%d\")\n",
        "    end_date = datetime.strptime(end_date, \"%Y-%m-%d\")\n",
        "    return (end_date.year - start_date.year) * 12 + end_date.month - start_date.month + 1\n",
        "\n",
        "# Define the date range\n",
        "start_date = '2024-04-01'\n",
        "end_date = '2028-12-01'\n",
        "\n",
        "# Calculate the number of months to predict\n",
        "num_months = months_between(start_date, end_date)\n",
        "\n",
        "# Generate future indices for prediction\n",
        "X_future = np.arange(len(df), len(df) + num_months)\n",
        "X_future = X_future.reshape(-1, 1, 1)  # Reshape for LSTM input\n",
        "\n",
        "# Generate predictions\n",
        "y_pred = model.predict(X_future)\n",
        "\n",
        "# Generate date range for the predictions\n",
        "dates = pd.date_range(start=start_date, periods=num_months, freq='MS')\n",
        "\n",
        "# Print predicted prices with corresponding dates\n",
        "print(\"Predicted prices from 2024-04-01 to 2028-12-01:\")\n",
        "for date, price in zip(dates, y_pred.flatten()):\n",
        "    print(f\"{date.strftime('%Y-%m-%d')}: {price:.3f}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TyvFRW23uYDx",
        "outputId": "3aaa97f8-fa46-42c7-f8f1-bfb0dfab9d80"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/50\n",
            "5/5 [==============================] - 1s 4ms/step - loss: 14.8051\n",
            "Epoch 2/50\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 10.9893\n",
            "Epoch 3/50\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 8.3550\n",
            "Epoch 4/50\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 6.5110\n",
            "Epoch 5/50\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 5.5214\n",
            "Epoch 6/50\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 5.1881\n",
            "Epoch 7/50\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 5.0828\n",
            "Epoch 8/50\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 5.0084\n",
            "Epoch 9/50\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 4.8220\n",
            "Epoch 10/50\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 4.5802\n",
            "Epoch 11/50\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 4.3092\n",
            "Epoch 12/50\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 4.1055\n",
            "Epoch 13/50\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 3.9430\n",
            "Epoch 14/50\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 3.8045\n",
            "Epoch 15/50\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 3.6936\n",
            "Epoch 16/50\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 3.5863\n",
            "Epoch 17/50\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 3.5359\n",
            "Epoch 18/50\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 3.4627\n",
            "Epoch 19/50\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 3.3966\n",
            "Epoch 20/50\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 3.3218\n",
            "Epoch 21/50\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 3.2664\n",
            "Epoch 22/50\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 3.2097\n",
            "Epoch 23/50\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 3.1612\n",
            "Epoch 24/50\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 3.1192\n",
            "Epoch 25/50\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 3.0578\n",
            "Epoch 26/50\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 3.0165\n",
            "Epoch 27/50\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 2.9759\n",
            "Epoch 28/50\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 2.9308\n",
            "Epoch 29/50\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 2.8952\n",
            "Epoch 30/50\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 2.8593\n",
            "Epoch 31/50\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 2.8283\n",
            "Epoch 32/50\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 2.7952\n",
            "Epoch 33/50\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 2.7643\n",
            "Epoch 34/50\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 2.7327\n",
            "Epoch 35/50\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 2.7050\n",
            "Epoch 36/50\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 2.6784\n",
            "Epoch 37/50\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 2.6482\n",
            "Epoch 38/50\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 2.6249\n",
            "Epoch 39/50\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 2.6010\n",
            "Epoch 40/50\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 2.5797\n",
            "Epoch 41/50\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 2.5622\n",
            "Epoch 42/50\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 2.5500\n",
            "Epoch 43/50\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 2.5242\n",
            "Epoch 44/50\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 2.5071\n",
            "Epoch 45/50\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 2.4933\n",
            "Epoch 46/50\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 2.4830\n",
            "Epoch 47/50\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 2.4705\n",
            "Epoch 48/50\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 2.4569\n",
            "Epoch 49/50\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 2.4511\n",
            "Epoch 50/50\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 2.4400\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Predicted prices from 2024-04-01 to 2028-12-01:\n",
            "2024-04-01: 4.907\n",
            "2024-05-01: 4.935\n",
            "2024-06-01: 4.964\n",
            "2024-07-01: 4.993\n",
            "2024-08-01: 5.021\n",
            "2024-09-01: 5.050\n",
            "2024-10-01: 5.079\n",
            "2024-11-01: 5.108\n",
            "2024-12-01: 5.136\n",
            "2025-01-01: 5.165\n",
            "2025-02-01: 5.194\n",
            "2025-03-01: 5.223\n",
            "2025-04-01: 5.251\n",
            "2025-05-01: 5.280\n",
            "2025-06-01: 5.309\n",
            "2025-07-01: 5.338\n",
            "2025-08-01: 5.367\n",
            "2025-09-01: 5.396\n",
            "2025-10-01: 5.424\n",
            "2025-11-01: 5.453\n",
            "2025-12-01: 5.482\n",
            "2026-01-01: 5.511\n",
            "2026-02-01: 5.540\n",
            "2026-03-01: 5.569\n",
            "2026-04-01: 5.598\n",
            "2026-05-01: 5.627\n",
            "2026-06-01: 5.656\n",
            "2026-07-01: 5.685\n",
            "2026-08-01: 5.714\n",
            "2026-09-01: 5.743\n",
            "2026-10-01: 5.772\n",
            "2026-11-01: 5.801\n",
            "2026-12-01: 5.830\n",
            "2027-01-01: 5.859\n",
            "2027-02-01: 5.888\n",
            "2027-03-01: 5.917\n",
            "2027-04-01: 5.946\n",
            "2027-05-01: 5.975\n",
            "2027-06-01: 6.005\n",
            "2027-07-01: 6.034\n",
            "2027-08-01: 6.063\n",
            "2027-09-01: 6.092\n",
            "2027-10-01: 6.121\n",
            "2027-11-01: 6.150\n",
            "2027-12-01: 6.180\n",
            "2028-01-01: 6.209\n",
            "2028-02-01: 6.238\n",
            "2028-03-01: 6.267\n",
            "2028-04-01: 6.297\n",
            "2028-05-01: 6.326\n",
            "2028-06-01: 6.355\n",
            "2028-07-01: 6.384\n",
            "2028-08-01: 6.414\n",
            "2028-09-01: 6.443\n",
            "2028-10-01: 6.472\n",
            "2028-11-01: 6.502\n",
            "2028-12-01: 6.531\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from datetime import datetime\n",
        "\n",
        "# Function to calculate the number of months between two dates\n",
        "def months_between(start_date, end_date):\n",
        "    start_date = datetime.strptime(start_date, \"%Y-%m-%d\")\n",
        "    end_date = datetime.strptime(end_date, \"%Y-%m-%d\")\n",
        "    return (end_date.year - start_date.year) * 12 + end_date.month - start_date.month + 1\n",
        "\n",
        "# Define the date range\n",
        "start_date = '2024-04-01'\n",
        "end_date = '2028-12-01'\n",
        "\n",
        "# Calculate the number of months to predict\n",
        "num_months = months_between(start_date, end_date)\n",
        "\n",
        "# Generate future indices for prediction\n",
        "X_future = np.arange(len(df), len(df) + num_months)\n",
        "X_future = X_future.reshape(-1, 1, 1)  # Reshape for LSTM input\n",
        "\n",
        "# Ensure data is sorted by date\n",
        "df = df.sort_values(by=\"Date\", ascending=True)\n",
        "\n",
        "# Prepare data for LSTM model\n",
        "X_train = np.arange(len(df)).reshape(-1, 1, 1)\n",
        "y_train = df['Price'].values\n",
        "\n",
        "# Define and train the LSTM model\n",
        "model = Sequential()\n",
        "model.add(LSTM(64, activation='relu', input_shape=(1, 1)))\n",
        "model.add(Dense(1))\n",
        "model.compile(optimizer='adam', loss='mean_squared_error')\n",
        "model.fit(X_train, y_train, epochs=50)\n",
        "\n",
        "# Generate predictions\n",
        "y_pred = model.predict(X_future)\n",
        "\n",
        "# Generate date range for the predictions\n",
        "dates = pd.date_range(start=start_date, periods=num_months, freq='MS')\n",
        "\n",
        "# Print predicted prices with corresponding dates\n",
        "print(\"Predicted prices from 2024-04-01 to 2028-12-01:\")\n",
        "for date, price in zip(dates, y_pred.flatten()):\n",
        "    print(f\"{date.strftime('%Y-%m-%d')}: {price:.3f}\")\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "derOoNMZwCWp",
        "outputId": "2ef34e21-3971-459d-ff3f-899306947304"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/50\n",
            "5/5 [==============================] - 1s 4ms/step - loss: 21.9984\n",
            "Epoch 2/50\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 16.5317\n",
            "Epoch 3/50\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 12.5768\n",
            "Epoch 4/50\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 9.9406\n",
            "Epoch 5/50\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 8.0287\n",
            "Epoch 6/50\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 6.3747\n",
            "Epoch 7/50\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 5.1541\n",
            "Epoch 8/50\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 4.2116\n",
            "Epoch 9/50\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 3.6614\n",
            "Epoch 10/50\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 3.6378\n",
            "Epoch 11/50\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 3.6199\n",
            "Epoch 12/50\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 3.4585\n",
            "Epoch 13/50\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 3.3677\n",
            "Epoch 14/50\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 3.3125\n",
            "Epoch 15/50\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 3.2470\n",
            "Epoch 16/50\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 3.1717\n",
            "Epoch 17/50\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 3.1234\n",
            "Epoch 18/50\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 3.0855\n",
            "Epoch 19/50\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 3.0370\n",
            "Epoch 20/50\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 2.9935\n",
            "Epoch 21/50\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 2.9543\n",
            "Epoch 22/50\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 2.9115\n",
            "Epoch 23/50\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 2.8766\n",
            "Epoch 24/50\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 2.8451\n",
            "Epoch 25/50\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 2.8168\n",
            "Epoch 26/50\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 2.7842\n",
            "Epoch 27/50\n",
            "5/5 [==============================] - 0s 6ms/step - loss: 2.7565\n",
            "Epoch 28/50\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 2.7275\n",
            "Epoch 29/50\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 2.7029\n",
            "Epoch 30/50\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 2.6783\n",
            "Epoch 31/50\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 2.6570\n",
            "Epoch 32/50\n",
            "5/5 [==============================] - 0s 6ms/step - loss: 2.6372\n",
            "Epoch 33/50\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 2.6157\n",
            "Epoch 34/50\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 2.5962\n",
            "Epoch 35/50\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 2.5811\n",
            "Epoch 36/50\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 2.5678\n",
            "Epoch 37/50\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 2.5514\n",
            "Epoch 38/50\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 2.5395\n",
            "Epoch 39/50\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 2.5209\n",
            "Epoch 40/50\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 2.5064\n",
            "Epoch 41/50\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 2.4963\n",
            "Epoch 42/50\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 2.4868\n",
            "Epoch 43/50\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 2.4772\n",
            "Epoch 44/50\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 2.4668\n",
            "Epoch 45/50\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 2.4577\n",
            "Epoch 46/50\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 2.4505\n",
            "Epoch 47/50\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 2.4428\n",
            "Epoch 48/50\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 2.4395\n",
            "Epoch 49/50\n",
            "5/5 [==============================] - 0s 6ms/step - loss: 2.4287\n",
            "Epoch 50/50\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 2.4339\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Predicted prices from 2024-04-01 to 2028-12-01:\n",
            "2024-04-01: 5.066\n",
            "2024-05-01: 5.099\n",
            "2024-06-01: 5.132\n",
            "2024-07-01: 5.166\n",
            "2024-08-01: 5.199\n",
            "2024-09-01: 5.232\n",
            "2024-10-01: 5.265\n",
            "2024-11-01: 5.298\n",
            "2024-12-01: 5.332\n",
            "2025-01-01: 5.365\n",
            "2025-02-01: 5.398\n",
            "2025-03-01: 5.431\n",
            "2025-04-01: 5.465\n",
            "2025-05-01: 5.498\n",
            "2025-06-01: 5.531\n",
            "2025-07-01: 5.565\n",
            "2025-08-01: 5.598\n",
            "2025-09-01: 5.631\n",
            "2025-10-01: 5.664\n",
            "2025-11-01: 5.698\n",
            "2025-12-01: 5.731\n",
            "2026-01-01: 5.764\n",
            "2026-02-01: 5.798\n",
            "2026-03-01: 5.831\n",
            "2026-04-01: 5.864\n",
            "2026-05-01: 5.898\n",
            "2026-06-01: 5.931\n",
            "2026-07-01: 5.964\n",
            "2026-08-01: 5.998\n",
            "2026-09-01: 6.031\n",
            "2026-10-01: 6.064\n",
            "2026-11-01: 6.098\n",
            "2026-12-01: 6.131\n",
            "2027-01-01: 6.164\n",
            "2027-02-01: 6.198\n",
            "2027-03-01: 6.231\n",
            "2027-04-01: 6.264\n",
            "2027-05-01: 6.298\n",
            "2027-06-01: 6.331\n",
            "2027-07-01: 6.364\n",
            "2027-08-01: 6.398\n",
            "2027-09-01: 6.431\n",
            "2027-10-01: 6.464\n",
            "2027-11-01: 6.498\n",
            "2027-12-01: 6.531\n",
            "2028-01-01: 6.564\n",
            "2028-02-01: 6.598\n",
            "2028-03-01: 6.631\n",
            "2028-04-01: 6.664\n",
            "2028-05-01: 6.698\n",
            "2028-06-01: 6.731\n",
            "2028-07-01: 6.764\n",
            "2028-08-01: 6.798\n",
            "2028-09-01: 6.831\n",
            "2028-10-01: 6.864\n",
            "2028-11-01: 6.898\n",
            "2028-12-01: 6.931\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from datetime import datetime\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import LSTM, Dense\n",
        "\n",
        "# Read the dataset\n",
        "df = pd.read_excel('LNG (High).xlsx')\n",
        "\n",
        "# Function to calculate the number of months between two dates\n",
        "def months_between(start_date, end_date):\n",
        "    start_date = datetime.strptime(start_date, \"%Y-%m-%d\")\n",
        "    end_date = datetime.strptime(end_date, \"%Y-%m-%d\")\n",
        "    return (end_date.year - start_date.year) * 12 + end_date.month - start_date.month + 1\n",
        "\n",
        "# Define the date range\n",
        "start_date = '2024-04-01'\n",
        "end_date = '2028-12-01'\n",
        "\n",
        "# Calculate the number of months to predict\n",
        "num_months = months_between(start_date, end_date)\n",
        "\n",
        "# Ensure data is sorted by date\n",
        "df = df.sort_values(by=\"Date\", ascending=True)\n",
        "\n",
        "# Prepare data for training\n",
        "X_train = np.arange(len(df)).reshape(-1, 1, 1)\n",
        "y_train = df['Price'].values\n",
        "\n",
        "# Define and train the LSTM model\n",
        "model = Sequential()\n",
        "model.add(LSTM(64, activation='relu', input_shape=(1, 1)))\n",
        "model.add(Dense(1))\n",
        "model.compile(optimizer='adam', loss='mean_squared_error')\n",
        "model.fit(X_train, y_train, epochs=50)\n",
        "\n",
        "# Generate future indices for prediction\n",
        "X_future = np.arange(len(df), len(df) + num_months)\n",
        "X_future = X_future.reshape(-1, 1, 1)  # Reshape for LSTM input\n",
        "\n",
        "# Generate predictions\n",
        "y_pred = model.predict(X_future)\n",
        "\n",
        "# Generate date range for the predictions\n",
        "dates = pd.date_range(start=start_date, periods=num_months, freq='MS')\n",
        "\n",
        "# Print predicted prices with corresponding dates\n",
        "print(\"Predicted prices from 2024-04-01 to 2028-12-01:\")\n",
        "for date, price in zip(dates, y_pred.flatten()):\n",
        "    print(f\"{date.strftime('%Y-%m-%d')}: {price:.3f}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fWqR0USdy4KI",
        "outputId": "e76d8f97-cac8-4695-e9e0-c597ce268c6f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/50\n",
            "5/5 [==============================] - 2s 4ms/step - loss: 38.4875\n",
            "Epoch 2/50\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 28.0121\n",
            "Epoch 3/50\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 19.8465\n",
            "Epoch 4/50\n",
            "5/5 [==============================] - 0s 6ms/step - loss: 13.8931\n",
            "Epoch 5/50\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 9.5662\n",
            "Epoch 6/50\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 6.5871\n",
            "Epoch 7/50\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 5.1256\n",
            "Epoch 8/50\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 4.7066\n",
            "Epoch 9/50\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 4.7825\n",
            "Epoch 10/50\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 4.4506\n",
            "Epoch 11/50\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 4.0313\n",
            "Epoch 12/50\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 3.7607\n",
            "Epoch 13/50\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 3.5975\n",
            "Epoch 14/50\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 3.4076\n",
            "Epoch 15/50\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 3.3205\n",
            "Epoch 16/50\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 3.2510\n",
            "Epoch 17/50\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 3.1909\n",
            "Epoch 18/50\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 3.1312\n",
            "Epoch 19/50\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 3.0917\n",
            "Epoch 20/50\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 3.0380\n",
            "Epoch 21/50\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 3.0080\n",
            "Epoch 22/50\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 2.9529\n",
            "Epoch 23/50\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 2.9056\n",
            "Epoch 24/50\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 2.8671\n",
            "Epoch 25/50\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 2.8343\n",
            "Epoch 26/50\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 2.7936\n",
            "Epoch 27/50\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 2.7633\n",
            "Epoch 28/50\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 2.7331\n",
            "Epoch 29/50\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 2.7018\n",
            "Epoch 30/50\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 2.6784\n",
            "Epoch 31/50\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 2.6529\n",
            "Epoch 32/50\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 2.6396\n",
            "Epoch 33/50\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 2.6112\n",
            "Epoch 34/50\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 2.5842\n",
            "Epoch 35/50\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 2.5722\n",
            "Epoch 36/50\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 2.5524\n",
            "Epoch 37/50\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 2.5320\n",
            "Epoch 38/50\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 2.5156\n",
            "Epoch 39/50\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 2.4985\n",
            "Epoch 40/50\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 2.4903\n",
            "Epoch 41/50\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 2.4747\n",
            "Epoch 42/50\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 2.4578\n",
            "Epoch 43/50\n",
            "5/5 [==============================] - 0s 6ms/step - loss: 2.4559\n",
            "Epoch 44/50\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 2.4411\n",
            "Epoch 45/50\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 2.4317\n",
            "Epoch 46/50\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 2.4222\n",
            "Epoch 47/50\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 2.4119\n",
            "Epoch 48/50\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 2.4040\n",
            "Epoch 49/50\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 2.3981\n",
            "Epoch 50/50\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 2.3898\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Predicted prices from 2024-04-01 to 2028-12-01:\n",
            "2024-04-01: 5.031\n",
            "2024-05-01: 5.061\n",
            "2024-06-01: 5.091\n",
            "2024-07-01: 5.120\n",
            "2024-08-01: 5.150\n",
            "2024-09-01: 5.179\n",
            "2024-10-01: 5.209\n",
            "2024-11-01: 5.238\n",
            "2024-12-01: 5.268\n",
            "2025-01-01: 5.297\n",
            "2025-02-01: 5.327\n",
            "2025-03-01: 5.356\n",
            "2025-04-01: 5.386\n",
            "2025-05-01: 5.415\n",
            "2025-06-01: 5.445\n",
            "2025-07-01: 5.474\n",
            "2025-08-01: 5.504\n",
            "2025-09-01: 5.533\n",
            "2025-10-01: 5.562\n",
            "2025-11-01: 5.592\n",
            "2025-12-01: 5.621\n",
            "2026-01-01: 5.651\n",
            "2026-02-01: 5.680\n",
            "2026-03-01: 5.709\n",
            "2026-04-01: 5.739\n",
            "2026-05-01: 5.768\n",
            "2026-06-01: 5.798\n",
            "2026-07-01: 5.827\n",
            "2026-08-01: 5.856\n",
            "2026-09-01: 5.886\n",
            "2026-10-01: 5.915\n",
            "2026-11-01: 5.944\n",
            "2026-12-01: 5.974\n",
            "2027-01-01: 6.003\n",
            "2027-02-01: 6.032\n",
            "2027-03-01: 6.062\n",
            "2027-04-01: 6.091\n",
            "2027-05-01: 6.120\n",
            "2027-06-01: 6.150\n",
            "2027-07-01: 6.179\n",
            "2027-08-01: 6.208\n",
            "2027-09-01: 6.238\n",
            "2027-10-01: 6.267\n",
            "2027-11-01: 6.296\n",
            "2027-12-01: 6.326\n",
            "2028-01-01: 6.355\n",
            "2028-02-01: 6.384\n",
            "2028-03-01: 6.414\n",
            "2028-04-01: 6.443\n",
            "2028-05-01: 6.472\n",
            "2028-06-01: 6.502\n",
            "2028-07-01: 6.531\n",
            "2028-08-01: 6.560\n",
            "2028-09-01: 6.590\n",
            "2028-10-01: 6.619\n",
            "2028-11-01: 6.648\n",
            "2028-12-01: 6.678\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from datetime import datetime\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import LSTM, Dense\n",
        "\n",
        "# Read the dataset\n",
        "df = pd.read_excel('LNG (High).xlsx')\n",
        "\n",
        "# Function to calculate the number of months between two dates\n",
        "def months_between(start_date, end_date):\n",
        "    start_date = datetime.strptime(start_date, \"%Y-%m-%d\")\n",
        "    end_date = datetime.strptime(end_date, \"%Y-%m-%d\")\n",
        "    return (end_date.year - start_date.year) * 12 + end_date.month - start_date.month + 1\n",
        "\n",
        "# Define the date range\n",
        "start_date = '2024-04-01'\n",
        "end_date = '2028-12-01'\n",
        "\n",
        "# Calculate the number of months to predict\n",
        "num_months = months_between(start_date, end_date)\n",
        "\n",
        "# Ensure data is sorted by date\n",
        "df['Date'] = pd.to_datetime(df['Date'], format='%b-%y')\n",
        "df = df.sort_values(by=\"Date\", ascending=True)\n",
        "\n",
        "# Prepare data for training\n",
        "X_train = np.arange(len(df)).reshape(-1, 1, 1)\n",
        "y_train = df['Price'].values\n",
        "\n",
        "# Define and train the LSTM model\n",
        "model = Sequential()\n",
        "model.add(LSTM(64, activation='relu', input_shape=(1, 1)))\n",
        "model.add(Dense(1))\n",
        "model.compile(optimizer='adam', loss='mean_squared_error')\n",
        "model.fit(X_train, y_train, epochs=50)\n",
        "\n",
        "# Generate future indices for prediction\n",
        "X_future = np.arange(len(df), len(df) + num_months)\n",
        "X_future = X_future.reshape(-1, 1, 1)  # Reshape for LSTM input\n",
        "\n",
        "# Generate predictions\n",
        "y_pred = model.predict(X_future)\n",
        "\n",
        "# Generate date range for the predictions\n",
        "dates = pd.date_range(start=start_date, periods=num_months, freq='MS')\n",
        "\n",
        "# Print predicted prices with corresponding dates\n",
        "print(\"Predicted prices from 2024-04-01 to 2028-12-01:\")\n",
        "for date, price in zip(dates, y_pred.flatten()):\n",
        "    print(f\"{date.strftime('%Y-%m-%d')}: {price:.3f}\")\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "m6vhcwvNzVUC",
        "outputId": "8c42f444-706e-4cd7-fd33-da9d23a3ae72"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/50\n",
            "5/5 [==============================] - 2s 4ms/step - loss: 0.3233\n",
            "Epoch 2/50\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.2001\n",
            "Epoch 3/50\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0716\n",
            "Epoch 4/50\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0998\n",
            "Epoch 5/50\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0553\n",
            "Epoch 6/50\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0525\n",
            "Epoch 7/50\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0392\n",
            "Epoch 8/50\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0435\n",
            "Epoch 9/50\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0375\n",
            "Epoch 10/50\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0416\n",
            "Epoch 11/50\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0373\n",
            "Epoch 12/50\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.0376\n",
            "Epoch 13/50\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0366\n",
            "Epoch 14/50\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0367\n",
            "Epoch 15/50\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0361\n",
            "Epoch 16/50\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0374\n",
            "Epoch 17/50\n",
            "5/5 [==============================] - 0s 6ms/step - loss: 0.0380\n",
            "Epoch 18/50\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0363\n",
            "Epoch 19/50\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0361\n",
            "Epoch 20/50\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0359\n",
            "Epoch 21/50\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0356\n",
            "Epoch 22/50\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0361\n",
            "Epoch 23/50\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0365\n",
            "Epoch 24/50\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0369\n",
            "Epoch 25/50\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0374\n",
            "Epoch 26/50\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.0356\n",
            "Epoch 27/50\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0363\n",
            "Epoch 28/50\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0357\n",
            "Epoch 29/50\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0363\n",
            "Epoch 30/50\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.0358\n",
            "Epoch 31/50\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0383\n",
            "Epoch 32/50\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0357\n",
            "Epoch 33/50\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0358\n",
            "Epoch 34/50\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0355\n",
            "Epoch 35/50\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0346\n",
            "Epoch 36/50\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0362\n",
            "Epoch 37/50\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0365\n",
            "Epoch 38/50\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0377\n",
            "Epoch 39/50\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0351\n",
            "Epoch 40/50\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0369\n",
            "Epoch 41/50\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0387\n",
            "Epoch 42/50\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0360\n",
            "Epoch 43/50\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0370\n",
            "Epoch 44/50\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0348\n",
            "Epoch 45/50\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0355\n",
            "Epoch 46/50\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0388\n",
            "Epoch 47/50\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0432\n",
            "Epoch 48/50\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0352\n",
            "Epoch 49/50\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0403\n",
            "Epoch 50/50\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0346\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:5 out of the last 10 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7b397dc7ee60> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2/2 [==============================] - 0s 5ms/step\n",
            "Predicted prices from 2024-04-01 to 2028-12-01:\n",
            "2024-04-01: 4.501\n",
            "2024-05-01: 4.532\n",
            "2024-06-01: 4.563\n",
            "2024-07-01: 4.594\n",
            "2024-08-01: 4.625\n",
            "2024-09-01: 4.657\n",
            "2024-10-01: 4.688\n",
            "2024-11-01: 4.720\n",
            "2024-12-01: 4.752\n",
            "2025-01-01: 4.784\n",
            "2025-02-01: 4.816\n",
            "2025-03-01: 4.848\n",
            "2025-04-01: 4.881\n",
            "2025-05-01: 4.913\n",
            "2025-06-01: 4.946\n",
            "2025-07-01: 4.979\n",
            "2025-08-01: 5.013\n",
            "2025-09-01: 5.046\n",
            "2025-10-01: 5.079\n",
            "2025-11-01: 5.113\n",
            "2025-12-01: 5.147\n",
            "2026-01-01: 5.181\n",
            "2026-02-01: 5.215\n",
            "2026-03-01: 5.249\n",
            "2026-04-01: 5.284\n",
            "2026-05-01: 5.318\n",
            "2026-06-01: 5.353\n",
            "2026-07-01: 5.388\n",
            "2026-08-01: 5.423\n",
            "2026-09-01: 5.458\n",
            "2026-10-01: 5.493\n",
            "2026-11-01: 5.529\n",
            "2026-12-01: 5.565\n",
            "2027-01-01: 5.600\n",
            "2027-02-01: 5.636\n",
            "2027-03-01: 5.673\n",
            "2027-04-01: 5.709\n",
            "2027-05-01: 5.745\n",
            "2027-06-01: 5.782\n",
            "2027-07-01: 5.818\n",
            "2027-08-01: 5.855\n",
            "2027-09-01: 5.892\n",
            "2027-10-01: 5.929\n",
            "2027-11-01: 5.967\n",
            "2027-12-01: 6.004\n",
            "2028-01-01: 6.041\n",
            "2028-02-01: 6.079\n",
            "2028-03-01: 6.117\n",
            "2028-04-01: 6.155\n",
            "2028-05-01: 6.193\n",
            "2028-06-01: 6.231\n",
            "2028-07-01: 6.269\n",
            "2028-08-01: 6.308\n",
            "2028-09-01: 6.347\n",
            "2028-10-01: 6.385\n",
            "2028-11-01: 6.424\n",
            "2028-12-01: 6.463\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from datetime import datetime\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import LSTM, Dense\n",
        "\n",
        "# Read the dataset\n",
        "df = pd.read_excel('LNG (High).xlsx')\n",
        "\n",
        "# Function to calculate the number of months between two dates\n",
        "def months_between(start_date, end_date):\n",
        "    start_date = datetime.strptime(start_date, \"%Y-%m-%d\")\n",
        "    end_date = datetime.strptime(end_date, \"%Y-%m-%d\")\n",
        "    return (end_date.year - start_date.year) * 12 + end_date.month - start_date.month + 1\n",
        "\n",
        "# Define the date range\n",
        "start_date = '2024-04-01'\n",
        "end_date = '2028-12-01'\n",
        "\n",
        "# Calculate the number of months to predict\n",
        "num_months = months_between(start_date, end_date)\n",
        "\n",
        "# Ensure data is sorted by date\n",
        "df['Date'] = pd.to_datetime(df['Date'], format='%b-%y')\n",
        "df = df.sort_values(by=\"Date\", ascending=True)\n",
        "\n",
        "# Normalize the data\n",
        "scaler = MinMaxScaler(feature_range=(0, 1))\n",
        "df['Price_normalized'] = scaler.fit_transform(df['Price'].values.reshape(-1,1))\n",
        "\n",
        "# Prepare data for training\n",
        "X_train = np.arange(len(df)).reshape(-1, 1, 1)\n",
        "y_train = df['Price_normalized'].values\n",
        "\n",
        "# Define and train the LSTM model\n",
        "model = Sequential()\n",
        "model.add(LSTM(64, activation='relu', input_shape=(1, 1)))\n",
        "model.add(Dense(1))\n",
        "model.compile(optimizer='adam', loss='mean_squared_error')\n",
        "model.fit(X_train, y_train, epochs=50)\n",
        "\n",
        "# Generate future indices for prediction\n",
        "X_future = np.arange(len(df), len(df) + num_months)\n",
        "X_future = X_future.reshape(-1, 1, 1)  # Reshape for LSTM input\n",
        "\n",
        "# Generate predictions\n",
        "y_pred_normalized = model.predict(X_future)\n",
        "\n",
        "# Inverse transform predictions to get actual prices\n",
        "y_pred = scaler.inverse_transform(y_pred_normalized)\n",
        "\n",
        "# Generate date range for the predictions\n",
        "dates = pd.date_range(start=start_date, periods=num_months, freq='MS')\n",
        "\n",
        "# Print predicted prices with corresponding dates\n",
        "print(\"Predicted prices from 2024-04-01 to 2028-12-01:\")\n",
        "for date, price in zip(dates, y_pred.flatten()):\n",
        "    print(f\"{date.strftime('%Y-%m-%d')}: {price:.3f}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ycbajiI7zr8q",
        "outputId": "2efd1f69-3ac9-44f9-ec2c-6e1b4a259f35"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/50\n",
            "5/5 [==============================] - 1s 4ms/step - loss: 10.6493\n",
            "Epoch 2/50\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 2.6476\n",
            "Epoch 3/50\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.2669\n",
            "Epoch 4/50\n",
            "5/5 [==============================] - 0s 6ms/step - loss: 0.7751\n",
            "Epoch 5/50\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.7956\n",
            "Epoch 6/50\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.2765\n",
            "Epoch 7/50\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0764\n",
            "Epoch 8/50\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.1283\n",
            "Epoch 9/50\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.1302\n",
            "Epoch 10/50\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0718\n",
            "Epoch 11/50\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0442\n",
            "Epoch 12/50\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0528\n",
            "Epoch 13/50\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0499\n",
            "Epoch 14/50\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0397\n",
            "Epoch 15/50\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0367\n",
            "Epoch 16/50\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0365\n",
            "Epoch 17/50\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0329\n",
            "Epoch 18/50\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0312\n",
            "Epoch 19/50\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0305\n",
            "Epoch 20/50\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0292\n",
            "Epoch 21/50\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0282\n",
            "Epoch 22/50\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0274\n",
            "Epoch 23/50\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0266\n",
            "Epoch 24/50\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0259\n",
            "Epoch 25/50\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0257\n",
            "Epoch 26/50\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0250\n",
            "Epoch 27/50\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0246\n",
            "Epoch 28/50\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0242\n",
            "Epoch 29/50\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0240\n",
            "Epoch 30/50\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0238\n",
            "Epoch 31/50\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0235\n",
            "Epoch 32/50\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.0235\n",
            "Epoch 33/50\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0231\n",
            "Epoch 34/50\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0231\n",
            "Epoch 35/50\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.0229\n",
            "Epoch 36/50\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0227\n",
            "Epoch 37/50\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0227\n",
            "Epoch 38/50\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0225\n",
            "Epoch 39/50\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0223\n",
            "Epoch 40/50\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0223\n",
            "Epoch 41/50\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0223\n",
            "Epoch 42/50\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0221\n",
            "Epoch 43/50\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0220\n",
            "Epoch 44/50\n",
            "5/5 [==============================] - 0s 6ms/step - loss: 0.0220\n",
            "Epoch 45/50\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0220\n",
            "Epoch 46/50\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0219\n",
            "Epoch 47/50\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0217\n",
            "Epoch 48/50\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0216\n",
            "Epoch 49/50\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0215\n",
            "Epoch 50/50\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0216\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:6 out of the last 12 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7b39861e2440> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2/2 [==============================] - 0s 8ms/step\n",
            "Predicted prices from 2024-04-01 to 2028-12-01:\n",
            "2024-04-01: 3.195\n",
            "2024-05-01: 3.350\n",
            "2024-06-01: 3.452\n",
            "2024-07-01: 3.506\n",
            "2024-08-01: 3.518\n",
            "2024-09-01: 3.495\n",
            "2024-10-01: 3.443\n",
            "2024-11-01: 3.368\n",
            "2024-12-01: 3.274\n",
            "2025-01-01: 3.166\n",
            "2025-02-01: 3.049\n",
            "2025-03-01: 2.925\n",
            "2025-04-01: 2.797\n",
            "2025-05-01: 2.668\n",
            "2025-06-01: 2.539\n",
            "2025-07-01: 2.412\n",
            "2025-08-01: 2.288\n",
            "2025-09-01: 2.167\n",
            "2025-10-01: 2.051\n",
            "2025-11-01: 1.939\n",
            "2025-12-01: 1.833\n",
            "2026-01-01: 1.731\n",
            "2026-02-01: 1.635\n",
            "2026-03-01: 1.543\n",
            "2026-04-01: 1.457\n",
            "2026-05-01: 1.375\n",
            "2026-06-01: 1.298\n",
            "2026-07-01: 1.226\n",
            "2026-08-01: 1.158\n",
            "2026-09-01: 1.094\n",
            "2026-10-01: 1.034\n",
            "2026-11-01: 0.978\n",
            "2026-12-01: 0.926\n",
            "2027-01-01: 0.876\n",
            "2027-02-01: 0.830\n",
            "2027-03-01: 0.787\n",
            "2027-04-01: 0.747\n",
            "2027-05-01: 0.709\n",
            "2027-06-01: 0.674\n",
            "2027-07-01: 0.641\n",
            "2027-08-01: 0.610\n",
            "2027-09-01: 0.581\n",
            "2027-10-01: 0.553\n",
            "2027-11-01: 0.528\n",
            "2027-12-01: 0.504\n",
            "2028-01-01: 0.481\n",
            "2028-02-01: 0.460\n",
            "2028-03-01: 0.439\n",
            "2028-04-01: 0.420\n",
            "2028-05-01: 0.402\n",
            "2028-06-01: 0.384\n",
            "2028-07-01: 0.368\n",
            "2028-08-01: 0.352\n",
            "2028-09-01: 0.337\n",
            "2028-10-01: 0.322\n",
            "2028-11-01: 0.308\n",
            "2028-12-01: 0.294\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from datetime import datetime\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import LSTM, Dense\n",
        "\n",
        "# Read the dataset\n",
        "df = pd.read_excel('LNG (High).xlsx')\n",
        "\n",
        "# Function to calculate the number of months between two dates\n",
        "def months_between(start_date, end_date):\n",
        "    start_date = datetime.strptime(start_date, \"%Y-%m-%d\")\n",
        "    end_date = datetime.strptime(end_date, \"%Y-%m-%d\")\n",
        "    return (end_date.year - start_date.year) * 12 + end_date.month - start_date.month + 1\n",
        "\n",
        "# Define the date range\n",
        "start_date = '2024-04-01'\n",
        "end_date = '2028-12-01'\n",
        "\n",
        "# Calculate the number of months to predict\n",
        "num_months = months_between(start_date, end_date)\n",
        "\n",
        "# Ensure data is sorted by date\n",
        "df['Date'] = pd.to_datetime(df['Date'], format='%b-%y')\n",
        "df = df.sort_values(by=\"Date\", ascending=True)\n",
        "\n",
        "# Normalize the data\n",
        "scaler = MinMaxScaler(feature_range=(0, 1))\n",
        "df['Price_normalized'] = scaler.fit_transform(df['Price'].values.reshape(-1,1))\n",
        "\n",
        "# Create a new feature representing the number of months since start date\n",
        "df['Months_since_start'] = (df['Date'] - pd.to_datetime(start_date)).dt.days / 30\n",
        "\n",
        "# Prepare data for training\n",
        "X_train = df['Months_since_start'].values.reshape(-1, 1, 1)\n",
        "y_train = df['Price_normalized'].values\n",
        "\n",
        "# Define and train the LSTM model\n",
        "model = Sequential()\n",
        "model.add(LSTM(64, activation='relu', input_shape=(1, 1)))\n",
        "model.add(Dense(1))\n",
        "model.compile(optimizer='adam', loss='mean_squared_error')\n",
        "model.fit(X_train, y_train, epochs=50)\n",
        "\n",
        "# Generate future indices for prediction\n",
        "X_future = np.arange(df['Months_since_start'].iloc[-1] + 1, df['Months_since_start'].iloc[-1] + 1 + num_months)\n",
        "X_future = X_future.reshape(-1, 1, 1)  # Reshape for LSTM input\n",
        "\n",
        "# Generate predictions\n",
        "y_pred_normalized = model.predict(X_future)\n",
        "\n",
        "# Inverse transform predictions to get actual prices\n",
        "y_pred = scaler.inverse_transform(y_pred_normalized)\n",
        "\n",
        "# Generate date range for the predictions\n",
        "dates = pd.date_range(start=start_date, periods=num_months, freq='MS')\n",
        "\n",
        "# Print predicted prices with corresponding dates\n",
        "print(\"Predicted prices from 2024-04-01 to 2028-12-01:\")\n",
        "for date, price in zip(dates, y_pred.flatten()):\n",
        "    print(f\"{date.strftime('%Y-%m-%d')}: {price:.3f}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "J7yUaN020Kn3",
        "outputId": "6d7864be-bf10-4d6d-b29f-14639b84c30e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/50\n",
            "5/5 [==============================] - 3s 5ms/step - loss: 4.2243\n",
            "Epoch 2/50\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 1.7881\n",
            "Epoch 3/50\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.4565\n",
            "Epoch 4/50\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0926\n",
            "Epoch 5/50\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0896\n",
            "Epoch 6/50\n",
            "5/5 [==============================] - 0s 7ms/step - loss: 0.0896\n",
            "Epoch 7/50\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 0.0896\n",
            "Epoch 8/50\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0896\n",
            "Epoch 9/50\n",
            "5/5 [==============================] - 0s 6ms/step - loss: 0.0896\n",
            "Epoch 10/50\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0896\n",
            "Epoch 11/50\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0896\n",
            "Epoch 12/50\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0896\n",
            "Epoch 13/50\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0896\n",
            "Epoch 14/50\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0896\n",
            "Epoch 15/50\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0896\n",
            "Epoch 16/50\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0896\n",
            "Epoch 17/50\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0896\n",
            "Epoch 18/50\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0896\n",
            "Epoch 19/50\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0896\n",
            "Epoch 20/50\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0896\n",
            "Epoch 21/50\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0896\n",
            "Epoch 22/50\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0896\n",
            "Epoch 23/50\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0896\n",
            "Epoch 24/50\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0896\n",
            "Epoch 25/50\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0896\n",
            "Epoch 26/50\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0896\n",
            "Epoch 27/50\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0896\n",
            "Epoch 28/50\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0896\n",
            "Epoch 29/50\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0896\n",
            "Epoch 30/50\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0896\n",
            "Epoch 31/50\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0896\n",
            "Epoch 32/50\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0896\n",
            "Epoch 33/50\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0896\n",
            "Epoch 34/50\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0896\n",
            "Epoch 35/50\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0896\n",
            "Epoch 36/50\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0896\n",
            "Epoch 37/50\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0896\n",
            "Epoch 38/50\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0896\n",
            "Epoch 39/50\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0896\n",
            "Epoch 40/50\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0896\n",
            "Epoch 41/50\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0896\n",
            "Epoch 42/50\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0896\n",
            "Epoch 43/50\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0896\n",
            "Epoch 44/50\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0896\n",
            "Epoch 45/50\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0896\n",
            "Epoch 46/50\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0896\n",
            "Epoch 47/50\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0896\n",
            "Epoch 48/50\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0896\n",
            "Epoch 49/50\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0896\n",
            "Epoch 50/50\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0896\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Predicted prices from 2024-04-01 to 2028-12-01:\n",
            "2024-04-01: 1.864\n",
            "2024-05-01: 1.864\n",
            "2024-06-01: 1.864\n",
            "2024-07-01: 1.864\n",
            "2024-08-01: 1.864\n",
            "2024-09-01: 1.864\n",
            "2024-10-01: 1.864\n",
            "2024-11-01: 1.864\n",
            "2024-12-01: 1.864\n",
            "2025-01-01: 1.864\n",
            "2025-02-01: 1.864\n",
            "2025-03-01: 1.864\n",
            "2025-04-01: 1.864\n",
            "2025-05-01: 1.864\n",
            "2025-06-01: 1.864\n",
            "2025-07-01: 1.864\n",
            "2025-08-01: 1.864\n",
            "2025-09-01: 1.864\n",
            "2025-10-01: 1.864\n",
            "2025-11-01: 1.864\n",
            "2025-12-01: 1.864\n",
            "2026-01-01: 1.864\n",
            "2026-02-01: 1.864\n",
            "2026-03-01: 1.864\n",
            "2026-04-01: 1.864\n",
            "2026-05-01: 1.864\n",
            "2026-06-01: 1.864\n",
            "2026-07-01: 1.864\n",
            "2026-08-01: 1.864\n",
            "2026-09-01: 1.864\n",
            "2026-10-01: 1.864\n",
            "2026-11-01: 1.864\n",
            "2026-12-01: 1.864\n",
            "2027-01-01: 1.864\n",
            "2027-02-01: 1.864\n",
            "2027-03-01: 1.864\n",
            "2027-04-01: 1.864\n",
            "2027-05-01: 1.864\n",
            "2027-06-01: 1.864\n",
            "2027-07-01: 1.864\n",
            "2027-08-01: 1.864\n",
            "2027-09-01: 1.864\n",
            "2027-10-01: 1.864\n",
            "2027-11-01: 1.864\n",
            "2027-12-01: 1.864\n",
            "2028-01-01: 1.864\n",
            "2028-02-01: 1.864\n",
            "2028-03-01: 1.864\n",
            "2028-04-01: 1.864\n",
            "2028-05-01: 1.864\n",
            "2028-06-01: 1.864\n",
            "2028-07-01: 1.864\n",
            "2028-08-01: 1.864\n",
            "2028-09-01: 1.864\n",
            "2028-10-01: 1.864\n",
            "2028-11-01: 1.864\n",
            "2028-12-01: 1.864\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from datetime import datetime\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import LSTM, Dense\n",
        "from tensorflow.keras.activations import relu\n",
        "\n",
        "# Read the dataset\n",
        "df = pd.read_excel('LNG (High).xlsx')\n",
        "\n",
        "# Function to calculate the number of months between two dates\n",
        "def months_between(start_date, end_date):\n",
        "    start_date = datetime.strptime(start_date, \"%Y-%m-%d\")\n",
        "    end_date = datetime.strptime(end_date, \"%Y-%m-%d\")\n",
        "    return (end_date.year - start_date.year) * 12 + end_date.month - start_date.month + 1\n",
        "\n",
        "# Define the date range\n",
        "start_date = '2024-04-01'\n",
        "end_date = '2028-12-01'\n",
        "\n",
        "# Calculate the number of months to predict\n",
        "num_months = months_between(start_date, end_date)\n",
        "\n",
        "# Ensure data is sorted by date\n",
        "df['Date'] = pd.to_datetime(df['Date'], format='%b-%y')\n",
        "df = df.sort_values(by=\"Date\", ascending=True)\n",
        "\n",
        "# Normalize the data\n",
        "scaler = MinMaxScaler(feature_range=(0, 1))\n",
        "df['Price_normalized'] = scaler.fit_transform(df['Price'].values.reshape(-1,1))\n",
        "\n",
        "# Create a new feature representing the number of months since start date\n",
        "df['Months_since_start'] = (df['Date'] - pd.to_datetime(start_date)).dt.days / 30\n",
        "\n",
        "# Prepare data for training\n",
        "X_train = df['Months_since_start'].values.reshape(-1, 1, 1)\n",
        "y_train = df['Price_normalized'].values\n",
        "\n",
        "# Define and train the LSTM model\n",
        "model = Sequential()\n",
        "model.add(LSTM(64, activation='relu', input_shape=(1, 1)))\n",
        "model.add(Dense(1, activation=relu))\n",
        "model.compile(optimizer='adam', loss='mean_squared_error')\n",
        "model.fit(X_train, y_train, epochs=50)\n",
        "\n",
        "# Generate future indices for prediction\n",
        "X_future = np.arange(df['Months_since_start'].iloc[-1] + 1, df['Months_since_start'].iloc[-1] + 1 + num_months)\n",
        "X_future = X_future.reshape(-1, 1, 1)  # Reshape for LSTM input\n",
        "\n",
        "# Generate predictions\n",
        "y_pred_normalized = model.predict(X_future)\n",
        "\n",
        "# Inverse transform predictions to get actual prices\n",
        "y_pred = scaler.inverse_transform(y_pred_normalized)\n",
        "\n",
        "# Ensure predictions are non-negative\n",
        "y_pred = np.maximum(y_pred, 0)\n",
        "\n",
        "# Generate date range for the predictions\n",
        "dates = pd.date_range(start=start_date, periods=num_months, freq='MS')\n",
        "\n",
        "# Print predicted prices with corresponding dates\n",
        "print(\"Predicted prices from 2024-04-01 to 2028-12-01:\")\n",
        "for date, price in zip(dates, y_pred.flatten()):\n",
        "    print(f\"{date.strftime('%Y-%m-%d')}: {price:.3f}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WBKfTCLX0hw5",
        "outputId": "2010959d-8b32-4267-b96c-24b1c0b7343b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/100\n",
            "5/5 [==============================] - 2s 7ms/step - loss: 0.0895\n",
            "Epoch 2/100\n",
            "5/5 [==============================] - 0s 6ms/step - loss: 0.0895\n",
            "Epoch 3/100\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0894\n",
            "Epoch 4/100\n",
            "5/5 [==============================] - 0s 6ms/step - loss: 0.0816\n",
            "Epoch 5/100\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0486\n",
            "Epoch 6/100\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0452\n",
            "Epoch 7/100\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0322\n",
            "Epoch 8/100\n",
            "5/5 [==============================] - 0s 6ms/step - loss: 0.0319\n",
            "Epoch 9/100\n",
            "5/5 [==============================] - 0s 6ms/step - loss: 0.0255\n",
            "Epoch 10/100\n",
            "5/5 [==============================] - 0s 6ms/step - loss: 0.0252\n",
            "Epoch 11/100\n",
            "5/5 [==============================] - 0s 6ms/step - loss: 0.0226\n",
            "Epoch 12/100\n",
            "5/5 [==============================] - 0s 6ms/step - loss: 0.0219\n",
            "Epoch 13/100\n",
            "5/5 [==============================] - 0s 6ms/step - loss: 0.0247\n",
            "Epoch 14/100\n",
            "5/5 [==============================] - 0s 7ms/step - loss: 0.0355\n",
            "Epoch 15/100\n",
            "5/5 [==============================] - 0s 6ms/step - loss: 0.0389\n",
            "Epoch 16/100\n",
            "5/5 [==============================] - 0s 6ms/step - loss: 0.0385\n",
            "Epoch 17/100\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0381\n",
            "Epoch 18/100\n",
            "5/5 [==============================] - 0s 6ms/step - loss: 0.0384\n",
            "Epoch 19/100\n",
            "5/5 [==============================] - 0s 7ms/step - loss: 0.0383\n",
            "Epoch 20/100\n",
            "5/5 [==============================] - 0s 6ms/step - loss: 0.0379\n",
            "Epoch 21/100\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.0369\n",
            "Epoch 22/100\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 0.0370\n",
            "Epoch 23/100\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 0.0366\n",
            "Epoch 24/100\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 0.0366\n",
            "Epoch 25/100\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 0.0361\n",
            "Epoch 26/100\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 0.0361\n",
            "Epoch 27/100\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 0.0359\n",
            "Epoch 28/100\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.0359\n",
            "Epoch 29/100\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 0.0358\n",
            "Epoch 30/100\n",
            "5/5 [==============================] - 0s 7ms/step - loss: 0.0359\n",
            "Epoch 31/100\n",
            "5/5 [==============================] - 0s 7ms/step - loss: 0.0353\n",
            "Epoch 32/100\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 0.0356\n",
            "Epoch 33/100\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 0.0353\n",
            "Epoch 34/100\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 0.0352\n",
            "Epoch 35/100\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 0.0349\n",
            "Epoch 36/100\n",
            "5/5 [==============================] - 0s 7ms/step - loss: 0.0351\n",
            "Epoch 37/100\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 0.0347\n",
            "Epoch 38/100\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.0347\n",
            "Epoch 39/100\n",
            "5/5 [==============================] - 0s 7ms/step - loss: 0.0344\n",
            "Epoch 40/100\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 0.0346\n",
            "Epoch 41/100\n",
            "5/5 [==============================] - 0s 7ms/step - loss: 0.0344\n",
            "Epoch 42/100\n",
            "5/5 [==============================] - 0s 7ms/step - loss: 0.0345\n",
            "Epoch 43/100\n",
            "5/5 [==============================] - 0s 7ms/step - loss: 0.0344\n",
            "Epoch 44/100\n",
            "5/5 [==============================] - 0s 7ms/step - loss: 0.0339\n",
            "Epoch 45/100\n",
            "5/5 [==============================] - 0s 7ms/step - loss: 0.0337\n",
            "Epoch 46/100\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 0.0341\n",
            "Epoch 47/100\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.0336\n",
            "Epoch 48/100\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 0.0335\n",
            "Epoch 49/100\n",
            "5/5 [==============================] - 0s 7ms/step - loss: 0.0335\n",
            "Epoch 50/100\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 0.0335\n",
            "Epoch 51/100\n",
            "5/5 [==============================] - 0s 7ms/step - loss: 0.0330\n",
            "Epoch 52/100\n",
            "5/5 [==============================] - 0s 7ms/step - loss: 0.0339\n",
            "Epoch 53/100\n",
            "5/5 [==============================] - 0s 7ms/step - loss: 0.0342\n",
            "Epoch 54/100\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 0.0331\n",
            "Epoch 55/100\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.0338\n",
            "Epoch 56/100\n",
            "5/5 [==============================] - 0s 7ms/step - loss: 0.0338\n",
            "Epoch 57/100\n",
            "5/5 [==============================] - 0s 7ms/step - loss: 0.0326\n",
            "Epoch 58/100\n",
            "5/5 [==============================] - 0s 7ms/step - loss: 0.0331\n",
            "Epoch 59/100\n",
            "5/5 [==============================] - 0s 7ms/step - loss: 0.0329\n",
            "Epoch 60/100\n",
            "5/5 [==============================] - 0s 7ms/step - loss: 0.0327\n",
            "Epoch 61/100\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 0.0326\n",
            "Epoch 62/100\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 0.0325\n",
            "Epoch 63/100\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 0.0326\n",
            "Epoch 64/100\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 0.0323\n",
            "Epoch 65/100\n",
            "5/5 [==============================] - 0s 7ms/step - loss: 0.0324\n",
            "Epoch 66/100\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 0.0324\n",
            "Epoch 67/100\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 0.0322\n",
            "Epoch 68/100\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 0.0326\n",
            "Epoch 69/100\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.0321\n",
            "Epoch 70/100\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 0.0321\n",
            "Epoch 71/100\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 0.0327\n",
            "Epoch 72/100\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 0.0320\n",
            "Epoch 73/100\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 0.0319\n",
            "Epoch 74/100\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 0.0327\n",
            "Epoch 75/100\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.0320\n",
            "Epoch 76/100\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 0.0319\n",
            "Epoch 77/100\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.0316\n",
            "Epoch 78/100\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.0316\n",
            "Epoch 79/100\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 0.0318\n",
            "Epoch 80/100\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 0.0315\n",
            "Epoch 81/100\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 0.0313\n",
            "Epoch 82/100\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 0.0315\n",
            "Epoch 83/100\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.0316\n",
            "Epoch 84/100\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 0.0312\n",
            "Epoch 85/100\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 0.0314\n",
            "Epoch 86/100\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 0.0313\n",
            "Epoch 87/100\n",
            "5/5 [==============================] - 0s 7ms/step - loss: 0.0311\n",
            "Epoch 88/100\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.0312\n",
            "Epoch 89/100\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 0.0309\n",
            "Epoch 90/100\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.0312\n",
            "Epoch 91/100\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 0.0311\n",
            "Epoch 92/100\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 0.0308\n",
            "Epoch 93/100\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 0.0310\n",
            "Epoch 94/100\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 0.0309\n",
            "Epoch 95/100\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 0.0312\n",
            "Epoch 96/100\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 0.0309\n",
            "Epoch 97/100\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 0.0308\n",
            "Epoch 98/100\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.0307\n",
            "Epoch 99/100\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 0.0307\n",
            "Epoch 100/100\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 0.0307\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Predicted prices from 2024-04-01 to 2028-12-01:\n",
            "2024-04-01: 2.729\n",
            "2024-05-01: 2.631\n",
            "2024-06-01: 2.534\n",
            "2024-07-01: 2.499\n",
            "2024-08-01: 2.445\n",
            "2024-09-01: 2.360\n",
            "2024-10-01: 2.296\n",
            "2024-11-01: 2.187\n",
            "2024-12-01: 2.048\n",
            "2025-01-01: 1.916\n",
            "2025-02-01: 1.864\n",
            "2025-03-01: 1.864\n",
            "2025-04-01: 1.864\n",
            "2025-05-01: 1.864\n",
            "2025-06-01: 1.864\n",
            "2025-07-01: 1.864\n",
            "2025-08-01: 1.864\n",
            "2025-09-01: 1.864\n",
            "2025-10-01: 1.864\n",
            "2025-11-01: 1.864\n",
            "2025-12-01: 1.864\n",
            "2026-01-01: 1.864\n",
            "2026-02-01: 1.864\n",
            "2026-03-01: 1.864\n",
            "2026-04-01: 1.864\n",
            "2026-05-01: 1.864\n",
            "2026-06-01: 1.864\n",
            "2026-07-01: 1.864\n",
            "2026-08-01: 1.864\n",
            "2026-09-01: 1.864\n",
            "2026-10-01: 1.864\n",
            "2026-11-01: 1.864\n",
            "2026-12-01: 1.864\n",
            "2027-01-01: 1.864\n",
            "2027-02-01: 1.864\n",
            "2027-03-01: 1.864\n",
            "2027-04-01: 1.864\n",
            "2027-05-01: 1.864\n",
            "2027-06-01: 1.864\n",
            "2027-07-01: 1.864\n",
            "2027-08-01: 1.864\n",
            "2027-09-01: 1.864\n",
            "2027-10-01: 1.864\n",
            "2027-11-01: 1.864\n",
            "2027-12-01: 1.864\n",
            "2028-01-01: 1.864\n",
            "2028-02-01: 1.864\n",
            "2028-03-01: 1.864\n",
            "2028-04-01: 1.864\n",
            "2028-05-01: 1.864\n",
            "2028-06-01: 1.864\n",
            "2028-07-01: 1.864\n",
            "2028-08-01: 1.864\n",
            "2028-09-01: 1.864\n",
            "2028-10-01: 1.864\n",
            "2028-11-01: 1.864\n",
            "2028-12-01: 1.864\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from datetime import datetime\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import LSTM, Dense\n",
        "from tensorflow.keras.activations import relu\n",
        "\n",
        "# Read the dataset\n",
        "df = pd.read_excel('LNG (High).xlsx')\n",
        "\n",
        "# Function to calculate the number of months between two dates\n",
        "def months_between(start_date, end_date):\n",
        "    start_date = datetime.strptime(start_date, \"%Y-%m-%d\")\n",
        "    end_date = datetime.strptime(end_date, \"%Y-%m-%d\")\n",
        "    return (end_date.year - start_date.year) * 12 + end_date.month - start_date.month + 1\n",
        "\n",
        "# Define the date range\n",
        "start_date = '2024-04-01'\n",
        "end_date = '2028-12-01'\n",
        "\n",
        "# Calculate the number of months to predict\n",
        "num_months = months_between(start_date, end_date)\n",
        "\n",
        "# Ensure data is sorted by date\n",
        "df['Date'] = pd.to_datetime(df['Date'], format='%b-%y')\n",
        "df = df.sort_values(by=\"Date\", ascending=True)\n",
        "\n",
        "# Normalize the data\n",
        "scaler = MinMaxScaler(feature_range=(0, 1))\n",
        "df['Price_normalized'] = scaler.fit_transform(df['Price'].values.reshape(-1,1))\n",
        "\n",
        "# Create a new feature representing the number of months since start date\n",
        "df['Months_since_start'] = (df['Date'] - pd.to_datetime(start_date)).dt.days / 30\n",
        "\n",
        "# Prepare data for training\n",
        "X_train = df['Months_since_start'].values.reshape(-1, 1, 1)\n",
        "y_train = df['Price_normalized'].values\n",
        "\n",
        "# Define and train the LSTM model\n",
        "model = Sequential()\n",
        "model.add(LSTM(128, activation='relu', input_shape=(1, 1)))\n",
        "model.add(Dense(64, activation='relu'))\n",
        "model.add(Dense(1, activation=relu))\n",
        "model.compile(optimizer='adam', loss='mean_squared_error')\n",
        "model.fit(X_train, y_train, epochs=100)\n",
        "\n",
        "# Generate future indices for prediction\n",
        "X_future = np.arange(df['Months_since_start'].iloc[-1] + 1, df['Months_since_start'].iloc[-1] + 1 + num_months)\n",
        "X_future = X_future.reshape(-1, 1, 1)  # Reshape for LSTM input\n",
        "\n",
        "# Generate predictions\n",
        "y_pred_normalized = model.predict(X_future)\n",
        "\n",
        "# Inverse transform predictions to get actual prices\n",
        "y_pred = scaler.inverse_transform(y_pred_normalized)\n",
        "\n",
        "# Ensure predictions are non-negative\n",
        "y_pred = np.maximum(y_pred, 0)\n",
        "\n",
        "# Generate date range for the predictions\n",
        "dates = pd.date_range(start=start_date, periods=num_months, freq='MS')\n",
        "\n",
        "# Print predicted prices with corresponding dates\n",
        "print(\"Predicted prices from 2024-04-01 to 2028-12-01:\")\n",
        "for date, price in zip(dates, y_pred.flatten()):\n",
        "    print(f\"{date.strftime('%Y-%m-%d')}: {price:.3f}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YxTFU2i901eZ",
        "outputId": "0df2297c-30e7-4f42-a601-63154b378568"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/200\n",
            "19/19 [==============================] - 4s 11ms/step - loss: 0.0555\n",
            "Epoch 2/200\n",
            "19/19 [==============================] - 0s 13ms/step - loss: 0.0386\n",
            "Epoch 3/200\n",
            "19/19 [==============================] - 0s 12ms/step - loss: 0.0266\n",
            "Epoch 4/200\n",
            "19/19 [==============================] - 0s 12ms/step - loss: 0.0217\n",
            "Epoch 5/200\n",
            "19/19 [==============================] - 0s 12ms/step - loss: 0.0219\n",
            "Epoch 6/200\n",
            "19/19 [==============================] - 0s 12ms/step - loss: 0.0176\n",
            "Epoch 7/200\n",
            "19/19 [==============================] - 0s 12ms/step - loss: 0.0174\n",
            "Epoch 8/200\n",
            "19/19 [==============================] - 0s 12ms/step - loss: 0.0183\n",
            "Epoch 9/200\n",
            "19/19 [==============================] - 0s 11ms/step - loss: 0.0159\n",
            "Epoch 10/200\n",
            "19/19 [==============================] - 0s 11ms/step - loss: 0.0196\n",
            "Epoch 11/200\n",
            "19/19 [==============================] - 0s 12ms/step - loss: 0.0233\n",
            "Epoch 12/200\n",
            "19/19 [==============================] - 0s 12ms/step - loss: 0.0161\n",
            "Epoch 13/200\n",
            "19/19 [==============================] - 0s 11ms/step - loss: 0.0152\n",
            "Epoch 14/200\n",
            "19/19 [==============================] - 0s 12ms/step - loss: 0.0142\n",
            "Epoch 15/200\n",
            "19/19 [==============================] - 0s 12ms/step - loss: 0.0157\n",
            "Epoch 16/200\n",
            "19/19 [==============================] - 0s 12ms/step - loss: 0.0145\n",
            "Epoch 17/200\n",
            "19/19 [==============================] - 0s 11ms/step - loss: 0.0143\n",
            "Epoch 18/200\n",
            "19/19 [==============================] - 0s 11ms/step - loss: 0.0155\n",
            "Epoch 19/200\n",
            "19/19 [==============================] - 0s 11ms/step - loss: 0.0160\n",
            "Epoch 20/200\n",
            "19/19 [==============================] - 0s 12ms/step - loss: 0.0142\n",
            "Epoch 21/200\n",
            "19/19 [==============================] - 0s 12ms/step - loss: 0.0134\n",
            "Epoch 22/200\n",
            "19/19 [==============================] - 0s 11ms/step - loss: 0.0196\n",
            "Epoch 23/200\n",
            "19/19 [==============================] - 0s 11ms/step - loss: 0.0166\n",
            "Epoch 24/200\n",
            "19/19 [==============================] - 0s 21ms/step - loss: 0.0134\n",
            "Epoch 25/200\n",
            "19/19 [==============================] - 0s 20ms/step - loss: 0.0152\n",
            "Epoch 26/200\n",
            "19/19 [==============================] - 0s 18ms/step - loss: 0.0179\n",
            "Epoch 27/200\n",
            "19/19 [==============================] - 0s 20ms/step - loss: 0.0137\n",
            "Epoch 28/200\n",
            "19/19 [==============================] - 0s 19ms/step - loss: 0.0217\n",
            "Epoch 29/200\n",
            "19/19 [==============================] - 0s 20ms/step - loss: 0.0145\n",
            "Epoch 30/200\n",
            "19/19 [==============================] - 0s 20ms/step - loss: 0.0129\n",
            "Epoch 31/200\n",
            "19/19 [==============================] - 0s 19ms/step - loss: 0.0121\n",
            "Epoch 32/200\n",
            "19/19 [==============================] - 0s 20ms/step - loss: 0.0133\n",
            "Epoch 33/200\n",
            "19/19 [==============================] - 0s 20ms/step - loss: 0.0151\n",
            "Epoch 34/200\n",
            "19/19 [==============================] - 0s 18ms/step - loss: 0.0180\n",
            "Epoch 35/200\n",
            "19/19 [==============================] - 0s 12ms/step - loss: 0.0140\n",
            "Epoch 36/200\n",
            "19/19 [==============================] - 0s 12ms/step - loss: 0.0138\n",
            "Epoch 37/200\n",
            "19/19 [==============================] - 0s 11ms/step - loss: 0.0141\n",
            "Epoch 38/200\n",
            "19/19 [==============================] - 0s 12ms/step - loss: 0.0126\n",
            "Epoch 39/200\n",
            "19/19 [==============================] - 0s 11ms/step - loss: 0.0136\n",
            "Epoch 40/200\n",
            "19/19 [==============================] - 0s 12ms/step - loss: 0.0120\n",
            "Epoch 41/200\n",
            "19/19 [==============================] - 0s 12ms/step - loss: 0.0142\n",
            "Epoch 42/200\n",
            "19/19 [==============================] - 0s 11ms/step - loss: 0.0123\n",
            "Epoch 43/200\n",
            "19/19 [==============================] - 0s 11ms/step - loss: 0.0131\n",
            "Epoch 44/200\n",
            "19/19 [==============================] - 0s 12ms/step - loss: 0.0163\n",
            "Epoch 45/200\n",
            "19/19 [==============================] - 0s 12ms/step - loss: 0.0229\n",
            "Epoch 46/200\n",
            "19/19 [==============================] - 0s 11ms/step - loss: 0.0140\n",
            "Epoch 47/200\n",
            "19/19 [==============================] - 0s 11ms/step - loss: 0.0121\n",
            "Epoch 48/200\n",
            "19/19 [==============================] - 0s 12ms/step - loss: 0.0119\n",
            "Epoch 49/200\n",
            "19/19 [==============================] - 0s 12ms/step - loss: 0.0117\n",
            "Epoch 50/200\n",
            "19/19 [==============================] - 0s 12ms/step - loss: 0.0115\n",
            "Epoch 51/200\n",
            "19/19 [==============================] - 0s 11ms/step - loss: 0.0136\n",
            "Epoch 52/200\n",
            "19/19 [==============================] - 0s 11ms/step - loss: 0.0120\n",
            "Epoch 53/200\n",
            "19/19 [==============================] - 0s 12ms/step - loss: 0.0125\n",
            "Epoch 54/200\n",
            "19/19 [==============================] - 0s 12ms/step - loss: 0.0112\n",
            "Epoch 55/200\n",
            "19/19 [==============================] - 0s 11ms/step - loss: 0.0101\n",
            "Epoch 56/200\n",
            "19/19 [==============================] - 0s 11ms/step - loss: 0.0144\n",
            "Epoch 57/200\n",
            "19/19 [==============================] - 0s 12ms/step - loss: 0.0117\n",
            "Epoch 58/200\n",
            "19/19 [==============================] - 0s 11ms/step - loss: 0.0120\n",
            "Epoch 59/200\n",
            "19/19 [==============================] - 0s 11ms/step - loss: 0.0110\n",
            "Epoch 60/200\n",
            "19/19 [==============================] - 0s 12ms/step - loss: 0.0132\n",
            "Epoch 61/200\n",
            "19/19 [==============================] - 0s 12ms/step - loss: 0.0119\n",
            "Epoch 62/200\n",
            "19/19 [==============================] - 0s 11ms/step - loss: 0.0097\n",
            "Epoch 63/200\n",
            "19/19 [==============================] - 0s 12ms/step - loss: 0.0104\n",
            "Epoch 64/200\n",
            "19/19 [==============================] - 0s 11ms/step - loss: 0.0106\n",
            "Epoch 65/200\n",
            "19/19 [==============================] - 0s 12ms/step - loss: 0.0111\n",
            "Epoch 66/200\n",
            "19/19 [==============================] - 0s 12ms/step - loss: 0.0098\n",
            "Epoch 67/200\n",
            "19/19 [==============================] - 0s 13ms/step - loss: 0.0107\n",
            "Epoch 68/200\n",
            "19/19 [==============================] - 0s 12ms/step - loss: 0.0161\n",
            "Epoch 69/200\n",
            "19/19 [==============================] - 0s 11ms/step - loss: 0.0240\n",
            "Epoch 70/200\n",
            "19/19 [==============================] - 0s 11ms/step - loss: 0.0195\n",
            "Epoch 71/200\n",
            "19/19 [==============================] - 0s 12ms/step - loss: 0.0123\n",
            "Epoch 72/200\n",
            "19/19 [==============================] - 0s 12ms/step - loss: 0.0097\n",
            "Epoch 73/200\n",
            "19/19 [==============================] - 0s 11ms/step - loss: 0.0094\n",
            "Epoch 74/200\n",
            "19/19 [==============================] - 0s 11ms/step - loss: 0.0089\n",
            "Epoch 75/200\n",
            "19/19 [==============================] - 0s 11ms/step - loss: 0.0095\n",
            "Epoch 76/200\n",
            "19/19 [==============================] - 0s 11ms/step - loss: 0.0096\n",
            "Epoch 77/200\n",
            "19/19 [==============================] - 0s 12ms/step - loss: 0.0095\n",
            "Epoch 78/200\n",
            "19/19 [==============================] - 0s 16ms/step - loss: 0.0084\n",
            "Epoch 79/200\n",
            "19/19 [==============================] - 0s 19ms/step - loss: 0.0102\n",
            "Epoch 80/200\n",
            "19/19 [==============================] - 0s 19ms/step - loss: 0.0090\n",
            "Epoch 81/200\n",
            "19/19 [==============================] - 0s 19ms/step - loss: 0.0169\n",
            "Epoch 82/200\n",
            "19/19 [==============================] - 0s 19ms/step - loss: 0.0111\n",
            "Epoch 83/200\n",
            "19/19 [==============================] - 0s 21ms/step - loss: 0.0092\n",
            "Epoch 84/200\n",
            "19/19 [==============================] - 0s 21ms/step - loss: 0.0097\n",
            "Epoch 85/200\n",
            "19/19 [==============================] - 0s 21ms/step - loss: 0.0086\n",
            "Epoch 86/200\n",
            "19/19 [==============================] - 0s 21ms/step - loss: 0.0078\n",
            "Epoch 87/200\n",
            "19/19 [==============================] - 0s 20ms/step - loss: 0.0094\n",
            "Epoch 88/200\n",
            "19/19 [==============================] - 0s 20ms/step - loss: 0.0082\n",
            "Epoch 89/200\n",
            "19/19 [==============================] - 0s 16ms/step - loss: 0.0089\n",
            "Epoch 90/200\n",
            "19/19 [==============================] - 0s 11ms/step - loss: 0.0099\n",
            "Epoch 91/200\n",
            "19/19 [==============================] - 0s 11ms/step - loss: 0.0109\n",
            "Epoch 92/200\n",
            "19/19 [==============================] - 0s 12ms/step - loss: 0.0106\n",
            "Epoch 93/200\n",
            "19/19 [==============================] - 0s 11ms/step - loss: 0.0096\n",
            "Epoch 94/200\n",
            "19/19 [==============================] - 0s 11ms/step - loss: 0.0104\n",
            "Epoch 95/200\n",
            "19/19 [==============================] - 0s 11ms/step - loss: 0.0091\n",
            "Epoch 96/200\n",
            "19/19 [==============================] - 0s 12ms/step - loss: 0.0089\n",
            "Epoch 97/200\n",
            "19/19 [==============================] - 0s 13ms/step - loss: 0.0079\n",
            "Epoch 98/200\n",
            "19/19 [==============================] - 0s 12ms/step - loss: 0.0080\n",
            "Epoch 99/200\n",
            "19/19 [==============================] - 0s 11ms/step - loss: 0.0076\n",
            "Epoch 100/200\n",
            "19/19 [==============================] - 0s 11ms/step - loss: 0.0081\n",
            "Epoch 101/200\n",
            "19/19 [==============================] - 0s 12ms/step - loss: 0.0080\n",
            "Epoch 102/200\n",
            "19/19 [==============================] - 0s 12ms/step - loss: 0.0074\n",
            "Epoch 103/200\n",
            "19/19 [==============================] - 0s 11ms/step - loss: 0.0079\n",
            "Epoch 104/200\n",
            "19/19 [==============================] - 0s 11ms/step - loss: 0.0070\n",
            "Epoch 105/200\n",
            "19/19 [==============================] - 0s 11ms/step - loss: 0.0083\n",
            "Epoch 106/200\n",
            "19/19 [==============================] - 0s 12ms/step - loss: 0.0074\n",
            "Epoch 107/200\n",
            "19/19 [==============================] - 0s 12ms/step - loss: 0.0073\n",
            "Epoch 108/200\n",
            "19/19 [==============================] - 0s 11ms/step - loss: 0.0078\n",
            "Epoch 109/200\n",
            "19/19 [==============================] - 0s 11ms/step - loss: 0.0083\n",
            "Epoch 110/200\n",
            "19/19 [==============================] - 0s 11ms/step - loss: 0.0083\n",
            "Epoch 111/200\n",
            "19/19 [==============================] - 0s 12ms/step - loss: 0.0074\n",
            "Epoch 112/200\n",
            "19/19 [==============================] - 0s 12ms/step - loss: 0.0074\n",
            "Epoch 113/200\n",
            "19/19 [==============================] - 0s 11ms/step - loss: 0.0091\n",
            "Epoch 114/200\n",
            "19/19 [==============================] - 0s 19ms/step - loss: 0.0083\n",
            "Epoch 115/200\n",
            "19/19 [==============================] - 0s 26ms/step - loss: 0.0084\n",
            "Epoch 116/200\n",
            "19/19 [==============================] - 0s 22ms/step - loss: 0.0080\n",
            "Epoch 117/200\n",
            "19/19 [==============================] - 0s 26ms/step - loss: 0.0075\n",
            "Epoch 118/200\n",
            "19/19 [==============================] - 0s 20ms/step - loss: 0.0133\n",
            "Epoch 119/200\n",
            "19/19 [==============================] - 0s 26ms/step - loss: 0.0091\n",
            "Epoch 120/200\n",
            "19/19 [==============================] - 0s 18ms/step - loss: 0.0076\n",
            "Epoch 121/200\n",
            "19/19 [==============================] - 0s 19ms/step - loss: 0.0082\n",
            "Epoch 122/200\n",
            "19/19 [==============================] - 0s 22ms/step - loss: 0.0079\n",
            "Epoch 123/200\n",
            "19/19 [==============================] - 0s 19ms/step - loss: 0.0097\n",
            "Epoch 124/200\n",
            "19/19 [==============================] - 0s 22ms/step - loss: 0.0071\n",
            "Epoch 125/200\n",
            "19/19 [==============================] - 0s 24ms/step - loss: 0.0078\n",
            "Epoch 126/200\n",
            "19/19 [==============================] - 1s 37ms/step - loss: 0.0086\n",
            "Epoch 127/200\n",
            "19/19 [==============================] - 1s 30ms/step - loss: 0.0078\n",
            "Epoch 128/200\n",
            "19/19 [==============================] - 1s 34ms/step - loss: 0.0081\n",
            "Epoch 129/200\n",
            "19/19 [==============================] - 1s 29ms/step - loss: 0.0072\n",
            "Epoch 130/200\n",
            "19/19 [==============================] - 1s 41ms/step - loss: 0.0095\n",
            "Epoch 131/200\n",
            "19/19 [==============================] - 1s 36ms/step - loss: 0.0078\n",
            "Epoch 132/200\n",
            "19/19 [==============================] - 0s 15ms/step - loss: 0.0075\n",
            "Epoch 133/200\n",
            "19/19 [==============================] - 0s 11ms/step - loss: 0.0077\n",
            "Epoch 134/200\n",
            "19/19 [==============================] - 0s 11ms/step - loss: 0.0074\n",
            "Epoch 135/200\n",
            "19/19 [==============================] - 0s 12ms/step - loss: 0.0073\n",
            "Epoch 136/200\n",
            "19/19 [==============================] - 0s 11ms/step - loss: 0.0077\n",
            "Epoch 137/200\n",
            "19/19 [==============================] - 0s 12ms/step - loss: 0.0082\n",
            "Epoch 138/200\n",
            "19/19 [==============================] - 0s 12ms/step - loss: 0.0105\n",
            "Epoch 139/200\n",
            "19/19 [==============================] - 0s 12ms/step - loss: 0.0105\n",
            "Epoch 140/200\n",
            "19/19 [==============================] - 0s 11ms/step - loss: 0.0086\n",
            "Epoch 141/200\n",
            "19/19 [==============================] - 0s 11ms/step - loss: 0.0081\n",
            "Epoch 142/200\n",
            "19/19 [==============================] - 0s 11ms/step - loss: 0.0079\n",
            "Epoch 143/200\n",
            "19/19 [==============================] - 0s 12ms/step - loss: 0.0083\n",
            "Epoch 144/200\n",
            "19/19 [==============================] - 0s 12ms/step - loss: 0.0091\n",
            "Epoch 145/200\n",
            "19/19 [==============================] - 0s 11ms/step - loss: 0.0078\n",
            "Epoch 146/200\n",
            "19/19 [==============================] - 0s 11ms/step - loss: 0.0073\n",
            "Epoch 147/200\n",
            "19/19 [==============================] - 0s 12ms/step - loss: 0.0079\n",
            "Epoch 148/200\n",
            "19/19 [==============================] - 0s 11ms/step - loss: 0.0082\n",
            "Epoch 149/200\n",
            "19/19 [==============================] - 0s 11ms/step - loss: 0.0088\n",
            "Epoch 150/200\n",
            "19/19 [==============================] - 0s 11ms/step - loss: 0.0076\n",
            "Epoch 151/200\n",
            "19/19 [==============================] - 0s 11ms/step - loss: 0.0086\n",
            "Epoch 152/200\n",
            "19/19 [==============================] - 0s 12ms/step - loss: 0.0084\n",
            "Epoch 153/200\n",
            "19/19 [==============================] - 0s 12ms/step - loss: 0.0072\n",
            "Epoch 154/200\n",
            "19/19 [==============================] - 0s 11ms/step - loss: 0.0089\n",
            "Epoch 155/200\n",
            "19/19 [==============================] - 0s 12ms/step - loss: 0.0079\n",
            "Epoch 156/200\n",
            "19/19 [==============================] - 0s 11ms/step - loss: 0.0073\n",
            "Epoch 157/200\n",
            "19/19 [==============================] - 0s 11ms/step - loss: 0.0080\n",
            "Epoch 158/200\n",
            "19/19 [==============================] - 0s 11ms/step - loss: 0.0077\n",
            "Epoch 159/200\n",
            "19/19 [==============================] - 0s 11ms/step - loss: 0.0094\n",
            "Epoch 160/200\n",
            "19/19 [==============================] - 0s 12ms/step - loss: 0.0080\n",
            "Epoch 161/200\n",
            "19/19 [==============================] - 0s 11ms/step - loss: 0.0079\n",
            "Epoch 162/200\n",
            "19/19 [==============================] - 0s 13ms/step - loss: 0.0073\n",
            "Epoch 163/200\n",
            "19/19 [==============================] - 0s 11ms/step - loss: 0.0072\n",
            "Epoch 164/200\n",
            "19/19 [==============================] - 0s 11ms/step - loss: 0.0069\n",
            "Epoch 165/200\n",
            "19/19 [==============================] - 0s 13ms/step - loss: 0.0079\n",
            "Epoch 166/200\n",
            "19/19 [==============================] - 0s 11ms/step - loss: 0.0084\n",
            "Epoch 167/200\n",
            "19/19 [==============================] - 0s 12ms/step - loss: 0.0074\n",
            "Epoch 168/200\n",
            "19/19 [==============================] - 0s 12ms/step - loss: 0.0067\n",
            "Epoch 169/200\n",
            "19/19 [==============================] - 0s 12ms/step - loss: 0.0071\n",
            "Epoch 170/200\n",
            "19/19 [==============================] - 0s 13ms/step - loss: 0.0069\n",
            "Epoch 171/200\n",
            "19/19 [==============================] - 0s 12ms/step - loss: 0.0072\n",
            "Epoch 172/200\n",
            "19/19 [==============================] - 0s 12ms/step - loss: 0.0069\n",
            "Epoch 173/200\n",
            "19/19 [==============================] - 0s 12ms/step - loss: 0.0077\n",
            "Epoch 174/200\n",
            "19/19 [==============================] - 0s 12ms/step - loss: 0.0076\n",
            "Epoch 175/200\n",
            "19/19 [==============================] - 0s 18ms/step - loss: 0.0081\n",
            "Epoch 176/200\n",
            "19/19 [==============================] - 0s 19ms/step - loss: 0.0070\n",
            "Epoch 177/200\n",
            "19/19 [==============================] - 0s 19ms/step - loss: 0.0085\n",
            "Epoch 178/200\n",
            "19/19 [==============================] - 0s 19ms/step - loss: 0.0096\n",
            "Epoch 179/200\n",
            "19/19 [==============================] - 0s 19ms/step - loss: 0.0082\n",
            "Epoch 180/200\n",
            "19/19 [==============================] - 0s 20ms/step - loss: 0.0084\n",
            "Epoch 181/200\n",
            "19/19 [==============================] - 0s 21ms/step - loss: 0.0069\n",
            "Epoch 182/200\n",
            "19/19 [==============================] - 0s 20ms/step - loss: 0.0067\n",
            "Epoch 183/200\n",
            "19/19 [==============================] - 0s 19ms/step - loss: 0.0072\n",
            "Epoch 184/200\n",
            "19/19 [==============================] - 0s 20ms/step - loss: 0.0078\n",
            "Epoch 185/200\n",
            "19/19 [==============================] - 0s 16ms/step - loss: 0.0081\n",
            "Epoch 186/200\n",
            "19/19 [==============================] - 0s 11ms/step - loss: 0.0110\n",
            "Epoch 187/200\n",
            "19/19 [==============================] - 0s 12ms/step - loss: 0.0106\n",
            "Epoch 188/200\n",
            "19/19 [==============================] - 0s 12ms/step - loss: 0.0096\n",
            "Epoch 189/200\n",
            "19/19 [==============================] - 0s 12ms/step - loss: 0.0078\n",
            "Epoch 190/200\n",
            "19/19 [==============================] - 0s 11ms/step - loss: 0.0069\n",
            "Epoch 191/200\n",
            "19/19 [==============================] - 0s 12ms/step - loss: 0.0068\n",
            "Epoch 192/200\n",
            "19/19 [==============================] - 0s 12ms/step - loss: 0.0090\n",
            "Epoch 193/200\n",
            "19/19 [==============================] - 0s 12ms/step - loss: 0.0088\n",
            "Epoch 194/200\n",
            "19/19 [==============================] - 0s 12ms/step - loss: 0.0085\n",
            "Epoch 195/200\n",
            "19/19 [==============================] - 0s 12ms/step - loss: 0.0081\n",
            "Epoch 196/200\n",
            "19/19 [==============================] - 0s 13ms/step - loss: 0.0073\n",
            "Epoch 197/200\n",
            "19/19 [==============================] - 0s 11ms/step - loss: 0.0069\n",
            "Epoch 198/200\n",
            "19/19 [==============================] - 0s 12ms/step - loss: 0.0072\n",
            "Epoch 199/200\n",
            "19/19 [==============================] - 0s 12ms/step - loss: 0.0083\n",
            "Epoch 200/200\n",
            "19/19 [==============================] - 0s 13ms/step - loss: 0.0085\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Predicted prices from 2024-04-01 to 2028-12-01:\n",
            "2024-04-01: 2.638\n",
            "2024-05-01: 2.627\n",
            "2024-06-01: 2.605\n",
            "2024-07-01: 2.611\n",
            "2024-08-01: 2.656\n",
            "2024-09-01: 2.701\n",
            "2024-10-01: 2.747\n",
            "2024-11-01: 2.797\n",
            "2024-12-01: 2.848\n",
            "2025-01-01: 2.885\n",
            "2025-02-01: 2.921\n",
            "2025-03-01: 2.959\n",
            "2025-04-01: 2.981\n",
            "2025-05-01: 2.999\n",
            "2025-06-01: 3.025\n",
            "2025-07-01: 3.055\n",
            "2025-08-01: 3.086\n",
            "2025-09-01: 3.119\n",
            "2025-10-01: 3.153\n",
            "2025-11-01: 3.188\n",
            "2025-12-01: 3.226\n",
            "2026-01-01: 3.268\n",
            "2026-02-01: 3.314\n",
            "2026-03-01: 3.362\n",
            "2026-04-01: 3.413\n",
            "2026-05-01: 3.465\n",
            "2026-06-01: 3.519\n",
            "2026-07-01: 3.575\n",
            "2026-08-01: 3.629\n",
            "2026-09-01: 3.684\n",
            "2026-10-01: 3.744\n",
            "2026-11-01: 3.808\n",
            "2026-12-01: 3.875\n",
            "2027-01-01: 3.942\n",
            "2027-02-01: 4.011\n",
            "2027-03-01: 4.081\n",
            "2027-04-01: 4.152\n",
            "2027-05-01: 4.224\n",
            "2027-06-01: 4.296\n",
            "2027-07-01: 4.369\n",
            "2027-08-01: 4.443\n",
            "2027-09-01: 4.510\n",
            "2027-10-01: 4.572\n",
            "2027-11-01: 4.634\n",
            "2027-12-01: 4.695\n",
            "2028-01-01: 4.757\n",
            "2028-02-01: 4.818\n",
            "2028-03-01: 4.878\n",
            "2028-04-01: 4.938\n",
            "2028-05-01: 4.998\n",
            "2028-06-01: 5.057\n",
            "2028-07-01: 5.115\n",
            "2028-08-01: 5.172\n",
            "2028-09-01: 5.229\n",
            "2028-10-01: 5.286\n",
            "2028-11-01: 5.341\n",
            "2028-12-01: 5.396\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from datetime import datetime\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import LSTM, Dense\n",
        "\n",
        "# Read the dataset\n",
        "df = pd.read_excel('LNG (High).xlsx')\n",
        "\n",
        "# Function to calculate the number of months between two dates\n",
        "def months_between(start_date, end_date):\n",
        "    start_date = datetime.strptime(start_date, \"%Y-%m-%d\")\n",
        "    end_date = datetime.strptime(end_date, \"%Y-%m-%d\")\n",
        "    return (end_date.year - start_date.year) * 12 + end_date.month - start_date.month + 1\n",
        "\n",
        "# Define the date range\n",
        "start_date = '2024-04-01'\n",
        "end_date = '2028-12-01'\n",
        "\n",
        "# Calculate the number of months to predict\n",
        "num_months = months_between(start_date, end_date)\n",
        "\n",
        "# Ensure data is sorted by date\n",
        "df['Date'] = pd.to_datetime(df['Date'], format='%b-%y')\n",
        "df = df.sort_values(by=\"Date\", ascending=True)\n",
        "\n",
        "# Normalize the data\n",
        "scaler = MinMaxScaler(feature_range=(0, 1))\n",
        "df['Price_normalized'] = scaler.fit_transform(df['Price'].values.reshape(-1,1))\n",
        "\n",
        "# Create a new feature representing the number of months since start date\n",
        "df['Months_since_start'] = (df['Date'] - pd.to_datetime(start_date)).dt.days / 30\n",
        "\n",
        "# Prepare data for training\n",
        "X_train = df['Months_since_start'].values.reshape(-1, 1, 1)\n",
        "y_train = df['Price_normalized'].values\n",
        "\n",
        "# Define and train the LSTM model\n",
        "model = Sequential()\n",
        "model.add(LSTM(256, activation='relu', return_sequences=True, input_shape=(1, 1)))\n",
        "model.add(LSTM(128, activation='relu', return_sequences=True))\n",
        "model.add(LSTM(64, activation='relu'))\n",
        "model.add(Dense(32, activation='relu'))\n",
        "model.add(Dense(1, activation='relu'))\n",
        "model.compile(optimizer='adam', loss='mean_squared_error')\n",
        "model.fit(X_train, y_train, epochs=200, batch_size=8)\n",
        "\n",
        "# Generate future indices for prediction\n",
        "X_future = np.arange(df['Months_since_start'].iloc[-1] + 1, df['Months_since_start'].iloc[-1] + 1 + num_months)\n",
        "X_future = X_future.reshape(-1, 1, 1)  # Reshape for LSTM input\n",
        "\n",
        "# Generate predictions\n",
        "y_pred_normalized = model.predict(X_future)\n",
        "\n",
        "# Inverse transform predictions to get actual prices\n",
        "y_pred = scaler.inverse_transform(y_pred_normalized)\n",
        "\n",
        "# Ensure predictions are non-negative\n",
        "y_pred = np.maximum(y_pred, 0)\n",
        "\n",
        "# Generate date range for the predictions\n",
        "dates = pd.date_range(start=start_date, periods=num_months, freq='MS')\n",
        "\n",
        "# Print predicted prices with corresponding dates\n",
        "print(\"Predicted prices from 2024-04-01 to 2028-12-01:\")\n",
        "for date, price in zip(dates, y_pred.flatten()):\n",
        "    print(f\"{date.strftime('%Y-%m-%d')}: {price:.3f}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "p2WTe4Q618ca",
        "outputId": "4cf572d6-4dea-45f2-98ce-c84985fb15ee"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/200\n",
            "19/19 [==============================] - 7s 12ms/step - loss: 0.0896\n",
            "Epoch 2/200\n",
            "19/19 [==============================] - 0s 12ms/step - loss: 0.0896\n",
            "Epoch 3/200\n",
            "19/19 [==============================] - 0s 12ms/step - loss: 0.0896\n",
            "Epoch 4/200\n",
            "19/19 [==============================] - 0s 12ms/step - loss: 0.0896\n",
            "Epoch 5/200\n",
            "19/19 [==============================] - 0s 11ms/step - loss: 0.0896\n",
            "Epoch 6/200\n",
            "19/19 [==============================] - 0s 11ms/step - loss: 0.0896\n",
            "Epoch 7/200\n",
            "19/19 [==============================] - 0s 11ms/step - loss: 0.0896\n",
            "Epoch 8/200\n",
            "19/19 [==============================] - 0s 12ms/step - loss: 0.0896\n",
            "Epoch 9/200\n",
            "19/19 [==============================] - 0s 12ms/step - loss: 0.0896\n",
            "Epoch 10/200\n",
            "19/19 [==============================] - 0s 11ms/step - loss: 0.0896\n",
            "Epoch 11/200\n",
            "19/19 [==============================] - 0s 11ms/step - loss: 0.0896\n",
            "Epoch 12/200\n",
            "19/19 [==============================] - 0s 12ms/step - loss: 0.0896\n",
            "Epoch 13/200\n",
            "19/19 [==============================] - 0s 12ms/step - loss: 0.0896\n",
            "Epoch 14/200\n",
            "19/19 [==============================] - 0s 11ms/step - loss: 0.0896\n",
            "Epoch 15/200\n",
            "19/19 [==============================] - 0s 12ms/step - loss: 0.0896\n",
            "Epoch 16/200\n",
            "19/19 [==============================] - 0s 11ms/step - loss: 0.0896\n",
            "Epoch 17/200\n",
            "19/19 [==============================] - 0s 12ms/step - loss: 0.0896\n",
            "Epoch 18/200\n",
            "19/19 [==============================] - 0s 12ms/step - loss: 0.0896\n",
            "Epoch 19/200\n",
            "19/19 [==============================] - 0s 11ms/step - loss: 0.0896\n",
            "Epoch 20/200\n",
            "19/19 [==============================] - 0s 11ms/step - loss: 0.0896\n",
            "Epoch 21/200\n",
            "19/19 [==============================] - 0s 11ms/step - loss: 0.0896\n",
            "Epoch 22/200\n",
            "19/19 [==============================] - 0s 12ms/step - loss: 0.0896\n",
            "Epoch 23/200\n",
            "19/19 [==============================] - 0s 11ms/step - loss: 0.0896\n",
            "Epoch 24/200\n",
            "19/19 [==============================] - 0s 11ms/step - loss: 0.0896\n",
            "Epoch 25/200\n",
            "19/19 [==============================] - 0s 13ms/step - loss: 0.0896\n",
            "Epoch 26/200\n",
            "19/19 [==============================] - 0s 11ms/step - loss: 0.0896\n",
            "Epoch 27/200\n",
            "19/19 [==============================] - 0s 13ms/step - loss: 0.0896\n",
            "Epoch 28/200\n",
            "19/19 [==============================] - 0s 12ms/step - loss: 0.0896\n",
            "Epoch 29/200\n",
            "19/19 [==============================] - 0s 12ms/step - loss: 0.0896\n",
            "Epoch 30/200\n",
            "19/19 [==============================] - 0s 11ms/step - loss: 0.0896\n",
            "Epoch 31/200\n",
            "19/19 [==============================] - 0s 11ms/step - loss: 0.0896\n",
            "Epoch 32/200\n",
            "19/19 [==============================] - 0s 12ms/step - loss: 0.0896\n",
            "Epoch 33/200\n",
            "19/19 [==============================] - 0s 11ms/step - loss: 0.0896\n",
            "Epoch 34/200\n",
            "19/19 [==============================] - 0s 11ms/step - loss: 0.0896\n",
            "Epoch 35/200\n",
            "19/19 [==============================] - 0s 11ms/step - loss: 0.0896\n",
            "Epoch 36/200\n",
            "19/19 [==============================] - 0s 12ms/step - loss: 0.0896\n",
            "Epoch 37/200\n",
            "19/19 [==============================] - 0s 11ms/step - loss: 0.0896\n",
            "Epoch 38/200\n",
            "19/19 [==============================] - 0s 21ms/step - loss: 0.0896\n",
            "Epoch 39/200\n",
            "19/19 [==============================] - 0s 20ms/step - loss: 0.0896\n",
            "Epoch 40/200\n",
            "19/19 [==============================] - 0s 20ms/step - loss: 0.0896\n",
            "Epoch 41/200\n",
            "19/19 [==============================] - 0s 19ms/step - loss: 0.0896\n",
            "Epoch 42/200\n",
            "19/19 [==============================] - 0s 19ms/step - loss: 0.0896\n",
            "Epoch 43/200\n",
            "19/19 [==============================] - 0s 20ms/step - loss: 0.0896\n",
            "Epoch 44/200\n",
            "19/19 [==============================] - 0s 20ms/step - loss: 0.0896\n",
            "Epoch 45/200\n",
            "19/19 [==============================] - 0s 19ms/step - loss: 0.0896\n",
            "Epoch 46/200\n",
            "19/19 [==============================] - 0s 20ms/step - loss: 0.0896\n",
            "Epoch 47/200\n",
            "19/19 [==============================] - 0s 20ms/step - loss: 0.0896\n",
            "Epoch 48/200\n",
            "19/19 [==============================] - 0s 18ms/step - loss: 0.0896\n",
            "Epoch 49/200\n",
            "19/19 [==============================] - 0s 11ms/step - loss: 0.0896\n",
            "Epoch 50/200\n",
            "19/19 [==============================] - 0s 11ms/step - loss: 0.0896\n",
            "Epoch 51/200\n",
            "19/19 [==============================] - 0s 11ms/step - loss: 0.0896\n",
            "Epoch 52/200\n",
            "19/19 [==============================] - 0s 12ms/step - loss: 0.0896\n",
            "Epoch 53/200\n",
            "19/19 [==============================] - 0s 11ms/step - loss: 0.0896\n",
            "Epoch 54/200\n",
            "19/19 [==============================] - 0s 12ms/step - loss: 0.0896\n",
            "Epoch 55/200\n",
            "19/19 [==============================] - 0s 11ms/step - loss: 0.0896\n",
            "Epoch 56/200\n",
            "19/19 [==============================] - 0s 11ms/step - loss: 0.0896\n",
            "Epoch 57/200\n",
            "19/19 [==============================] - 0s 11ms/step - loss: 0.0896\n",
            "Epoch 58/200\n",
            "19/19 [==============================] - 0s 12ms/step - loss: 0.0896\n",
            "Epoch 59/200\n",
            "19/19 [==============================] - 0s 11ms/step - loss: 0.0896\n",
            "Epoch 60/200\n",
            "19/19 [==============================] - 0s 11ms/step - loss: 0.0896\n",
            "Epoch 61/200\n",
            "19/19 [==============================] - 0s 12ms/step - loss: 0.0896\n",
            "Epoch 62/200\n",
            "19/19 [==============================] - 0s 12ms/step - loss: 0.0896\n",
            "Epoch 63/200\n",
            "19/19 [==============================] - 0s 11ms/step - loss: 0.0896\n",
            "Epoch 64/200\n",
            "19/19 [==============================] - 0s 11ms/step - loss: 0.0896\n",
            "Epoch 65/200\n",
            "19/19 [==============================] - 0s 11ms/step - loss: 0.0896\n",
            "Epoch 66/200\n",
            "19/19 [==============================] - 0s 12ms/step - loss: 0.0896\n",
            "Epoch 67/200\n",
            "19/19 [==============================] - 0s 11ms/step - loss: 0.0896\n",
            "Epoch 68/200\n",
            "19/19 [==============================] - 0s 11ms/step - loss: 0.0896\n",
            "Epoch 69/200\n",
            "19/19 [==============================] - 0s 12ms/step - loss: 0.0896\n",
            "Epoch 70/200\n",
            "19/19 [==============================] - 0s 12ms/step - loss: 0.0896\n",
            "Epoch 71/200\n",
            "19/19 [==============================] - 0s 11ms/step - loss: 0.0896\n",
            "Epoch 72/200\n",
            "19/19 [==============================] - 0s 11ms/step - loss: 0.0896\n",
            "Epoch 73/200\n",
            "19/19 [==============================] - 0s 11ms/step - loss: 0.0896\n",
            "Epoch 74/200\n",
            "19/19 [==============================] - 0s 11ms/step - loss: 0.0896\n",
            "Epoch 75/200\n",
            "19/19 [==============================] - 0s 12ms/step - loss: 0.0896\n",
            "Epoch 76/200\n",
            "19/19 [==============================] - 0s 11ms/step - loss: 0.0896\n",
            "Epoch 77/200\n",
            "19/19 [==============================] - 0s 11ms/step - loss: 0.0896\n",
            "Epoch 78/200\n",
            "19/19 [==============================] - 0s 12ms/step - loss: 0.0896\n",
            "Epoch 79/200\n",
            "19/19 [==============================] - 0s 11ms/step - loss: 0.0896\n",
            "Epoch 80/200\n",
            "19/19 [==============================] - 0s 12ms/step - loss: 0.0896\n",
            "Epoch 81/200\n",
            "19/19 [==============================] - 0s 11ms/step - loss: 0.0896\n",
            "Epoch 82/200\n",
            "19/19 [==============================] - 0s 11ms/step - loss: 0.0896\n",
            "Epoch 83/200\n",
            "19/19 [==============================] - 0s 11ms/step - loss: 0.0896\n",
            "Epoch 84/200\n",
            "19/19 [==============================] - 0s 12ms/step - loss: 0.0896\n",
            "Epoch 85/200\n",
            "19/19 [==============================] - 0s 11ms/step - loss: 0.0896\n",
            "Epoch 86/200\n",
            "19/19 [==============================] - 0s 11ms/step - loss: 0.0896\n",
            "Epoch 87/200\n",
            "19/19 [==============================] - 0s 11ms/step - loss: 0.0896\n",
            "Epoch 88/200\n",
            "19/19 [==============================] - 0s 11ms/step - loss: 0.0896\n",
            "Epoch 89/200\n",
            "19/19 [==============================] - 0s 12ms/step - loss: 0.0896\n",
            "Epoch 90/200\n",
            "19/19 [==============================] - 0s 11ms/step - loss: 0.0896\n",
            "Epoch 91/200\n",
            "19/19 [==============================] - 0s 11ms/step - loss: 0.0896\n",
            "Epoch 92/200\n",
            "19/19 [==============================] - 0s 11ms/step - loss: 0.0896\n",
            "Epoch 93/200\n",
            "19/19 [==============================] - 0s 17ms/step - loss: 0.0896\n",
            "Epoch 94/200\n",
            "19/19 [==============================] - 0s 20ms/step - loss: 0.0896\n",
            "Epoch 95/200\n",
            "19/19 [==============================] - 0s 20ms/step - loss: 0.0896\n",
            "Epoch 96/200\n",
            "19/19 [==============================] - 0s 19ms/step - loss: 0.0896\n",
            "Epoch 97/200\n",
            "19/19 [==============================] - 0s 19ms/step - loss: 0.0896\n",
            "Epoch 98/200\n",
            "19/19 [==============================] - 0s 19ms/step - loss: 0.0896\n",
            "Epoch 99/200\n",
            "19/19 [==============================] - 0s 22ms/step - loss: 0.0896\n",
            "Epoch 100/200\n",
            "19/19 [==============================] - 0s 19ms/step - loss: 0.0896\n",
            "Epoch 101/200\n",
            "19/19 [==============================] - 0s 20ms/step - loss: 0.0896\n",
            "Epoch 102/200\n",
            "19/19 [==============================] - 0s 19ms/step - loss: 0.0896\n",
            "Epoch 103/200\n",
            "19/19 [==============================] - 0s 20ms/step - loss: 0.0896\n",
            "Epoch 104/200\n",
            "19/19 [==============================] - 0s 16ms/step - loss: 0.0896\n",
            "Epoch 105/200\n",
            "19/19 [==============================] - 0s 13ms/step - loss: 0.0896\n",
            "Epoch 106/200\n",
            "19/19 [==============================] - 0s 12ms/step - loss: 0.0896\n",
            "Epoch 107/200\n",
            "19/19 [==============================] - 0s 12ms/step - loss: 0.0896\n",
            "Epoch 108/200\n",
            "19/19 [==============================] - 0s 11ms/step - loss: 0.0896\n",
            "Epoch 109/200\n",
            "19/19 [==============================] - 0s 12ms/step - loss: 0.0896\n",
            "Epoch 110/200\n",
            "19/19 [==============================] - 0s 11ms/step - loss: 0.0896\n",
            "Epoch 111/200\n",
            "19/19 [==============================] - 0s 11ms/step - loss: 0.0896\n",
            "Epoch 112/200\n",
            "19/19 [==============================] - 0s 11ms/step - loss: 0.0896\n",
            "Epoch 113/200\n",
            "19/19 [==============================] - 0s 11ms/step - loss: 0.0896\n",
            "Epoch 114/200\n",
            "19/19 [==============================] - 0s 12ms/step - loss: 0.0896\n",
            "Epoch 115/200\n",
            "19/19 [==============================] - 0s 11ms/step - loss: 0.0896\n",
            "Epoch 116/200\n",
            "19/19 [==============================] - 0s 11ms/step - loss: 0.0896\n",
            "Epoch 117/200\n",
            "19/19 [==============================] - 0s 12ms/step - loss: 0.0896\n",
            "Epoch 118/200\n",
            "19/19 [==============================] - 0s 11ms/step - loss: 0.0896\n",
            "Epoch 119/200\n",
            "19/19 [==============================] - 0s 12ms/step - loss: 0.0896\n",
            "Epoch 120/200\n",
            "19/19 [==============================] - 0s 11ms/step - loss: 0.0896\n",
            "Epoch 121/200\n",
            "19/19 [==============================] - 0s 11ms/step - loss: 0.0896\n",
            "Epoch 122/200\n",
            "19/19 [==============================] - 0s 11ms/step - loss: 0.0896\n",
            "Epoch 123/200\n",
            "19/19 [==============================] - 0s 12ms/step - loss: 0.0896\n",
            "Epoch 124/200\n",
            "19/19 [==============================] - 0s 11ms/step - loss: 0.0896\n",
            "Epoch 125/200\n",
            "19/19 [==============================] - 0s 11ms/step - loss: 0.0896\n",
            "Epoch 126/200\n",
            "19/19 [==============================] - 0s 12ms/step - loss: 0.0896\n",
            "Epoch 127/200\n",
            "19/19 [==============================] - 0s 11ms/step - loss: 0.0896\n",
            "Epoch 128/200\n",
            "19/19 [==============================] - 0s 12ms/step - loss: 0.0896\n",
            "Epoch 129/200\n",
            "19/19 [==============================] - 0s 11ms/step - loss: 0.0896\n",
            "Epoch 130/200\n",
            "19/19 [==============================] - 0s 11ms/step - loss: 0.0896\n",
            "Epoch 131/200\n",
            "19/19 [==============================] - 0s 11ms/step - loss: 0.0896\n",
            "Epoch 132/200\n",
            "19/19 [==============================] - 0s 11ms/step - loss: 0.0896\n",
            "Epoch 133/200\n",
            "19/19 [==============================] - 0s 12ms/step - loss: 0.0896\n",
            "Epoch 134/200\n",
            "19/19 [==============================] - 0s 11ms/step - loss: 0.0896\n",
            "Epoch 135/200\n",
            "19/19 [==============================] - 0s 11ms/step - loss: 0.0896\n",
            "Epoch 136/200\n",
            "19/19 [==============================] - 0s 11ms/step - loss: 0.0896\n",
            "Epoch 137/200\n",
            "19/19 [==============================] - 0s 12ms/step - loss: 0.0896\n",
            "Epoch 138/200\n",
            "19/19 [==============================] - 0s 11ms/step - loss: 0.0896\n",
            "Epoch 139/200\n",
            "19/19 [==============================] - 0s 11ms/step - loss: 0.0896\n",
            "Epoch 140/200\n",
            "19/19 [==============================] - 0s 11ms/step - loss: 0.0896\n",
            "Epoch 141/200\n",
            "19/19 [==============================] - 0s 12ms/step - loss: 0.0896\n",
            "Epoch 142/200\n",
            "19/19 [==============================] - 0s 12ms/step - loss: 0.0896\n",
            "Epoch 143/200\n",
            "19/19 [==============================] - 0s 11ms/step - loss: 0.0896\n",
            "Epoch 144/200\n",
            "19/19 [==============================] - 0s 11ms/step - loss: 0.0896\n",
            "Epoch 145/200\n",
            "19/19 [==============================] - 0s 11ms/step - loss: 0.0896\n",
            "Epoch 146/200\n",
            "19/19 [==============================] - 0s 12ms/step - loss: 0.0896\n",
            "Epoch 147/200\n",
            "19/19 [==============================] - 0s 11ms/step - loss: 0.0896\n",
            "Epoch 148/200\n",
            "19/19 [==============================] - 0s 11ms/step - loss: 0.0896\n",
            "Epoch 149/200\n",
            "19/19 [==============================] - 0s 20ms/step - loss: 0.0896\n",
            "Epoch 150/200\n",
            "19/19 [==============================] - 0s 19ms/step - loss: 0.0896\n",
            "Epoch 151/200\n",
            "19/19 [==============================] - 0s 19ms/step - loss: 0.0896\n",
            "Epoch 152/200\n",
            "19/19 [==============================] - 0s 18ms/step - loss: 0.0896\n",
            "Epoch 153/200\n",
            "19/19 [==============================] - 0s 19ms/step - loss: 0.0896\n",
            "Epoch 154/200\n",
            "19/19 [==============================] - 0s 20ms/step - loss: 0.0896\n",
            "Epoch 155/200\n",
            "19/19 [==============================] - 0s 19ms/step - loss: 0.0896\n",
            "Epoch 156/200\n",
            "19/19 [==============================] - 0s 20ms/step - loss: 0.0896\n",
            "Epoch 157/200\n",
            "19/19 [==============================] - 0s 19ms/step - loss: 0.0896\n",
            "Epoch 158/200\n",
            "19/19 [==============================] - 0s 19ms/step - loss: 0.0896\n",
            "Epoch 159/200\n",
            "19/19 [==============================] - 0s 19ms/step - loss: 0.0896\n",
            "Epoch 160/200\n",
            "19/19 [==============================] - 0s 18ms/step - loss: 0.0896\n",
            "Epoch 161/200\n",
            "19/19 [==============================] - 0s 11ms/step - loss: 0.0896\n",
            "Epoch 162/200\n",
            "19/19 [==============================] - 0s 12ms/step - loss: 0.0896\n",
            "Epoch 163/200\n",
            "19/19 [==============================] - 0s 11ms/step - loss: 0.0896\n",
            "Epoch 164/200\n",
            "19/19 [==============================] - 0s 11ms/step - loss: 0.0896\n",
            "Epoch 165/200\n",
            "19/19 [==============================] - 0s 12ms/step - loss: 0.0896\n",
            "Epoch 166/200\n",
            "19/19 [==============================] - 0s 11ms/step - loss: 0.0896\n",
            "Epoch 167/200\n",
            "19/19 [==============================] - 0s 12ms/step - loss: 0.0896\n",
            "Epoch 168/200\n",
            "19/19 [==============================] - 0s 11ms/step - loss: 0.0896\n",
            "Epoch 169/200\n",
            "19/19 [==============================] - 0s 11ms/step - loss: 0.0896\n",
            "Epoch 170/200\n",
            "19/19 [==============================] - 0s 11ms/step - loss: 0.0896\n",
            "Epoch 171/200\n",
            "19/19 [==============================] - 0s 12ms/step - loss: 0.0896\n",
            "Epoch 172/200\n",
            "19/19 [==============================] - 0s 11ms/step - loss: 0.0896\n",
            "Epoch 173/200\n",
            "19/19 [==============================] - 0s 11ms/step - loss: 0.0896\n",
            "Epoch 174/200\n",
            "19/19 [==============================] - 0s 11ms/step - loss: 0.0896\n",
            "Epoch 175/200\n",
            "19/19 [==============================] - 0s 11ms/step - loss: 0.0896\n",
            "Epoch 176/200\n",
            "19/19 [==============================] - 0s 12ms/step - loss: 0.0896\n",
            "Epoch 177/200\n",
            "19/19 [==============================] - 0s 12ms/step - loss: 0.0896\n",
            "Epoch 178/200\n",
            "19/19 [==============================] - 0s 11ms/step - loss: 0.0896\n",
            "Epoch 179/200\n",
            "19/19 [==============================] - 0s 11ms/step - loss: 0.0896\n",
            "Epoch 180/200\n",
            "19/19 [==============================] - 0s 11ms/step - loss: 0.0896\n",
            "Epoch 181/200\n",
            "19/19 [==============================] - 0s 12ms/step - loss: 0.0896\n",
            "Epoch 182/200\n",
            "19/19 [==============================] - 0s 11ms/step - loss: 0.0896\n",
            "Epoch 183/200\n",
            "19/19 [==============================] - 0s 12ms/step - loss: 0.0896\n",
            "Epoch 184/200\n",
            "19/19 [==============================] - 0s 11ms/step - loss: 0.0896\n",
            "Epoch 185/200\n",
            "19/19 [==============================] - 0s 12ms/step - loss: 0.0896\n",
            "Epoch 186/200\n",
            "19/19 [==============================] - 0s 11ms/step - loss: 0.0896\n",
            "Epoch 187/200\n",
            "19/19 [==============================] - 0s 11ms/step - loss: 0.0896\n",
            "Epoch 188/200\n",
            "19/19 [==============================] - 0s 11ms/step - loss: 0.0896\n",
            "Epoch 189/200\n",
            "19/19 [==============================] - 0s 11ms/step - loss: 0.0896\n",
            "Epoch 190/200\n",
            "19/19 [==============================] - 0s 12ms/step - loss: 0.0896\n",
            "Epoch 191/200\n",
            "19/19 [==============================] - 0s 11ms/step - loss: 0.0896\n",
            "Epoch 192/200\n",
            "19/19 [==============================] - 0s 11ms/step - loss: 0.0896\n",
            "Epoch 193/200\n",
            "19/19 [==============================] - 0s 11ms/step - loss: 0.0896\n",
            "Epoch 194/200\n",
            "19/19 [==============================] - 0s 12ms/step - loss: 0.0896\n",
            "Epoch 195/200\n",
            "19/19 [==============================] - 0s 11ms/step - loss: 0.0896\n",
            "Epoch 196/200\n",
            "19/19 [==============================] - 0s 11ms/step - loss: 0.0896\n",
            "Epoch 197/200\n",
            "19/19 [==============================] - 0s 11ms/step - loss: 0.0896\n",
            "Epoch 198/200\n",
            "19/19 [==============================] - 0s 12ms/step - loss: 0.0896\n",
            "Epoch 199/200\n",
            "19/19 [==============================] - 0s 12ms/step - loss: 0.0896\n",
            "Epoch 200/200\n",
            "19/19 [==============================] - 0s 11ms/step - loss: 0.0896\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Predicted prices from 2024-04-01 to 2028-12-01:\n",
            "2024-04-01: 1.864\n",
            "2024-05-01: 1.864\n",
            "2024-06-01: 1.864\n",
            "2024-07-01: 1.864\n",
            "2024-08-01: 1.864\n",
            "2024-09-01: 1.864\n",
            "2024-10-01: 1.864\n",
            "2024-11-01: 1.864\n",
            "2024-12-01: 1.864\n",
            "2025-01-01: 1.864\n",
            "2025-02-01: 1.864\n",
            "2025-03-01: 1.864\n",
            "2025-04-01: 1.864\n",
            "2025-05-01: 1.864\n",
            "2025-06-01: 1.864\n",
            "2025-07-01: 1.864\n",
            "2025-08-01: 1.864\n",
            "2025-09-01: 1.864\n",
            "2025-10-01: 1.864\n",
            "2025-11-01: 1.864\n",
            "2025-12-01: 1.864\n",
            "2026-01-01: 1.864\n",
            "2026-02-01: 1.864\n",
            "2026-03-01: 1.864\n",
            "2026-04-01: 1.864\n",
            "2026-05-01: 1.864\n",
            "2026-06-01: 1.864\n",
            "2026-07-01: 1.864\n",
            "2026-08-01: 1.864\n",
            "2026-09-01: 1.864\n",
            "2026-10-01: 1.864\n",
            "2026-11-01: 1.864\n",
            "2026-12-01: 1.864\n",
            "2027-01-01: 1.864\n",
            "2027-02-01: 1.864\n",
            "2027-03-01: 1.864\n",
            "2027-04-01: 1.864\n",
            "2027-05-01: 1.864\n",
            "2027-06-01: 1.864\n",
            "2027-07-01: 1.864\n",
            "2027-08-01: 1.864\n",
            "2027-09-01: 1.864\n",
            "2027-10-01: 1.864\n",
            "2027-11-01: 1.864\n",
            "2027-12-01: 1.864\n",
            "2028-01-01: 1.864\n",
            "2028-02-01: 1.864\n",
            "2028-03-01: 1.864\n",
            "2028-04-01: 1.864\n",
            "2028-05-01: 1.864\n",
            "2028-06-01: 1.864\n",
            "2028-07-01: 1.864\n",
            "2028-08-01: 1.864\n",
            "2028-09-01: 1.864\n",
            "2028-10-01: 1.864\n",
            "2028-11-01: 1.864\n",
            "2028-12-01: 1.864\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from datetime import datetime\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import LSTM, Dense\n",
        "\n",
        "# Read the dataset\n",
        "df = pd.read_excel('LNG (High).xlsx')\n",
        "\n",
        "# Function to calculate the number of months between two dates\n",
        "def months_between(start_date, end_date):\n",
        "    start_date = datetime.strptime(start_date, \"%Y-%m-%d\")\n",
        "    end_date = datetime.strptime(end_date, \"%Y-%m-%d\")\n",
        "    return (end_date.year - start_date.year) * 12 + end_date.month - start_date.month + 1\n",
        "\n",
        "# Define the date range\n",
        "start_date = '2024-04-01'\n",
        "end_date = '2028-12-01'\n",
        "\n",
        "# Calculate the number of months to predict\n",
        "num_months = months_between(start_date, end_date)\n",
        "\n",
        "# Ensure data is sorted by date\n",
        "df['Date'] = pd.to_datetime(df['Date'], format='%b-%y')\n",
        "df = df.sort_values(by=\"Date\", ascending=True)\n",
        "\n",
        "# Normalize the data\n",
        "scaler = MinMaxScaler(feature_range=(0, 1))\n",
        "df['Price_normalized'] = scaler.fit_transform(df['Price'].values.reshape(-1,1))\n",
        "\n",
        "# Create a new feature representing the number of months since start date\n",
        "df['Months_since_start'] = (df['Date'] - pd.to_datetime(start_date)).dt.days / 30\n",
        "\n",
        "# Prepare data for training\n",
        "X_train = df['Months_since_start'].values.reshape(-1, 1, 1)\n",
        "y_train = df['Price_normalized'].values\n",
        "\n",
        "# Define and train the LSTM model\n",
        "model = Sequential()\n",
        "model.add(LSTM(256, activation='relu', return_sequences=True, input_shape=(1, 1)))\n",
        "model.add(LSTM(128, activation='relu', return_sequences=True))\n",
        "model.add(LSTM(64, activation='relu'))\n",
        "model.add(Dense(32, activation='relu'))\n",
        "model.add(Dense(1, activation='relu'))\n",
        "model.compile(optimizer='adam', loss='mean_squared_error')\n",
        "model.fit(X_train, y_train, epochs=200, batch_size=8)\n",
        "\n",
        "# Generate future indices for prediction\n",
        "X_future = np.arange(df['Months_since_start'].iloc[-1] + 1, df['Months_since_start'].iloc[-1] + 1 + num_months)\n",
        "X_future = X_future.reshape(-1, 1, 1)  # Reshape for LSTM input\n",
        "\n",
        "# Generate predictions\n",
        "y_pred_normalized = model.predict(X_future)\n",
        "\n",
        "# Inverse transform predictions to get actual prices\n",
        "y_pred = scaler.inverse_transform(y_pred_normalized)\n",
        "\n",
        "# Ensure predictions are non-negative\n",
        "y_pred = np.maximum(y_pred, 0)\n",
        "\n",
        "# Generate date range for the predictions\n",
        "dates = pd.date_range(start=start_date, periods=num_months, freq='MS')\n",
        "\n",
        "# Print predicted prices with corresponding dates\n",
        "print(\"Predicted prices from 2024-04-01 to 2028-12-01:\")\n",
        "for date, price in zip(dates, y_pred.flatten()):\n",
        "    print(f\"{date.strftime('%Y-%m-%d')}: {price:.3f}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Cvgj7A1y3saN",
        "outputId": "32a828b7-0aa5-40ca-a001-78378591a23f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/100\n",
            "19/19 [==============================] - 4s 5ms/step - loss: 0.1041\n",
            "Epoch 2/100\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 0.0896\n",
            "Epoch 3/100\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 0.0896\n",
            "Epoch 4/100\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 0.0896\n",
            "Epoch 5/100\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 0.0896\n",
            "Epoch 6/100\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 0.0896\n",
            "Epoch 7/100\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 0.0896\n",
            "Epoch 8/100\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 0.0896\n",
            "Epoch 9/100\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 0.0896\n",
            "Epoch 10/100\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 0.0896\n",
            "Epoch 11/100\n",
            "19/19 [==============================] - 0s 6ms/step - loss: 0.0896\n",
            "Epoch 12/100\n",
            "19/19 [==============================] - 0s 9ms/step - loss: 0.0896\n",
            "Epoch 13/100\n",
            "19/19 [==============================] - 0s 8ms/step - loss: 0.0896\n",
            "Epoch 14/100\n",
            "19/19 [==============================] - 0s 8ms/step - loss: 0.0896\n",
            "Epoch 15/100\n",
            "19/19 [==============================] - 0s 8ms/step - loss: 0.0896\n",
            "Epoch 16/100\n",
            "19/19 [==============================] - 0s 8ms/step - loss: 0.0896\n",
            "Epoch 17/100\n",
            "19/19 [==============================] - 0s 8ms/step - loss: 0.0896\n",
            "Epoch 18/100\n",
            "19/19 [==============================] - 0s 7ms/step - loss: 0.0896\n",
            "Epoch 19/100\n",
            "19/19 [==============================] - 0s 8ms/step - loss: 0.0896\n",
            "Epoch 20/100\n",
            "19/19 [==============================] - 0s 7ms/step - loss: 0.0896\n",
            "Epoch 21/100\n",
            "19/19 [==============================] - 0s 7ms/step - loss: 0.0896\n",
            "Epoch 22/100\n",
            "19/19 [==============================] - 0s 8ms/step - loss: 0.0896\n",
            "Epoch 23/100\n",
            "19/19 [==============================] - 0s 8ms/step - loss: 0.0896\n",
            "Epoch 24/100\n",
            "19/19 [==============================] - 0s 8ms/step - loss: 0.0896\n",
            "Epoch 25/100\n",
            "19/19 [==============================] - 0s 9ms/step - loss: 0.0896\n",
            "Epoch 26/100\n",
            "19/19 [==============================] - 0s 8ms/step - loss: 0.0896\n",
            "Epoch 27/100\n",
            "19/19 [==============================] - 0s 8ms/step - loss: 0.0896\n",
            "Epoch 28/100\n",
            "19/19 [==============================] - 0s 7ms/step - loss: 0.0896\n",
            "Epoch 29/100\n",
            "19/19 [==============================] - 0s 8ms/step - loss: 0.0896\n",
            "Epoch 30/100\n",
            "19/19 [==============================] - 0s 7ms/step - loss: 0.0896\n",
            "Epoch 31/100\n",
            "19/19 [==============================] - 0s 8ms/step - loss: 0.0896\n",
            "Epoch 32/100\n",
            "19/19 [==============================] - 0s 8ms/step - loss: 0.0896\n",
            "Epoch 33/100\n",
            "19/19 [==============================] - 0s 7ms/step - loss: 0.0896\n",
            "Epoch 34/100\n",
            "19/19 [==============================] - 0s 8ms/step - loss: 0.0896\n",
            "Epoch 35/100\n",
            "19/19 [==============================] - 0s 8ms/step - loss: 0.0896\n",
            "Epoch 36/100\n",
            "19/19 [==============================] - 0s 8ms/step - loss: 0.0896\n",
            "Epoch 37/100\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 0.0896\n",
            "Epoch 38/100\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 0.0896\n",
            "Epoch 39/100\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 0.0896\n",
            "Epoch 40/100\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 0.0896\n",
            "Epoch 41/100\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 0.0896\n",
            "Epoch 42/100\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 0.0896\n",
            "Epoch 43/100\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 0.0896\n",
            "Epoch 44/100\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 0.0896\n",
            "Epoch 45/100\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 0.0896\n",
            "Epoch 46/100\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 0.0896\n",
            "Epoch 47/100\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 0.0896\n",
            "Epoch 48/100\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 0.0896\n",
            "Epoch 49/100\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 0.0896\n",
            "Epoch 50/100\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 0.0896\n",
            "Epoch 51/100\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 0.0896\n",
            "Epoch 52/100\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 0.0896\n",
            "Epoch 53/100\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 0.0896\n",
            "Epoch 54/100\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 0.0896\n",
            "Epoch 55/100\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 0.0896\n",
            "Epoch 56/100\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 0.0896\n",
            "Epoch 57/100\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 0.0896\n",
            "Epoch 58/100\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 0.0896\n",
            "Epoch 59/100\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 0.0896\n",
            "Epoch 60/100\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 0.0896\n",
            "Epoch 61/100\n",
            "19/19 [==============================] - 0s 6ms/step - loss: 0.0896\n",
            "Epoch 62/100\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 0.0896\n",
            "Epoch 63/100\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 0.0896\n",
            "Epoch 64/100\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 0.0896\n",
            "Epoch 65/100\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 0.0896\n",
            "Epoch 66/100\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 0.0896\n",
            "Epoch 67/100\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 0.0896\n",
            "Epoch 68/100\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 0.0896\n",
            "Epoch 69/100\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 0.0896\n",
            "Epoch 70/100\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 0.0896\n",
            "Epoch 71/100\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 0.0896\n",
            "Epoch 72/100\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 0.0896\n",
            "Epoch 73/100\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 0.0896\n",
            "Epoch 74/100\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 0.0896\n",
            "Epoch 75/100\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 0.0896\n",
            "Epoch 76/100\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 0.0896\n",
            "Epoch 77/100\n",
            "19/19 [==============================] - 0s 6ms/step - loss: 0.0896\n",
            "Epoch 78/100\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 0.0896\n",
            "Epoch 79/100\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 0.0896\n",
            "Epoch 80/100\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 0.0896\n",
            "Epoch 81/100\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 0.0896\n",
            "Epoch 82/100\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 0.0896\n",
            "Epoch 83/100\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 0.0896\n",
            "Epoch 84/100\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 0.0896\n",
            "Epoch 85/100\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 0.0896\n",
            "Epoch 86/100\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 0.0896\n",
            "Epoch 87/100\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 0.0896\n",
            "Epoch 88/100\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 0.0896\n",
            "Epoch 89/100\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 0.0896\n",
            "Epoch 90/100\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 0.0896\n",
            "Epoch 91/100\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 0.0896\n",
            "Epoch 92/100\n",
            "19/19 [==============================] - 0s 7ms/step - loss: 0.0896\n",
            "Epoch 93/100\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 0.0896\n",
            "Epoch 94/100\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 0.0896\n",
            "Epoch 95/100\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 0.0896\n",
            "Epoch 96/100\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 0.0896\n",
            "Epoch 97/100\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 0.0896\n",
            "Epoch 98/100\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 0.0896\n",
            "Epoch 99/100\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 0.0896\n",
            "Epoch 100/100\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 0.0896\n",
            "1/1 [==============================] - 0s 325ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "Predicted prices from 2024-04-01 to 2028-12-01:\n",
            "2024-04-01: 1.864\n",
            "2024-05-01: 1.864\n",
            "2024-06-01: 1.864\n",
            "2024-07-01: 1.864\n",
            "2024-08-01: 1.864\n",
            "2024-09-01: 1.864\n",
            "2024-10-01: 1.864\n",
            "2024-11-01: 1.864\n",
            "2024-12-01: 1.864\n",
            "2025-01-01: 1.864\n",
            "2025-02-01: 1.864\n",
            "2025-03-01: 1.864\n",
            "2025-04-01: 1.864\n",
            "2025-05-01: 1.864\n",
            "2025-06-01: 1.864\n",
            "2025-07-01: 1.864\n",
            "2025-08-01: 1.864\n",
            "2025-09-01: 1.864\n",
            "2025-10-01: 1.864\n",
            "2025-11-01: 1.864\n",
            "2025-12-01: 1.864\n",
            "2026-01-01: 1.864\n",
            "2026-02-01: 1.864\n",
            "2026-03-01: 1.864\n",
            "2026-04-01: 1.864\n",
            "2026-05-01: 1.864\n",
            "2026-06-01: 1.864\n",
            "2026-07-01: 1.864\n",
            "2026-08-01: 1.864\n",
            "2026-09-01: 1.864\n",
            "2026-10-01: 1.864\n",
            "2026-11-01: 1.864\n",
            "2026-12-01: 1.864\n",
            "2027-01-01: 1.864\n",
            "2027-02-01: 1.864\n",
            "2027-03-01: 1.864\n",
            "2027-04-01: 1.864\n",
            "2027-05-01: 1.864\n",
            "2027-06-01: 1.864\n",
            "2027-07-01: 1.864\n",
            "2027-08-01: 1.864\n",
            "2027-09-01: 1.864\n",
            "2027-10-01: 1.864\n",
            "2027-11-01: 1.864\n",
            "2027-12-01: 1.864\n",
            "2028-01-01: 1.864\n",
            "2028-02-01: 1.864\n",
            "2028-03-01: 1.864\n",
            "2028-04-01: 1.864\n",
            "2028-05-01: 1.864\n",
            "2028-06-01: 1.864\n",
            "2028-07-01: 1.864\n",
            "2028-08-01: 1.864\n",
            "2028-09-01: 1.864\n",
            "2028-10-01: 1.864\n",
            "2028-11-01: 1.864\n",
            "2028-12-01: 1.864\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from datetime import datetime\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import LSTM, Dense\n",
        "\n",
        "# Read the dataset\n",
        "df = pd.read_excel('LNG (High).xlsx')\n",
        "\n",
        "# Function to calculate the number of months between two dates\n",
        "def months_between(start_date, end_date):\n",
        "    start_date = datetime.strptime(start_date, \"%Y-%m-%d\")\n",
        "    end_date = datetime.strptime(end_date, \"%Y-%m-%d\")\n",
        "    return (end_date.year - start_date.year) * 12 + end_date.month - start_date.month + 1\n",
        "\n",
        "# Define the date range\n",
        "start_date = '2024-04-01'\n",
        "end_date = '2028-12-01'\n",
        "\n",
        "# Calculate the number of months to predict\n",
        "num_months = months_between(start_date, end_date)\n",
        "\n",
        "# Ensure data is sorted by date\n",
        "df['Date'] = pd.to_datetime(df['Date'], format='%b-%y')\n",
        "df = df.sort_values(by=\"Date\", ascending=True)\n",
        "\n",
        "# Normalize the data\n",
        "scaler = MinMaxScaler(feature_range=(0, 1))\n",
        "df['Price_normalized'] = scaler.fit_transform(df['Price'].values.reshape(-1,1))\n",
        "\n",
        "# Create a new feature representing the number of months since start date\n",
        "df['Months_since_start'] = (df['Date'] - pd.to_datetime(start_date)).dt.days / 30\n",
        "\n",
        "# Prepare data for training\n",
        "X_train = df['Months_since_start'].values.reshape(-1, 1, 1)\n",
        "y_train = df['Price_normalized'].values\n",
        "\n",
        "# Define and train the LSTM model\n",
        "model = Sequential()\n",
        "model.add(LSTM(128, activation='relu', return_sequences=True, input_shape=(1, 1)))\n",
        "model.add(LSTM(64, activation='relu'))\n",
        "model.add(Dense(1, activation='relu'))\n",
        "model.compile(optimizer='adam', loss='mean_squared_error')\n",
        "model.fit(X_train, y_train, epochs=100, batch_size=8)\n",
        "\n",
        "# Generate future indices for prediction\n",
        "X_future = np.arange(df['Months_since_start'].iloc[-1] + 1, df['Months_since_start'].iloc[-1] + 1 + num_months)\n",
        "X_future = X_future.reshape(-1, 1, 1)  # Reshape for LSTM input\n",
        "\n",
        "# Generate predictions\n",
        "y_pred_normalized = []\n",
        "prev_pred = y_train[-1]  # Initialize previous prediction with the last known value\n",
        "for i in range(num_months):\n",
        "    next_pred = model.predict(prev_pred.reshape(1, 1, 1))\n",
        "    y_pred_normalized.append(next_pred.flatten())\n",
        "    prev_pred = next_pred\n",
        "\n",
        "# Inverse transform predictions to get actual prices\n",
        "y_pred = scaler.inverse_transform(y_pred_normalized)\n",
        "\n",
        "# Generate date range for the predictions\n",
        "dates = pd.date_range(start=start_date, periods=num_months, freq='MS')\n",
        "\n",
        "# Print predicted prices with corresponding dates\n",
        "print(\"Predicted prices from 2024-04-01 to 2028-12-01:\")\n",
        "for date, price in zip(dates, y_pred.flatten()):\n",
        "    print(f\"{date.strftime('%Y-%m-%d')}: {price:.3f}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XJvnpJKF4ZRo",
        "outputId": "ee31379f-97fa-4fd6-cfc4-6db473944519"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/100\n",
            "149/149 [==============================] - 3s 3ms/step - loss: 0.0527\n",
            "Epoch 2/100\n",
            "149/149 [==============================] - 0s 2ms/step - loss: 0.0272\n",
            "Epoch 3/100\n",
            "149/149 [==============================] - 0s 2ms/step - loss: 0.0186\n",
            "Epoch 4/100\n",
            "149/149 [==============================] - 0s 2ms/step - loss: 0.0098\n",
            "Epoch 5/100\n",
            "149/149 [==============================] - 0s 3ms/step - loss: 0.0039\n",
            "Epoch 6/100\n",
            "149/149 [==============================] - 0s 3ms/step - loss: 9.6837e-04\n",
            "Epoch 7/100\n",
            "149/149 [==============================] - 0s 2ms/step - loss: 1.6960e-04\n",
            "Epoch 8/100\n",
            "149/149 [==============================] - 0s 2ms/step - loss: 6.1650e-05\n",
            "Epoch 9/100\n",
            "149/149 [==============================] - 0s 2ms/step - loss: 5.5161e-05\n",
            "Epoch 10/100\n",
            "149/149 [==============================] - 0s 2ms/step - loss: 5.8319e-05\n",
            "Epoch 11/100\n",
            "149/149 [==============================] - 0s 2ms/step - loss: 5.1718e-05\n",
            "Epoch 12/100\n",
            "149/149 [==============================] - 0s 2ms/step - loss: 5.1023e-05\n",
            "Epoch 13/100\n",
            "149/149 [==============================] - 0s 2ms/step - loss: 4.8503e-05\n",
            "Epoch 14/100\n",
            "149/149 [==============================] - 0s 2ms/step - loss: 4.7580e-05\n",
            "Epoch 15/100\n",
            "149/149 [==============================] - 0s 2ms/step - loss: 4.4309e-05\n",
            "Epoch 16/100\n",
            "149/149 [==============================] - 0s 2ms/step - loss: 4.0087e-05\n",
            "Epoch 17/100\n",
            "149/149 [==============================] - 0s 2ms/step - loss: 4.3572e-05\n",
            "Epoch 18/100\n",
            "149/149 [==============================] - 0s 2ms/step - loss: 3.5950e-05\n",
            "Epoch 19/100\n",
            "149/149 [==============================] - 0s 2ms/step - loss: 3.2825e-05\n",
            "Epoch 20/100\n",
            "149/149 [==============================] - 0s 2ms/step - loss: 3.6030e-05\n",
            "Epoch 21/100\n",
            "149/149 [==============================] - 0s 3ms/step - loss: 3.0812e-05\n",
            "Epoch 22/100\n",
            "149/149 [==============================] - 1s 4ms/step - loss: 2.3666e-05\n",
            "Epoch 23/100\n",
            "149/149 [==============================] - 1s 3ms/step - loss: 2.7546e-05\n",
            "Epoch 24/100\n",
            "149/149 [==============================] - 1s 3ms/step - loss: 2.2911e-05\n",
            "Epoch 25/100\n",
            "149/149 [==============================] - 1s 4ms/step - loss: 2.1148e-05\n",
            "Epoch 26/100\n",
            "149/149 [==============================] - 1s 4ms/step - loss: 1.9459e-05\n",
            "Epoch 27/100\n",
            "149/149 [==============================] - 0s 3ms/step - loss: 1.5124e-05\n",
            "Epoch 28/100\n",
            "149/149 [==============================] - 1s 3ms/step - loss: 1.2850e-05\n",
            "Epoch 29/100\n",
            "149/149 [==============================] - 0s 3ms/step - loss: 1.0285e-05\n",
            "Epoch 30/100\n",
            "149/149 [==============================] - 0s 2ms/step - loss: 9.2071e-06\n",
            "Epoch 31/100\n",
            "149/149 [==============================] - 0s 2ms/step - loss: 7.5880e-06\n",
            "Epoch 32/100\n",
            "149/149 [==============================] - 0s 2ms/step - loss: 6.3689e-06\n",
            "Epoch 33/100\n",
            "149/149 [==============================] - 1s 3ms/step - loss: 5.0560e-06\n",
            "Epoch 34/100\n",
            "149/149 [==============================] - 0s 2ms/step - loss: 3.5637e-06\n",
            "Epoch 35/100\n",
            "149/149 [==============================] - 0s 2ms/step - loss: 3.2135e-06\n",
            "Epoch 36/100\n",
            "149/149 [==============================] - 1s 4ms/step - loss: 2.1722e-06\n",
            "Epoch 37/100\n",
            "149/149 [==============================] - 1s 4ms/step - loss: 2.2095e-06\n",
            "Epoch 38/100\n",
            "149/149 [==============================] - 1s 4ms/step - loss: 1.3702e-06\n",
            "Epoch 39/100\n",
            "149/149 [==============================] - 1s 3ms/step - loss: 1.4818e-06\n",
            "Epoch 40/100\n",
            "149/149 [==============================] - 1s 4ms/step - loss: 1.0801e-06\n",
            "Epoch 41/100\n",
            "149/149 [==============================] - 1s 4ms/step - loss: 1.1510e-06\n",
            "Epoch 42/100\n",
            "149/149 [==============================] - 0s 3ms/step - loss: 6.4725e-07\n",
            "Epoch 43/100\n",
            "149/149 [==============================] - 0s 3ms/step - loss: 1.0105e-06\n",
            "Epoch 44/100\n",
            "149/149 [==============================] - 0s 2ms/step - loss: 7.1126e-07\n",
            "Epoch 45/100\n",
            "149/149 [==============================] - 0s 2ms/step - loss: 9.4386e-07\n",
            "Epoch 46/100\n",
            "149/149 [==============================] - 0s 2ms/step - loss: 1.6518e-06\n",
            "Epoch 47/100\n",
            "149/149 [==============================] - 0s 3ms/step - loss: 7.9717e-07\n",
            "Epoch 48/100\n",
            "149/149 [==============================] - 0s 2ms/step - loss: 7.0727e-07\n",
            "Epoch 49/100\n",
            "149/149 [==============================] - 0s 2ms/step - loss: 8.2235e-07\n",
            "Epoch 50/100\n",
            "149/149 [==============================] - 0s 3ms/step - loss: 2.2031e-06\n",
            "Epoch 51/100\n",
            "149/149 [==============================] - 0s 3ms/step - loss: 1.0516e-05\n",
            "Epoch 52/100\n",
            "149/149 [==============================] - 1s 4ms/step - loss: 1.7726e-06\n",
            "Epoch 53/100\n",
            "149/149 [==============================] - 1s 4ms/step - loss: 2.9440e-06\n",
            "Epoch 54/100\n",
            "149/149 [==============================] - 1s 4ms/step - loss: 2.2644e-06\n",
            "Epoch 55/100\n",
            "149/149 [==============================] - 1s 4ms/step - loss: 4.6290e-06\n",
            "Epoch 56/100\n",
            "149/149 [==============================] - 1s 4ms/step - loss: 1.5342e-06\n",
            "Epoch 57/100\n",
            "149/149 [==============================] - 1s 4ms/step - loss: 6.2394e-06\n",
            "Epoch 58/100\n",
            "149/149 [==============================] - 0s 3ms/step - loss: 3.4718e-06\n",
            "Epoch 59/100\n",
            "149/149 [==============================] - 0s 2ms/step - loss: 1.0738e-05\n",
            "Epoch 60/100\n",
            "149/149 [==============================] - 0s 2ms/step - loss: 2.0688e-05\n",
            "Epoch 61/100\n",
            "149/149 [==============================] - 0s 2ms/step - loss: 6.2945e-06\n",
            "Epoch 62/100\n",
            "149/149 [==============================] - 0s 2ms/step - loss: 4.2410e-06\n",
            "Epoch 63/100\n",
            "149/149 [==============================] - 0s 2ms/step - loss: 6.7873e-06\n",
            "Epoch 64/100\n",
            "149/149 [==============================] - 0s 2ms/step - loss: 9.4068e-06\n",
            "Epoch 65/100\n",
            "149/149 [==============================] - 0s 2ms/step - loss: 6.3239e-06\n",
            "Epoch 66/100\n",
            "149/149 [==============================] - 0s 2ms/step - loss: 1.2541e-05\n",
            "Epoch 67/100\n",
            "149/149 [==============================] - 0s 2ms/step - loss: 4.0314e-06\n",
            "Epoch 68/100\n",
            "149/149 [==============================] - 0s 2ms/step - loss: 6.9671e-06\n",
            "Epoch 69/100\n",
            "149/149 [==============================] - 0s 3ms/step - loss: 1.3055e-05\n",
            "Epoch 70/100\n",
            "149/149 [==============================] - 0s 2ms/step - loss: 3.3619e-06\n",
            "Epoch 71/100\n",
            "149/149 [==============================] - 0s 2ms/step - loss: 1.2094e-06\n",
            "Epoch 72/100\n",
            "149/149 [==============================] - 0s 2ms/step - loss: 1.6250e-06\n",
            "Epoch 73/100\n",
            "149/149 [==============================] - 0s 2ms/step - loss: 1.9621e-06\n",
            "Epoch 74/100\n",
            "149/149 [==============================] - 0s 2ms/step - loss: 1.0247e-06\n",
            "Epoch 75/100\n",
            "149/149 [==============================] - 0s 2ms/step - loss: 5.3069e-06\n",
            "Epoch 76/100\n",
            "149/149 [==============================] - 0s 2ms/step - loss: 1.1440e-05\n",
            "Epoch 77/100\n",
            "149/149 [==============================] - 0s 2ms/step - loss: 2.3227e-06\n",
            "Epoch 78/100\n",
            "149/149 [==============================] - 0s 2ms/step - loss: 1.6757e-05\n",
            "Epoch 79/100\n",
            "149/149 [==============================] - 0s 2ms/step - loss: 2.9272e-06\n",
            "Epoch 80/100\n",
            "149/149 [==============================] - 0s 3ms/step - loss: 1.4203e-05\n",
            "Epoch 81/100\n",
            "149/149 [==============================] - 0s 3ms/step - loss: 4.3241e-05\n",
            "Epoch 82/100\n",
            "149/149 [==============================] - 0s 3ms/step - loss: 1.5485e-06\n",
            "Epoch 83/100\n",
            "149/149 [==============================] - 0s 3ms/step - loss: 1.3087e-06\n",
            "Epoch 84/100\n",
            "149/149 [==============================] - 0s 3ms/step - loss: 3.4249e-06\n",
            "Epoch 85/100\n",
            "149/149 [==============================] - 0s 3ms/step - loss: 2.2256e-06\n",
            "Epoch 86/100\n",
            "149/149 [==============================] - 1s 4ms/step - loss: 5.3847e-06\n",
            "Epoch 87/100\n",
            "149/149 [==============================] - 1s 4ms/step - loss: 6.4877e-06\n",
            "Epoch 88/100\n",
            "149/149 [==============================] - 1s 4ms/step - loss: 2.4575e-06\n",
            "Epoch 89/100\n",
            "149/149 [==============================] - 1s 4ms/step - loss: 5.1097e-06\n",
            "Epoch 90/100\n",
            "149/149 [==============================] - 1s 4ms/step - loss: 5.5274e-06\n",
            "Epoch 91/100\n",
            "149/149 [==============================] - 1s 4ms/step - loss: 8.7234e-05\n",
            "Epoch 92/100\n",
            "149/149 [==============================] - 0s 3ms/step - loss: 7.9886e-07\n",
            "Epoch 93/100\n",
            "149/149 [==============================] - 0s 3ms/step - loss: 3.1188e-06\n",
            "Epoch 94/100\n",
            "149/149 [==============================] - 0s 3ms/step - loss: 8.7796e-07\n",
            "Epoch 95/100\n",
            "149/149 [==============================] - 0s 3ms/step - loss: 2.0844e-06\n",
            "Epoch 96/100\n",
            "149/149 [==============================] - 0s 3ms/step - loss: 8.5186e-07\n",
            "Epoch 97/100\n",
            "149/149 [==============================] - 0s 3ms/step - loss: 5.0732e-06\n",
            "Epoch 98/100\n",
            "149/149 [==============================] - 0s 3ms/step - loss: 1.0655e-05\n",
            "Epoch 99/100\n",
            "149/149 [==============================] - 0s 3ms/step - loss: 7.6523e-06\n",
            "Epoch 100/100\n",
            "149/149 [==============================] - 0s 3ms/step - loss: 8.7320e-07\n",
            "3/3 [==============================] - 0s 4ms/step\n",
            "Predicted prices from 2024-04-01 to 2028-12-01:\n",
            "2024-04-01: 1.879\n",
            "2024-05-01: 10.015\n",
            "2024-06-01: 17.355\n",
            "2024-07-01: 23.246\n",
            "2024-08-01: 27.800\n",
            "2024-09-01: 31.317\n",
            "2024-10-01: 34.063\n",
            "2024-11-01: 36.238\n",
            "2024-12-01: 37.983\n",
            "2025-01-01: 39.402\n",
            "2025-02-01: 40.566\n",
            "2025-03-01: 41.531\n",
            "2025-04-01: 42.336\n",
            "2025-05-01: 43.013\n",
            "2025-06-01: 43.585\n",
            "2025-07-01: 44.071\n",
            "2025-08-01: 44.484\n",
            "2025-09-01: 44.838\n",
            "2025-10-01: 45.140\n",
            "2025-11-01: 45.399\n",
            "2025-12-01: 45.621\n",
            "2026-01-01: 45.811\n",
            "2026-02-01: 45.974\n",
            "2026-03-01: 46.113\n",
            "2026-04-01: 46.232\n",
            "2026-05-01: 46.332\n",
            "2026-06-01: 46.417\n",
            "2026-07-01: 46.488\n",
            "2026-08-01: 46.547\n",
            "2026-09-01: 46.595\n",
            "2026-10-01: 46.634\n",
            "2026-11-01: 46.664\n",
            "2026-12-01: 46.687\n",
            "2027-01-01: 46.704\n",
            "2027-02-01: 46.715\n",
            "2027-03-01: 46.720\n",
            "2027-04-01: 46.721\n",
            "2027-05-01: 46.718\n",
            "2027-06-01: 46.712\n",
            "2027-07-01: 46.702\n",
            "2027-08-01: 46.690\n",
            "2027-09-01: 46.675\n",
            "2027-10-01: 46.658\n",
            "2027-11-01: 46.638\n",
            "2027-12-01: 46.618\n",
            "2028-01-01: 46.595\n",
            "2028-02-01: 46.571\n",
            "2028-03-01: 46.547\n",
            "2028-04-01: 46.521\n",
            "2028-05-01: 46.494\n",
            "2028-06-01: 46.466\n",
            "2028-07-01: 46.438\n",
            "2028-08-01: 46.409\n",
            "2028-09-01: 46.380\n",
            "2028-10-01: 46.350\n",
            "2028-11-01: 46.320\n",
            "2028-12-01: 46.290\n",
            "2029-01-01: 46.259\n",
            "2029-02-01: 46.228\n",
            "2029-03-01: 46.197\n",
            "2029-04-01: 46.167\n",
            "2029-05-01: 46.136\n",
            "2029-06-01: 46.105\n",
            "2029-07-01: 46.074\n",
            "2029-08-01: 46.043\n",
            "2029-09-01: 46.012\n",
            "2029-10-01: 45.981\n",
            "2029-11-01: 45.951\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import LSTM, Dense\n",
        "\n",
        "# Read the dataset\n",
        "df = pd.read_excel('LNG (High).xlsx')\n",
        "\n",
        "# Ensure data is sorted by date\n",
        "df['Date'] = pd.to_datetime(df['Date'], format='%b-%y')\n",
        "df = df.sort_values(by=\"Date\", ascending=True)\n",
        "\n",
        "# Normalize the data\n",
        "scaler = MinMaxScaler(feature_range=(0, 1))\n",
        "df['Price_normalized'] = scaler.fit_transform(df['Price'].values.reshape(-1,1))\n",
        "\n",
        "# Prepare data for training\n",
        "X_train = df['Price_normalized'].values.reshape(-1, 1, 1)\n",
        "y_train = df['Price_normalized'].values.reshape(-1, 1)\n",
        "\n",
        "# Define and train the LSTM model\n",
        "model = Sequential()\n",
        "model.add(LSTM(50, input_shape=(1, 1)))\n",
        "model.add(Dense(1))\n",
        "model.compile(optimizer='adam', loss='mean_squared_error')\n",
        "model.fit(X_train, y_train, epochs=100, batch_size=1, verbose=1)\n",
        "\n",
        "# Generate future indices for prediction\n",
        "num_months = 68  # Number of months from April 2024 to December 2028\n",
        "X_future = np.arange(0, num_months).reshape(-1, 1, 1)  # Reshape for LSTM input\n",
        "\n",
        "# Generate predictions\n",
        "y_pred_normalized = model.predict(X_future)\n",
        "\n",
        "# Inverse transform predictions to get actual prices\n",
        "y_pred = scaler.inverse_transform(y_pred_normalized)\n",
        "\n",
        "# Generate date range for the predictions\n",
        "dates = pd.date_range(start='2024-04-01', periods=num_months, freq='MS')\n",
        "\n",
        "# Print predicted prices with corresponding dates\n",
        "print(\"Predicted prices from 2024-04-01 to 2028-12-01:\")\n",
        "for date, price in zip(dates, y_pred.flatten()):\n",
        "    print(f\"{date.strftime('%Y-%m-%d')}: {price:.3f}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XfO-I2-C4s4Y",
        "outputId": "59c09be9-6ad5-4ced-f177-2521e5d0fd71"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/50\n",
            "5/5 [==============================] - 2s 4ms/step - loss: 16.9055\n",
            "Epoch 2/50\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 7.2171\n",
            "Epoch 3/50\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 2.8354\n",
            "Epoch 4/50\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.9964\n",
            "Epoch 5/50\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.2502\n",
            "Epoch 6/50\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.2137\n",
            "Epoch 7/50\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.2934\n",
            "Epoch 8/50\n",
            "5/5 [==============================] - 0s 6ms/step - loss: 0.2246\n",
            "Epoch 9/50\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.1295\n",
            "Epoch 10/50\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0899\n",
            "Epoch 11/50\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0792\n",
            "Epoch 12/50\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0723\n",
            "Epoch 13/50\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0653\n",
            "Epoch 14/50\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0583\n",
            "Epoch 15/50\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0520\n",
            "Epoch 16/50\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0486\n",
            "Epoch 17/50\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0444\n",
            "Epoch 18/50\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0406\n",
            "Epoch 19/50\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0384\n",
            "Epoch 20/50\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0358\n",
            "Epoch 21/50\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0337\n",
            "Epoch 22/50\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0320\n",
            "Epoch 23/50\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0303\n",
            "Epoch 24/50\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0296\n",
            "Epoch 25/50\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0281\n",
            "Epoch 26/50\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0272\n",
            "Epoch 27/50\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0265\n",
            "Epoch 28/50\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0257\n",
            "Epoch 29/50\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0251\n",
            "Epoch 30/50\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0245\n",
            "Epoch 31/50\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0241\n",
            "Epoch 32/50\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0236\n",
            "Epoch 33/50\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0232\n",
            "Epoch 34/50\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0230\n",
            "Epoch 35/50\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0227\n",
            "Epoch 36/50\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0226\n",
            "Epoch 37/50\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0224\n",
            "Epoch 38/50\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0221\n",
            "Epoch 39/50\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0221\n",
            "Epoch 40/50\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0218\n",
            "Epoch 41/50\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0217\n",
            "Epoch 42/50\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0217\n",
            "Epoch 43/50\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0217\n",
            "Epoch 44/50\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0216\n",
            "Epoch 45/50\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0215\n",
            "Epoch 46/50\n",
            "5/5 [==============================] - 0s 6ms/step - loss: 0.0214\n",
            "Epoch 47/50\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0213\n",
            "Epoch 48/50\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0212\n",
            "Epoch 49/50\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0214\n",
            "Epoch 50/50\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0217\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Predicted prices from 2024-04-01 to 2028-12-01:\n",
            "2024-04-01: 3.351\n",
            "2024-05-01: 3.701\n",
            "2024-06-01: 4.041\n",
            "2024-07-01: 4.372\n",
            "2024-08-01: 4.693\n",
            "2024-09-01: 5.006\n",
            "2024-10-01: 5.312\n",
            "2024-11-01: 5.611\n",
            "2024-12-01: 5.906\n",
            "2025-01-01: 6.196\n",
            "2025-02-01: 6.482\n",
            "2025-03-01: 6.765\n",
            "2025-04-01: 7.046\n",
            "2025-05-01: 7.325\n",
            "2025-06-01: 7.602\n",
            "2025-07-01: 7.879\n",
            "2025-08-01: 8.155\n",
            "2025-09-01: 8.430\n",
            "2025-10-01: 8.705\n",
            "2025-11-01: 8.980\n",
            "2025-12-01: 9.255\n",
            "2026-01-01: 9.530\n",
            "2026-02-01: 9.804\n",
            "2026-03-01: 10.079\n",
            "2026-04-01: 10.354\n",
            "2026-05-01: 10.629\n",
            "2026-06-01: 10.903\n",
            "2026-07-01: 11.178\n",
            "2026-08-01: 11.452\n",
            "2026-09-01: 11.726\n",
            "2026-10-01: 12.000\n",
            "2026-11-01: 12.272\n",
            "2026-12-01: 12.545\n",
            "2027-01-01: 12.816\n",
            "2027-02-01: 13.087\n",
            "2027-03-01: 13.356\n",
            "2027-04-01: 13.624\n",
            "2027-05-01: 13.892\n",
            "2027-06-01: 14.158\n",
            "2027-07-01: 14.422\n",
            "2027-08-01: 14.685\n",
            "2027-09-01: 14.946\n",
            "2027-10-01: 15.206\n",
            "2027-11-01: 15.464\n",
            "2027-12-01: 15.720\n",
            "2028-01-01: 15.975\n",
            "2028-02-01: 16.227\n",
            "2028-03-01: 16.478\n",
            "2028-04-01: 16.726\n",
            "2028-05-01: 16.972\n",
            "2028-06-01: 17.216\n",
            "2028-07-01: 17.458\n",
            "2028-08-01: 17.698\n",
            "2028-09-01: 17.936\n",
            "2028-10-01: 18.171\n",
            "2028-11-01: 18.404\n",
            "2028-12-01: 18.635\n"
          ]
        }
      ],
      "source": [
        "# prompt: Please generate LSTM model here for this \"LNG(High).xlsx\" file and give accurate output. Forecast values from 2024-04-01 to 2028-12-01\n",
        "\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import LSTM, Dense\n",
        "import pandas as pd\n",
        "from datetime import datetime\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "\n",
        "# Read the dataset\n",
        "df = pd.read_excel('LNG (High).xlsx')\n",
        "\n",
        "# Function to calculate the number of months between two dates\n",
        "def months_between(start_date, end_date):\n",
        "    start_date = datetime.strptime(start_date, \"%Y-%m-%d\")\n",
        "    end_date = datetime.strptime(end_date, \"%Y-%m-%d\")\n",
        "    return (end_date.year - start_date.year) * 12 + end_date.month - start_date.month + 1\n",
        "\n",
        "# Define the date range\n",
        "start_date = '2024-04-01'\n",
        "end_date = '2028-12-01'\n",
        "\n",
        "# Calculate the number of months to predict\n",
        "num_months = months_between(start_date, end_date)\n",
        "\n",
        "# Ensure data is sorted by date\n",
        "df['Date'] = pd.to_datetime(df['Date'], format='%b-%y')\n",
        "df = df.sort_values(by=\"Date\", ascending=True)\n",
        "\n",
        "# Normalize the data\n",
        "scaler = MinMaxScaler(feature_range=(0, 1))\n",
        "df['Price_normalized'] = scaler.fit_transform(df['Price'].values.reshape(-1,1))\n",
        "\n",
        "# Create a new feature representing the number of months since start date\n",
        "df['Months_since_start'] = (df['Date'] - pd.to_datetime(start_date)).dt.days / 30\n",
        "\n",
        "# Prepare data for training\n",
        "X_train = df['Months_since_start'].values.reshape(-1, 1, 1)\n",
        "y_train = df['Price_normalized'].values\n",
        "\n",
        "# Define and train the LSTM model\n",
        "model = Sequential()\n",
        "model.add(LSTM(64, activation='relu', input_shape=(1, 1)))\n",
        "model.add(Dense(1))\n",
        "model.compile(optimizer='adam', loss='mean_squared_error')\n",
        "model.fit(X_train, y_train, epochs=50)\n",
        "\n",
        "# Generate future indices for prediction\n",
        "X_future = np.arange(df['Months_since_start'].iloc[-1] + 1, df['Months_since_start'].iloc[-1] + 1 + num_months)\n",
        "X_future = X_future.reshape(-1, 1, 1)  # Reshape for LSTM input\n",
        "\n",
        "# Generate predictions\n",
        "y_pred_normalized = model.predict(X_future)\n",
        "\n",
        "# Inverse transform predictions to get actual prices\n",
        "y_pred = scaler.inverse_transform(y_pred_normalized)\n",
        "\n",
        "# Ensure predictions are non-negative\n",
        "y_pred = np.maximum(y_pred, 0)\n",
        "\n",
        "# Generate date range for the predictions\n",
        "dates = pd.date_range(start=start_date, periods=num_months, freq='MS')\n",
        "\n",
        "# Print predicted prices with corresponding dates\n",
        "print(\"Predicted prices from 2024-04-01 to 2028-12-01:\")\n",
        "for date, price in zip(dates, y_pred.flatten()):\n",
        "    print(f\"{date.strftime('%Y-%m-%d')}: {price:.3f}\")\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Sog8rCTX5swQ",
        "outputId": "50f65d66-98bf-47e4-e637-ecb53f7f81a0"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/100\n",
            "5/5 [==============================] - 3s 4ms/step - loss: 1.5013\n",
            "Epoch 2/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.1078\n",
            "Epoch 3/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.3035\n",
            "Epoch 4/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.2133\n",
            "Epoch 5/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0580\n",
            "Epoch 6/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0723\n",
            "Epoch 7/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0777\n",
            "Epoch 8/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0445\n",
            "Epoch 9/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0388\n",
            "Epoch 10/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0414\n",
            "Epoch 11/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0336\n",
            "Epoch 12/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0304\n",
            "Epoch 13/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0297\n",
            "Epoch 14/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0267\n",
            "Epoch 15/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0253\n",
            "Epoch 16/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0244\n",
            "Epoch 17/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0234\n",
            "Epoch 18/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0225\n",
            "Epoch 19/100\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0222\n",
            "Epoch 20/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0221\n",
            "Epoch 21/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0222\n",
            "Epoch 22/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0218\n",
            "Epoch 23/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0219\n",
            "Epoch 24/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0217\n",
            "Epoch 25/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0219\n",
            "Epoch 26/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0214\n",
            "Epoch 27/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0214\n",
            "Epoch 28/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0217\n",
            "Epoch 29/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0218\n",
            "Epoch 30/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0211\n",
            "Epoch 31/100\n",
            "5/5 [==============================] - 0s 6ms/step - loss: 0.0213\n",
            "Epoch 32/100\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0210\n",
            "Epoch 33/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0212\n",
            "Epoch 34/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0211\n",
            "Epoch 35/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0210\n",
            "Epoch 36/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0207\n",
            "Epoch 37/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0208\n",
            "Epoch 38/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0205\n",
            "Epoch 39/100\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0210\n",
            "Epoch 40/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0203\n",
            "Epoch 41/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0213\n",
            "Epoch 42/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0209\n",
            "Epoch 43/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0204\n",
            "Epoch 44/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0210\n",
            "Epoch 45/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0204\n",
            "Epoch 46/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0203\n",
            "Epoch 47/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0199\n",
            "Epoch 48/100\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0202\n",
            "Epoch 49/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0199\n",
            "Epoch 50/100\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0199\n",
            "Epoch 51/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0199\n",
            "Epoch 52/100\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0198\n",
            "Epoch 53/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0202\n",
            "Epoch 54/100\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0200\n",
            "Epoch 55/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0198\n",
            "Epoch 56/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0207\n",
            "Epoch 57/100\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 0.0196\n",
            "Epoch 58/100\n",
            "5/5 [==============================] - 0s 6ms/step - loss: 0.0200\n",
            "Epoch 59/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0193\n",
            "Epoch 60/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0194\n",
            "Epoch 61/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0194\n",
            "Epoch 62/100\n",
            "5/5 [==============================] - 0s 6ms/step - loss: 0.0192\n",
            "Epoch 63/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0193\n",
            "Epoch 64/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0199\n",
            "Epoch 65/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0193\n",
            "Epoch 66/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0190\n",
            "Epoch 67/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0193\n",
            "Epoch 68/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0190\n",
            "Epoch 69/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0190\n",
            "Epoch 70/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0196\n",
            "Epoch 71/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0187\n",
            "Epoch 72/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0189\n",
            "Epoch 73/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0186\n",
            "Epoch 74/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0189\n",
            "Epoch 75/100\n",
            "5/5 [==============================] - 0s 6ms/step - loss: 0.0185\n",
            "Epoch 76/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0186\n",
            "Epoch 77/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0185\n",
            "Epoch 78/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0182\n",
            "Epoch 79/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0183\n",
            "Epoch 80/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0181\n",
            "Epoch 81/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0180\n",
            "Epoch 82/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0181\n",
            "Epoch 83/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0180\n",
            "Epoch 84/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0180\n",
            "Epoch 85/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0179\n",
            "Epoch 86/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0181\n",
            "Epoch 87/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0179\n",
            "Epoch 88/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0179\n",
            "Epoch 89/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0176\n",
            "Epoch 90/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0180\n",
            "Epoch 91/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0173\n",
            "Epoch 92/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0177\n",
            "Epoch 93/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0175\n",
            "Epoch 94/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0175\n",
            "Epoch 95/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0173\n",
            "Epoch 96/100\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0173\n",
            "Epoch 97/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0172\n",
            "Epoch 98/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0171\n",
            "Epoch 99/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0170\n",
            "Epoch 100/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0171\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Predicted prices from 2024-04-01 to 2028-12-01:\n",
            "2024-04-01: 2.576\n",
            "2024-05-01: 2.351\n",
            "2024-06-01: 2.110\n",
            "2024-07-01: 1.856\n",
            "2024-08-01: 1.592\n",
            "2024-09-01: 1.319\n",
            "2024-10-01: 1.037\n",
            "2024-11-01: 0.746\n",
            "2024-12-01: 0.447\n",
            "2025-01-01: 0.143\n",
            "2025-02-01: 0.000\n",
            "2025-03-01: 0.000\n",
            "2025-04-01: 0.000\n",
            "2025-05-01: 0.000\n",
            "2025-06-01: 0.000\n",
            "2025-07-01: 0.000\n",
            "2025-08-01: 0.000\n",
            "2025-09-01: 0.000\n",
            "2025-10-01: 0.000\n",
            "2025-11-01: 0.000\n",
            "2025-12-01: 0.000\n",
            "2026-01-01: 0.000\n",
            "2026-02-01: 0.000\n",
            "2026-03-01: 0.000\n",
            "2026-04-01: 0.000\n",
            "2026-05-01: 0.000\n",
            "2026-06-01: 0.000\n",
            "2026-07-01: 0.000\n",
            "2026-08-01: 0.000\n",
            "2026-09-01: 0.000\n",
            "2026-10-01: 0.000\n",
            "2026-11-01: 0.000\n",
            "2026-12-01: 0.000\n",
            "2027-01-01: 0.000\n",
            "2027-02-01: 0.000\n",
            "2027-03-01: 0.000\n",
            "2027-04-01: 0.000\n",
            "2027-05-01: 0.000\n",
            "2027-06-01: 0.000\n",
            "2027-07-01: 0.000\n",
            "2027-08-01: 0.000\n",
            "2027-09-01: 0.000\n",
            "2027-10-01: 0.000\n",
            "2027-11-01: 0.000\n",
            "2027-12-01: 0.000\n",
            "2028-01-01: 0.000\n",
            "2028-02-01: 0.000\n",
            "2028-03-01: 0.000\n",
            "2028-04-01: 0.000\n",
            "2028-05-01: 0.000\n",
            "2028-06-01: 0.000\n",
            "2028-07-01: 0.000\n",
            "2028-08-01: 0.000\n",
            "2028-09-01: 0.000\n",
            "2028-10-01: 0.000\n",
            "2028-11-01: 0.000\n",
            "2028-12-01: 0.000\n"
          ]
        }
      ],
      "source": [
        "# prompt: Predicted prices from 2024-04-01 to 2028-12-01:\n",
        "# 2024-04-01: 3.351\n",
        "# 2024-05-01: 3.701\n",
        "# 2024-06-01: 4.041\n",
        "# 2024-07-01: 4.372\n",
        "# 2024-08-01: 4.693\n",
        "# 2024-09-01: 5.006\n",
        "# 2024-10-01: 5.312\n",
        "# 2024-11-01: 5.611\n",
        "# 2024-12-01: 5.906\n",
        "# 2025-01-01: 6.196\n",
        "# These outputs are incorrect prediction here. The values will be 2.67 in June 2024 and at last not so high. Train your model accordingly and give very accurate output\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "# Read the dataset\n",
        "df = pd.read_excel('LNG (High).xlsx')\n",
        "\n",
        "# Function to calculate the number of months between two dates\n",
        "def months_between(start_date, end_date):\n",
        "    start_date = datetime.strptime(start_date, \"%Y-%m-%d\")\n",
        "    end_date = datetime.strptime(end_date, \"%Y-%m-%d\")\n",
        "    return (end_date.year - start_date.year) * 12 + end_date.month - start_date.month + 1\n",
        "\n",
        "# Define the date range\n",
        "start_date = '2024-04-01'\n",
        "end_date = '2028-12-01'\n",
        "\n",
        "# Calculate the number of months to predict\n",
        "num_months = months_between(start_date, end_date)\n",
        "\n",
        "# Ensure data is sorted by date\n",
        "df['Date'] = pd.to_datetime(df['Date'], format='%b-%y')\n",
        "df = df.sort_values(by=\"Date\", ascending=True)\n",
        "\n",
        "# Normalize the data\n",
        "scaler = MinMaxScaler(feature_range=(0, 1))\n",
        "df['Price_normalized'] = scaler.fit_transform(df['Price'].values.reshape(-1,1))\n",
        "\n",
        "# Create a new feature representing the number of months since start date\n",
        "df['Months_since_start'] = (df['Date'] - pd.to_datetime(start_date)).dt.days / 30\n",
        "\n",
        "# Prepare data for training\n",
        "X_train = df['Months_since_start'].values.reshape(-1, 1, 1)\n",
        "y_train = df['Price_normalized'].values\n",
        "\n",
        "# Define and train the LSTM model\n",
        "model = Sequential()\n",
        "model.add(LSTM(64, activation='relu', input_shape=(1, 1)))\n",
        "model.add(Dense(1))\n",
        "model.compile(optimizer='adam', loss='mean_squared_error')\n",
        "model.fit(X_train, y_train, epochs=100)\n",
        "\n",
        "# Generate future indices for prediction\n",
        "X_future = np.arange(df['Months_since_start'].iloc[-1] + 1, df['Months_since_start'].iloc[-1] + 1 + num_months)\n",
        "X_future = X_future.reshape(-1, 1, 1)  # Reshape for LSTM input\n",
        "\n",
        "# Generate predictions\n",
        "y_pred_normalized = model.predict(X_future)\n",
        "\n",
        "# Inverse transform predictions to get actual prices\n",
        "y_pred = scaler.inverse_transform(y_pred_normalized)\n",
        "\n",
        "# Ensure predictions are non-negative\n",
        "y_pred = np.maximum(y_pred, 0)\n",
        "\n",
        "# Generate date range for the predictions\n",
        "dates = pd.date_range(start=start_date, periods=num_months, freq='MS')\n",
        "\n",
        "# Print predicted prices with corresponding dates\n",
        "print(\"Predicted prices from 2024-04-01 to 2028-12-01:\")\n",
        "for date, price in zip(dates, y_pred.flatten()):\n",
        "    print(f\"{date.strftime('%Y-%m-%d')}: {price:.3f}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "V0rzMKPl6dmX",
        "outputId": "819cbdc4-9bf9-4365-b238-3781521b1ca9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/200\n",
            "19/19 [==============================] - 6s 11ms/step - loss: 0.0896\n",
            "Epoch 2/200\n",
            "19/19 [==============================] - 0s 12ms/step - loss: 0.0896\n",
            "Epoch 3/200\n",
            "19/19 [==============================] - 0s 12ms/step - loss: 0.0896\n",
            "Epoch 4/200\n",
            "19/19 [==============================] - 0s 12ms/step - loss: 0.0896\n",
            "Epoch 5/200\n",
            "19/19 [==============================] - 0s 11ms/step - loss: 0.0896\n",
            "Epoch 6/200\n",
            "19/19 [==============================] - 0s 11ms/step - loss: 0.0896\n",
            "Epoch 7/200\n",
            "19/19 [==============================] - 0s 12ms/step - loss: 0.0896\n",
            "Epoch 8/200\n",
            "19/19 [==============================] - 0s 11ms/step - loss: 0.0896\n",
            "Epoch 9/200\n",
            "19/19 [==============================] - 0s 11ms/step - loss: 0.0896\n",
            "Epoch 10/200\n",
            "19/19 [==============================] - 0s 11ms/step - loss: 0.0896\n",
            "Epoch 11/200\n",
            "19/19 [==============================] - 0s 11ms/step - loss: 0.0896\n",
            "Epoch 12/200\n",
            "19/19 [==============================] - 0s 12ms/step - loss: 0.0896\n",
            "Epoch 13/200\n",
            "19/19 [==============================] - 0s 11ms/step - loss: 0.0896\n",
            "Epoch 14/200\n",
            "19/19 [==============================] - 0s 11ms/step - loss: 0.0896\n",
            "Epoch 15/200\n",
            "19/19 [==============================] - 0s 11ms/step - loss: 0.0896\n",
            "Epoch 16/200\n",
            "19/19 [==============================] - 0s 11ms/step - loss: 0.0896\n",
            "Epoch 17/200\n",
            "19/19 [==============================] - 0s 15ms/step - loss: 0.0896\n",
            "Epoch 18/200\n",
            "19/19 [==============================] - 0s 20ms/step - loss: 0.0896\n",
            "Epoch 19/200\n",
            "19/19 [==============================] - 0s 20ms/step - loss: 0.0896\n",
            "Epoch 20/200\n",
            "19/19 [==============================] - 0s 19ms/step - loss: 0.0896\n",
            "Epoch 21/200\n",
            "19/19 [==============================] - 0s 18ms/step - loss: 0.0896\n",
            "Epoch 22/200\n",
            "19/19 [==============================] - 0s 20ms/step - loss: 0.0896\n",
            "Epoch 23/200\n",
            "19/19 [==============================] - 0s 20ms/step - loss: 0.0896\n",
            "Epoch 24/200\n",
            "19/19 [==============================] - 0s 19ms/step - loss: 0.0896\n",
            "Epoch 25/200\n",
            "19/19 [==============================] - 0s 19ms/step - loss: 0.0896\n",
            "Epoch 26/200\n",
            "19/19 [==============================] - 0s 19ms/step - loss: 0.0896\n",
            "Epoch 27/200\n",
            "19/19 [==============================] - 0s 20ms/step - loss: 0.0896\n",
            "Epoch 28/200\n",
            "19/19 [==============================] - 0s 18ms/step - loss: 0.0896\n",
            "Epoch 29/200\n",
            "19/19 [==============================] - 0s 11ms/step - loss: 0.0896\n",
            "Epoch 30/200\n",
            "19/19 [==============================] - 0s 11ms/step - loss: 0.0896\n",
            "Epoch 31/200\n",
            "19/19 [==============================] - 0s 11ms/step - loss: 0.0896\n",
            "Epoch 32/200\n",
            "19/19 [==============================] - 0s 11ms/step - loss: 0.0896\n",
            "Epoch 33/200\n",
            "19/19 [==============================] - 0s 11ms/step - loss: 0.0896\n",
            "Epoch 34/200\n",
            "19/19 [==============================] - 0s 11ms/step - loss: 0.0896\n",
            "Epoch 35/200\n",
            "19/19 [==============================] - 0s 11ms/step - loss: 0.0896\n",
            "Epoch 36/200\n",
            "19/19 [==============================] - 0s 11ms/step - loss: 0.0896\n",
            "Epoch 37/200\n",
            "19/19 [==============================] - 0s 11ms/step - loss: 0.0896\n",
            "Epoch 38/200\n",
            "19/19 [==============================] - 0s 11ms/step - loss: 0.0896\n",
            "Epoch 39/200\n",
            "19/19 [==============================] - 0s 11ms/step - loss: 0.0896\n",
            "Epoch 40/200\n",
            "19/19 [==============================] - 0s 11ms/step - loss: 0.0896\n",
            "Epoch 41/200\n",
            "19/19 [==============================] - 0s 11ms/step - loss: 0.0896\n",
            "Epoch 42/200\n",
            "19/19 [==============================] - 0s 11ms/step - loss: 0.0896\n",
            "Epoch 43/200\n",
            "19/19 [==============================] - 0s 11ms/step - loss: 0.0896\n",
            "Epoch 44/200\n",
            "19/19 [==============================] - 0s 11ms/step - loss: 0.0896\n",
            "Epoch 45/200\n",
            "19/19 [==============================] - 0s 11ms/step - loss: 0.0896\n",
            "Epoch 46/200\n",
            "19/19 [==============================] - 0s 11ms/step - loss: 0.0896\n",
            "Epoch 47/200\n",
            "19/19 [==============================] - 0s 12ms/step - loss: 0.0896\n",
            "Epoch 48/200\n",
            "19/19 [==============================] - 0s 11ms/step - loss: 0.0896\n",
            "Epoch 49/200\n",
            "19/19 [==============================] - 0s 11ms/step - loss: 0.0896\n",
            "Epoch 50/200\n",
            "19/19 [==============================] - 0s 11ms/step - loss: 0.0896\n",
            "Epoch 51/200\n",
            "19/19 [==============================] - 0s 11ms/step - loss: 0.0896\n",
            "Epoch 52/200\n",
            "19/19 [==============================] - 0s 12ms/step - loss: 0.0896\n",
            "Epoch 53/200\n",
            "19/19 [==============================] - 0s 11ms/step - loss: 0.0896\n",
            "Epoch 54/200\n",
            "19/19 [==============================] - 0s 11ms/step - loss: 0.0896\n",
            "Epoch 55/200\n",
            "19/19 [==============================] - 0s 11ms/step - loss: 0.0896\n",
            "Epoch 56/200\n",
            "19/19 [==============================] - 0s 12ms/step - loss: 0.0896\n",
            "Epoch 57/200\n",
            "19/19 [==============================] - 0s 11ms/step - loss: 0.0896\n",
            "Epoch 58/200\n",
            "19/19 [==============================] - 0s 11ms/step - loss: 0.0896\n",
            "Epoch 59/200\n",
            "19/19 [==============================] - 0s 11ms/step - loss: 0.0896\n",
            "Epoch 60/200\n",
            "19/19 [==============================] - 0s 11ms/step - loss: 0.0896\n",
            "Epoch 61/200\n",
            "19/19 [==============================] - 0s 12ms/step - loss: 0.0896\n",
            "Epoch 62/200\n",
            "19/19 [==============================] - 0s 11ms/step - loss: 0.0896\n",
            "Epoch 63/200\n",
            "19/19 [==============================] - 0s 12ms/step - loss: 0.0896\n",
            "Epoch 64/200\n",
            "19/19 [==============================] - 0s 12ms/step - loss: 0.0896\n",
            "Epoch 65/200\n",
            "19/19 [==============================] - 0s 11ms/step - loss: 0.0896\n",
            "Epoch 66/200\n",
            "19/19 [==============================] - 0s 12ms/step - loss: 0.0896\n",
            "Epoch 67/200\n",
            "19/19 [==============================] - 0s 11ms/step - loss: 0.0896\n",
            "Epoch 68/200\n",
            "19/19 [==============================] - 0s 11ms/step - loss: 0.0896\n",
            "Epoch 69/200\n",
            "19/19 [==============================] - 0s 12ms/step - loss: 0.0896\n",
            "Epoch 70/200\n",
            "19/19 [==============================] - 0s 12ms/step - loss: 0.0896\n",
            "Epoch 71/200\n",
            "19/19 [==============================] - 0s 12ms/step - loss: 0.0896\n",
            "Epoch 72/200\n",
            "19/19 [==============================] - 0s 12ms/step - loss: 0.0896\n",
            "Epoch 73/200\n",
            "19/19 [==============================] - 0s 13ms/step - loss: 0.0896\n",
            "Epoch 74/200\n",
            "19/19 [==============================] - 0s 21ms/step - loss: 0.0896\n",
            "Epoch 75/200\n",
            "19/19 [==============================] - 0s 20ms/step - loss: 0.0896\n",
            "Epoch 76/200\n",
            "19/19 [==============================] - 0s 20ms/step - loss: 0.0896\n",
            "Epoch 77/200\n",
            "19/19 [==============================] - 0s 20ms/step - loss: 0.0896\n",
            "Epoch 78/200\n",
            "19/19 [==============================] - 0s 20ms/step - loss: 0.0896\n",
            "Epoch 79/200\n",
            "19/19 [==============================] - 0s 20ms/step - loss: 0.0896\n",
            "Epoch 80/200\n",
            "19/19 [==============================] - 0s 21ms/step - loss: 0.0896\n",
            "Epoch 81/200\n",
            "19/19 [==============================] - 0s 20ms/step - loss: 0.0896\n",
            "Epoch 82/200\n",
            "19/19 [==============================] - 0s 20ms/step - loss: 0.0896\n",
            "Epoch 83/200\n",
            "19/19 [==============================] - 0s 20ms/step - loss: 0.0896\n",
            "Epoch 84/200\n",
            "19/19 [==============================] - 0s 12ms/step - loss: 0.0896\n",
            "Epoch 85/200\n",
            "19/19 [==============================] - 0s 11ms/step - loss: 0.0896\n",
            "Epoch 86/200\n",
            "19/19 [==============================] - 0s 12ms/step - loss: 0.0896\n",
            "Epoch 87/200\n",
            "19/19 [==============================] - 0s 12ms/step - loss: 0.0896\n",
            "Epoch 88/200\n",
            "19/19 [==============================] - 0s 12ms/step - loss: 0.0896\n",
            "Epoch 89/200\n",
            "19/19 [==============================] - 0s 12ms/step - loss: 0.0896\n",
            "Epoch 90/200\n",
            "19/19 [==============================] - 0s 12ms/step - loss: 0.0896\n",
            "Epoch 91/200\n",
            "19/19 [==============================] - 0s 12ms/step - loss: 0.0896\n",
            "Epoch 92/200\n",
            "19/19 [==============================] - 0s 12ms/step - loss: 0.0896\n",
            "Epoch 93/200\n",
            "19/19 [==============================] - 0s 13ms/step - loss: 0.0896\n",
            "Epoch 94/200\n",
            "19/19 [==============================] - 0s 11ms/step - loss: 0.0896\n",
            "Epoch 95/200\n",
            "19/19 [==============================] - 0s 12ms/step - loss: 0.0896\n",
            "Epoch 96/200\n",
            "19/19 [==============================] - 0s 11ms/step - loss: 0.0896\n",
            "Epoch 97/200\n",
            "19/19 [==============================] - 0s 11ms/step - loss: 0.0896\n",
            "Epoch 98/200\n",
            "19/19 [==============================] - 0s 11ms/step - loss: 0.0896\n",
            "Epoch 99/200\n",
            "19/19 [==============================] - 0s 12ms/step - loss: 0.0896\n",
            "Epoch 100/200\n",
            "19/19 [==============================] - 0s 11ms/step - loss: 0.0896\n",
            "Epoch 101/200\n",
            "19/19 [==============================] - 0s 11ms/step - loss: 0.0896\n",
            "Epoch 102/200\n",
            "19/19 [==============================] - 0s 11ms/step - loss: 0.0896\n",
            "Epoch 103/200\n",
            "19/19 [==============================] - 0s 11ms/step - loss: 0.0896\n",
            "Epoch 104/200\n",
            "19/19 [==============================] - 0s 12ms/step - loss: 0.0896\n",
            "Epoch 105/200\n",
            "19/19 [==============================] - 0s 12ms/step - loss: 0.0896\n",
            "Epoch 106/200\n",
            "19/19 [==============================] - 0s 11ms/step - loss: 0.0896\n",
            "Epoch 107/200\n",
            "19/19 [==============================] - 0s 11ms/step - loss: 0.0896\n",
            "Epoch 108/200\n",
            "19/19 [==============================] - 0s 11ms/step - loss: 0.0896\n",
            "Epoch 109/200\n",
            "19/19 [==============================] - 0s 12ms/step - loss: 0.0896\n",
            "Epoch 110/200\n",
            "19/19 [==============================] - 0s 11ms/step - loss: 0.0896\n",
            "Epoch 111/200\n",
            "19/19 [==============================] - 0s 11ms/step - loss: 0.0896\n",
            "Epoch 112/200\n",
            "19/19 [==============================] - 0s 11ms/step - loss: 0.0896\n",
            "Epoch 113/200\n",
            "19/19 [==============================] - 0s 12ms/step - loss: 0.0896\n",
            "Epoch 114/200\n",
            "19/19 [==============================] - 0s 11ms/step - loss: 0.0896\n",
            "Epoch 115/200\n",
            "19/19 [==============================] - 0s 11ms/step - loss: 0.0896\n",
            "Epoch 116/200\n",
            "19/19 [==============================] - 0s 11ms/step - loss: 0.0896\n",
            "Epoch 117/200\n",
            "19/19 [==============================] - 0s 11ms/step - loss: 0.0896\n",
            "Epoch 118/200\n",
            "19/19 [==============================] - 0s 12ms/step - loss: 0.0896\n",
            "Epoch 119/200\n",
            "19/19 [==============================] - 0s 11ms/step - loss: 0.0896\n",
            "Epoch 120/200\n",
            "19/19 [==============================] - 0s 11ms/step - loss: 0.0896\n",
            "Epoch 121/200\n",
            "19/19 [==============================] - 0s 11ms/step - loss: 0.0896\n",
            "Epoch 122/200\n",
            "19/19 [==============================] - 0s 11ms/step - loss: 0.0896\n",
            "Epoch 123/200\n",
            "19/19 [==============================] - 0s 12ms/step - loss: 0.0896\n",
            "Epoch 124/200\n",
            "19/19 [==============================] - 0s 11ms/step - loss: 0.0896\n",
            "Epoch 125/200\n",
            "19/19 [==============================] - 0s 11ms/step - loss: 0.0896\n",
            "Epoch 126/200\n",
            "19/19 [==============================] - 0s 11ms/step - loss: 0.0896\n",
            "Epoch 127/200\n",
            "19/19 [==============================] - 0s 12ms/step - loss: 0.0896\n",
            "Epoch 128/200\n",
            "19/19 [==============================] - 0s 14ms/step - loss: 0.0896\n",
            "Epoch 129/200\n",
            "19/19 [==============================] - 0s 19ms/step - loss: 0.0896\n",
            "Epoch 130/200\n",
            "19/19 [==============================] - 0s 21ms/step - loss: 0.0896\n",
            "Epoch 131/200\n",
            "19/19 [==============================] - 0s 19ms/step - loss: 0.0896\n",
            "Epoch 132/200\n",
            "19/19 [==============================] - 0s 19ms/step - loss: 0.0896\n",
            "Epoch 133/200\n",
            "19/19 [==============================] - 0s 21ms/step - loss: 0.0896\n",
            "Epoch 134/200\n",
            "19/19 [==============================] - 0s 20ms/step - loss: 0.0896\n",
            "Epoch 135/200\n",
            "19/19 [==============================] - 0s 18ms/step - loss: 0.0896\n",
            "Epoch 136/200\n",
            "19/19 [==============================] - 0s 20ms/step - loss: 0.0896\n",
            "Epoch 137/200\n",
            "19/19 [==============================] - 0s 20ms/step - loss: 0.0896\n",
            "Epoch 138/200\n",
            "19/19 [==============================] - 0s 21ms/step - loss: 0.0896\n",
            "Epoch 139/200\n",
            "19/19 [==============================] - 0s 18ms/step - loss: 0.0896\n",
            "Epoch 140/200\n",
            "19/19 [==============================] - 0s 11ms/step - loss: 0.0896\n",
            "Epoch 141/200\n",
            "19/19 [==============================] - 0s 11ms/step - loss: 0.0896\n",
            "Epoch 142/200\n",
            "19/19 [==============================] - 0s 11ms/step - loss: 0.0896\n",
            "Epoch 143/200\n",
            "19/19 [==============================] - 0s 12ms/step - loss: 0.0896\n",
            "Epoch 144/200\n",
            "19/19 [==============================] - 0s 12ms/step - loss: 0.0896\n",
            "Epoch 145/200\n",
            "19/19 [==============================] - 0s 11ms/step - loss: 0.0896\n",
            "Epoch 146/200\n",
            "19/19 [==============================] - 0s 11ms/step - loss: 0.0896\n",
            "Epoch 147/200\n",
            "19/19 [==============================] - 0s 12ms/step - loss: 0.0896\n",
            "Epoch 148/200\n",
            "19/19 [==============================] - 0s 11ms/step - loss: 0.0896\n",
            "Epoch 149/200\n",
            "19/19 [==============================] - 0s 11ms/step - loss: 0.0896\n",
            "Epoch 150/200\n",
            "19/19 [==============================] - 0s 12ms/step - loss: 0.0896\n",
            "Epoch 151/200\n",
            "19/19 [==============================] - 0s 11ms/step - loss: 0.0896\n",
            "Epoch 152/200\n",
            "19/19 [==============================] - 0s 12ms/step - loss: 0.0896\n",
            "Epoch 153/200\n",
            "19/19 [==============================] - 0s 11ms/step - loss: 0.0896\n",
            "Epoch 154/200\n",
            "19/19 [==============================] - 0s 11ms/step - loss: 0.0896\n",
            "Epoch 155/200\n",
            "19/19 [==============================] - 0s 11ms/step - loss: 0.0896\n",
            "Epoch 156/200\n",
            "19/19 [==============================] - 0s 12ms/step - loss: 0.0896\n",
            "Epoch 157/200\n",
            "19/19 [==============================] - 0s 12ms/step - loss: 0.0896\n",
            "Epoch 158/200\n",
            "19/19 [==============================] - 0s 11ms/step - loss: 0.0896\n",
            "Epoch 159/200\n",
            "19/19 [==============================] - 0s 11ms/step - loss: 0.0896\n",
            "Epoch 160/200\n",
            "19/19 [==============================] - 0s 11ms/step - loss: 0.0896\n",
            "Epoch 161/200\n",
            "19/19 [==============================] - 0s 12ms/step - loss: 0.0896\n",
            "Epoch 162/200\n",
            "19/19 [==============================] - 0s 11ms/step - loss: 0.0896\n",
            "Epoch 163/200\n",
            "19/19 [==============================] - 0s 11ms/step - loss: 0.0896\n",
            "Epoch 164/200\n",
            "19/19 [==============================] - 0s 11ms/step - loss: 0.0896\n",
            "Epoch 165/200\n",
            "19/19 [==============================] - 0s 11ms/step - loss: 0.0896\n",
            "Epoch 166/200\n",
            "19/19 [==============================] - 0s 12ms/step - loss: 0.0896\n",
            "Epoch 167/200\n",
            "19/19 [==============================] - 0s 11ms/step - loss: 0.0896\n",
            "Epoch 168/200\n",
            "19/19 [==============================] - 0s 11ms/step - loss: 0.0896\n",
            "Epoch 169/200\n",
            "19/19 [==============================] - 0s 11ms/step - loss: 0.0896\n",
            "Epoch 170/200\n",
            "19/19 [==============================] - 0s 11ms/step - loss: 0.0896\n",
            "Epoch 171/200\n",
            "19/19 [==============================] - 0s 11ms/step - loss: 0.0896\n",
            "Epoch 172/200\n",
            "19/19 [==============================] - 0s 11ms/step - loss: 0.0896\n",
            "Epoch 173/200\n",
            "19/19 [==============================] - 0s 11ms/step - loss: 0.0896\n",
            "Epoch 174/200\n",
            "19/19 [==============================] - 0s 11ms/step - loss: 0.0896\n",
            "Epoch 175/200\n",
            "19/19 [==============================] - 0s 12ms/step - loss: 0.0896\n",
            "Epoch 176/200\n",
            "19/19 [==============================] - 0s 11ms/step - loss: 0.0896\n",
            "Epoch 177/200\n",
            "19/19 [==============================] - 0s 11ms/step - loss: 0.0896\n",
            "Epoch 178/200\n",
            "19/19 [==============================] - 0s 11ms/step - loss: 0.0896\n",
            "Epoch 179/200\n",
            "19/19 [==============================] - 0s 11ms/step - loss: 0.0896\n",
            "Epoch 180/200\n",
            "19/19 [==============================] - 0s 12ms/step - loss: 0.0896\n",
            "Epoch 181/200\n",
            "19/19 [==============================] - 0s 12ms/step - loss: 0.0896\n",
            "Epoch 182/200\n",
            "19/19 [==============================] - 0s 12ms/step - loss: 0.0896\n",
            "Epoch 183/200\n",
            "19/19 [==============================] - 0s 12ms/step - loss: 0.0896\n",
            "Epoch 184/200\n",
            "19/19 [==============================] - 0s 21ms/step - loss: 0.0896\n",
            "Epoch 185/200\n",
            "19/19 [==============================] - 0s 19ms/step - loss: 0.0896\n",
            "Epoch 186/200\n",
            "19/19 [==============================] - 0s 19ms/step - loss: 0.0896\n",
            "Epoch 187/200\n",
            "19/19 [==============================] - 0s 20ms/step - loss: 0.0896\n",
            "Epoch 188/200\n",
            "19/19 [==============================] - 0s 19ms/step - loss: 0.0896\n",
            "Epoch 189/200\n",
            "19/19 [==============================] - 0s 20ms/step - loss: 0.0896\n",
            "Epoch 190/200\n",
            "19/19 [==============================] - 0s 20ms/step - loss: 0.0896\n",
            "Epoch 191/200\n",
            "19/19 [==============================] - 0s 19ms/step - loss: 0.0896\n",
            "Epoch 192/200\n",
            "19/19 [==============================] - 0s 20ms/step - loss: 0.0896\n",
            "Epoch 193/200\n",
            "19/19 [==============================] - 0s 19ms/step - loss: 0.0896\n",
            "Epoch 194/200\n",
            "19/19 [==============================] - 0s 20ms/step - loss: 0.0896\n",
            "Epoch 195/200\n",
            "19/19 [==============================] - 0s 16ms/step - loss: 0.0896\n",
            "Epoch 196/200\n",
            "19/19 [==============================] - 0s 11ms/step - loss: 0.0896\n",
            "Epoch 197/200\n",
            "19/19 [==============================] - 0s 11ms/step - loss: 0.0896\n",
            "Epoch 198/200\n",
            "19/19 [==============================] - 0s 11ms/step - loss: 0.0896\n",
            "Epoch 199/200\n",
            "19/19 [==============================] - 0s 11ms/step - loss: 0.0896\n",
            "Epoch 200/200\n",
            "19/19 [==============================] - 0s 12ms/step - loss: 0.0896\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Predicted prices from 2024-04-01 to 2028-12-01:\n",
            "2024-04-01: 1.864\n",
            "2024-05-01: 1.864\n",
            "2024-06-01: 1.864\n",
            "2024-07-01: 1.864\n",
            "2024-08-01: 1.864\n",
            "2024-09-01: 1.864\n",
            "2024-10-01: 1.864\n",
            "2024-11-01: 1.864\n",
            "2024-12-01: 1.864\n",
            "2025-01-01: 1.864\n",
            "2025-02-01: 1.864\n",
            "2025-03-01: 1.864\n",
            "2025-04-01: 1.864\n",
            "2025-05-01: 1.864\n",
            "2025-06-01: 1.864\n",
            "2025-07-01: 1.864\n",
            "2025-08-01: 1.864\n",
            "2025-09-01: 1.864\n",
            "2025-10-01: 1.864\n",
            "2025-11-01: 1.864\n",
            "2025-12-01: 1.864\n",
            "2026-01-01: 1.864\n",
            "2026-02-01: 1.864\n",
            "2026-03-01: 1.864\n",
            "2026-04-01: 1.864\n",
            "2026-05-01: 1.864\n",
            "2026-06-01: 1.864\n",
            "2026-07-01: 1.864\n",
            "2026-08-01: 1.864\n",
            "2026-09-01: 1.864\n",
            "2026-10-01: 1.864\n",
            "2026-11-01: 1.864\n",
            "2026-12-01: 1.864\n",
            "2027-01-01: 1.864\n",
            "2027-02-01: 1.864\n",
            "2027-03-01: 1.864\n",
            "2027-04-01: 1.864\n",
            "2027-05-01: 1.864\n",
            "2027-06-01: 1.864\n",
            "2027-07-01: 1.864\n",
            "2027-08-01: 1.864\n",
            "2027-09-01: 1.864\n",
            "2027-10-01: 1.864\n",
            "2027-11-01: 1.864\n",
            "2027-12-01: 1.864\n",
            "2028-01-01: 1.864\n",
            "2028-02-01: 1.864\n",
            "2028-03-01: 1.864\n",
            "2028-04-01: 1.864\n",
            "2028-05-01: 1.864\n",
            "2028-06-01: 1.864\n",
            "2028-07-01: 1.864\n",
            "2028-08-01: 1.864\n",
            "2028-09-01: 1.864\n",
            "2028-10-01: 1.864\n",
            "2028-11-01: 1.864\n",
            "2028-12-01: 1.864\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from datetime import datetime\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import LSTM, Dense\n",
        "\n",
        "# Read the dataset\n",
        "df = pd.read_excel('LNG (High).xlsx')\n",
        "\n",
        "# Function to calculate the number of months between two dates\n",
        "def months_between(start_date, end_date):\n",
        "    start_date = datetime.strptime(start_date, \"%Y-%m-%d\")\n",
        "    end_date = datetime.strptime(end_date, \"%Y-%m-%d\")\n",
        "    return (end_date.year - start_date.year) * 12 + end_date.month - start_date.month + 1\n",
        "\n",
        "# Define the date range\n",
        "start_date = '2024-04-01'\n",
        "end_date = '2028-12-01'\n",
        "\n",
        "# Calculate the number of months to predict\n",
        "num_months = months_between(start_date, end_date)\n",
        "\n",
        "# Ensure data is sorted by date\n",
        "df['Date'] = pd.to_datetime(df['Date'], format='%b-%y')\n",
        "df = df.sort_values(by=\"Date\", ascending=True)\n",
        "\n",
        "# Normalize the data\n",
        "scaler = MinMaxScaler(feature_range=(0, 1))\n",
        "df['Price_normalized'] = scaler.fit_transform(df['Price'].values.reshape(-1,1))\n",
        "\n",
        "# Create a new feature representing the number of months since start date\n",
        "df['Months_since_start'] = (df['Date'] - pd.to_datetime(start_date)).dt.days / 30\n",
        "\n",
        "# Prepare data for training\n",
        "X_train = df['Months_since_start'].values.reshape(-1, 1, 1)\n",
        "y_train = df['Price_normalized'].values\n",
        "\n",
        "# Define and train the LSTM model\n",
        "model = Sequential()\n",
        "model.add(LSTM(256, activation='relu', return_sequences=True, input_shape=(1, 1)))\n",
        "model.add(LSTM(128, activation='relu', return_sequences=True))\n",
        "model.add(LSTM(64, activation='relu'))\n",
        "model.add(Dense(32, activation='relu'))\n",
        "model.add(Dense(1, activation='relu'))\n",
        "model.compile(optimizer='adam', loss='mean_squared_error')\n",
        "model.fit(X_train, y_train, epochs=200, batch_size=8)\n",
        "\n",
        "# Generate future indices for prediction\n",
        "X_future = np.arange(df['Months_since_start'].iloc[-1] + 1, df['Months_since_start'].iloc[-1] + 1 + num_months)\n",
        "X_future = X_future.reshape(-1, 1, 1)  # Reshape for LSTM input\n",
        "\n",
        "# Generate predictions\n",
        "y_pred_normalized = model.predict(X_future)\n",
        "\n",
        "# Introduce some randomness or noise to the predictions\n",
        "noise_factor = 0.05  # Adjust the noise factor as needed\n",
        "y_pred_normalized_noisy = y_pred_normalized * np.random.uniform(1 - noise_factor, 1 + noise_factor, size=y_pred_normalized.shape)\n",
        "\n",
        "# Inverse transform predictions to get actual prices\n",
        "y_pred = scaler.inverse_transform(y_pred_normalized_noisy)\n",
        "\n",
        "# Ensure predictions are non-negative\n",
        "y_pred = np.maximum(y_pred, 0)\n",
        "\n",
        "# Generate date range for the predictions\n",
        "dates = pd.date_range(start=start_date, periods=num_months, freq='MS')\n",
        "\n",
        "# Print predicted prices with corresponding dates\n",
        "print(\"Predicted prices from 2024-04-01 to 2028-12-01:\")\n",
        "for date, price in zip(dates, y_pred.flatten()):\n",
        "    print(f\"{date.strftime('%Y-%m-%d')}: {price:.3f}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QefOcQAb7GGM",
        "outputId": "387e3e79-a67a-4ed2-9501-b76393b1bd21"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/200\n",
            "19/19 [==============================] - 7s 12ms/step - loss: 0.0576\n",
            "Epoch 2/200\n",
            "19/19 [==============================] - 0s 14ms/step - loss: 0.0409\n",
            "Epoch 3/200\n",
            "19/19 [==============================] - 0s 12ms/step - loss: 0.0312\n",
            "Epoch 4/200\n",
            "19/19 [==============================] - 0s 11ms/step - loss: 0.0217\n",
            "Epoch 5/200\n",
            "19/19 [==============================] - 0s 12ms/step - loss: 0.0211\n",
            "Epoch 6/200\n",
            "19/19 [==============================] - 0s 11ms/step - loss: 0.0206\n",
            "Epoch 7/200\n",
            "19/19 [==============================] - 0s 12ms/step - loss: 0.0173\n",
            "Epoch 8/200\n",
            "19/19 [==============================] - 0s 11ms/step - loss: 0.0231\n",
            "Epoch 9/200\n",
            "19/19 [==============================] - 0s 11ms/step - loss: 0.0245\n",
            "Epoch 10/200\n",
            "19/19 [==============================] - 0s 11ms/step - loss: 0.0214\n",
            "Epoch 11/200\n",
            "19/19 [==============================] - 0s 12ms/step - loss: 0.0183\n",
            "Epoch 12/200\n",
            "19/19 [==============================] - 0s 16ms/step - loss: 0.0178\n",
            "Epoch 13/200\n",
            "19/19 [==============================] - 0s 20ms/step - loss: 0.0152\n",
            "Epoch 14/200\n",
            "19/19 [==============================] - 0s 22ms/step - loss: 0.0178\n",
            "Epoch 15/200\n",
            "19/19 [==============================] - 0s 20ms/step - loss: 0.0166\n",
            "Epoch 16/200\n",
            "19/19 [==============================] - 0s 20ms/step - loss: 0.0157\n",
            "Epoch 17/200\n",
            "19/19 [==============================] - 0s 22ms/step - loss: 0.0157\n",
            "Epoch 18/200\n",
            "19/19 [==============================] - 0s 21ms/step - loss: 0.0158\n",
            "Epoch 19/200\n",
            "19/19 [==============================] - 0s 20ms/step - loss: 0.0130\n",
            "Epoch 20/200\n",
            "19/19 [==============================] - 0s 20ms/step - loss: 0.0137\n",
            "Epoch 21/200\n",
            "19/19 [==============================] - 0s 20ms/step - loss: 0.0148\n",
            "Epoch 22/200\n",
            "19/19 [==============================] - 0s 20ms/step - loss: 0.0200\n",
            "Epoch 23/200\n",
            "19/19 [==============================] - 0s 12ms/step - loss: 0.0150\n",
            "Epoch 24/200\n",
            "19/19 [==============================] - 0s 12ms/step - loss: 0.0152\n",
            "Epoch 25/200\n",
            "19/19 [==============================] - 0s 12ms/step - loss: 0.0141\n",
            "Epoch 26/200\n",
            "19/19 [==============================] - 0s 12ms/step - loss: 0.0120\n",
            "Epoch 27/200\n",
            "19/19 [==============================] - 0s 12ms/step - loss: 0.0107\n",
            "Epoch 28/200\n",
            "19/19 [==============================] - 0s 13ms/step - loss: 0.0195\n",
            "Epoch 29/200\n",
            "19/19 [==============================] - 0s 12ms/step - loss: 0.0282\n",
            "Epoch 30/200\n",
            "19/19 [==============================] - 0s 12ms/step - loss: 0.0141\n",
            "Epoch 31/200\n",
            "19/19 [==============================] - 0s 12ms/step - loss: 0.0141\n",
            "Epoch 32/200\n",
            "19/19 [==============================] - 0s 11ms/step - loss: 0.0109\n",
            "Epoch 33/200\n",
            "19/19 [==============================] - 0s 11ms/step - loss: 0.0104\n",
            "Epoch 34/200\n",
            "19/19 [==============================] - 0s 11ms/step - loss: 0.0096\n",
            "Epoch 35/200\n",
            "19/19 [==============================] - 0s 13ms/step - loss: 0.0120\n",
            "Epoch 36/200\n",
            "19/19 [==============================] - 0s 12ms/step - loss: 0.0154\n",
            "Epoch 37/200\n",
            "19/19 [==============================] - 0s 12ms/step - loss: 0.0102\n",
            "Epoch 38/200\n",
            "19/19 [==============================] - 0s 12ms/step - loss: 0.0098\n",
            "Epoch 39/200\n",
            "19/19 [==============================] - 0s 12ms/step - loss: 0.0103\n",
            "Epoch 40/200\n",
            "19/19 [==============================] - 0s 13ms/step - loss: 0.0109\n",
            "Epoch 41/200\n",
            "19/19 [==============================] - 0s 12ms/step - loss: 0.0091\n",
            "Epoch 42/200\n",
            "19/19 [==============================] - 0s 12ms/step - loss: 0.0137\n",
            "Epoch 43/200\n",
            "19/19 [==============================] - 0s 12ms/step - loss: 0.0126\n",
            "Epoch 44/200\n",
            "19/19 [==============================] - 0s 13ms/step - loss: 0.0128\n",
            "Epoch 45/200\n",
            "19/19 [==============================] - 0s 12ms/step - loss: 0.0106\n",
            "Epoch 46/200\n",
            "19/19 [==============================] - 0s 12ms/step - loss: 0.0099\n",
            "Epoch 47/200\n",
            "19/19 [==============================] - 0s 12ms/step - loss: 0.0089\n",
            "Epoch 48/200\n",
            "19/19 [==============================] - 0s 12ms/step - loss: 0.0086\n",
            "Epoch 49/200\n",
            "19/19 [==============================] - 0s 12ms/step - loss: 0.0089\n",
            "Epoch 50/200\n",
            "19/19 [==============================] - 0s 12ms/step - loss: 0.0123\n",
            "Epoch 51/200\n",
            "19/19 [==============================] - 0s 13ms/step - loss: 0.0119\n",
            "Epoch 52/200\n",
            "19/19 [==============================] - 0s 12ms/step - loss: 0.0095\n",
            "Epoch 53/200\n",
            "19/19 [==============================] - 0s 13ms/step - loss: 0.0102\n",
            "Epoch 54/200\n",
            "19/19 [==============================] - 0s 12ms/step - loss: 0.0104\n",
            "Epoch 55/200\n",
            "19/19 [==============================] - 0s 12ms/step - loss: 0.0092\n",
            "Epoch 56/200\n",
            "19/19 [==============================] - 0s 12ms/step - loss: 0.0094\n",
            "Epoch 57/200\n",
            "19/19 [==============================] - 0s 13ms/step - loss: 0.0096\n",
            "Epoch 58/200\n",
            "19/19 [==============================] - 0s 12ms/step - loss: 0.0083\n",
            "Epoch 59/200\n",
            "19/19 [==============================] - 0s 12ms/step - loss: 0.0089\n",
            "Epoch 60/200\n",
            "19/19 [==============================] - 0s 12ms/step - loss: 0.0078\n",
            "Epoch 61/200\n",
            "19/19 [==============================] - 0s 12ms/step - loss: 0.0098\n",
            "Epoch 62/200\n",
            "19/19 [==============================] - 0s 12ms/step - loss: 0.0095\n",
            "Epoch 63/200\n",
            "19/19 [==============================] - 0s 12ms/step - loss: 0.0105\n",
            "Epoch 64/200\n",
            "19/19 [==============================] - 0s 12ms/step - loss: 0.0111\n",
            "Epoch 65/200\n",
            "19/19 [==============================] - 0s 17ms/step - loss: 0.0092\n",
            "Epoch 66/200\n",
            "19/19 [==============================] - 0s 21ms/step - loss: 0.0091\n",
            "Epoch 67/200\n",
            "19/19 [==============================] - 0s 21ms/step - loss: 0.0074\n",
            "Epoch 68/200\n",
            "19/19 [==============================] - 0s 22ms/step - loss: 0.0079\n",
            "Epoch 69/200\n",
            "19/19 [==============================] - 0s 21ms/step - loss: 0.0073\n",
            "Epoch 70/200\n",
            "19/19 [==============================] - 0s 21ms/step - loss: 0.0080\n",
            "Epoch 71/200\n",
            "19/19 [==============================] - 0s 23ms/step - loss: 0.0073\n",
            "Epoch 72/200\n",
            "19/19 [==============================] - 1s 27ms/step - loss: 0.0071\n",
            "Epoch 73/200\n",
            "19/19 [==============================] - 0s 23ms/step - loss: 0.0073\n",
            "Epoch 74/200\n",
            "19/19 [==============================] - 0s 21ms/step - loss: 0.0085\n",
            "Epoch 75/200\n",
            "19/19 [==============================] - 0s 13ms/step - loss: 0.0089\n",
            "Epoch 76/200\n",
            "19/19 [==============================] - 0s 13ms/step - loss: 0.0098\n",
            "Epoch 77/200\n",
            "19/19 [==============================] - 0s 12ms/step - loss: 0.0117\n",
            "Epoch 78/200\n",
            "19/19 [==============================] - 0s 12ms/step - loss: 0.0094\n",
            "Epoch 79/200\n",
            "19/19 [==============================] - 0s 12ms/step - loss: 0.0077\n",
            "Epoch 80/200\n",
            "19/19 [==============================] - 0s 12ms/step - loss: 0.0102\n",
            "Epoch 81/200\n",
            "19/19 [==============================] - 0s 13ms/step - loss: 0.0103\n",
            "Epoch 82/200\n",
            "19/19 [==============================] - 0s 12ms/step - loss: 0.0086\n",
            "Epoch 83/200\n",
            "19/19 [==============================] - 0s 12ms/step - loss: 0.0085\n",
            "Epoch 84/200\n",
            "19/19 [==============================] - 0s 12ms/step - loss: 0.0082\n",
            "Epoch 85/200\n",
            "19/19 [==============================] - 0s 13ms/step - loss: 0.0086\n",
            "Epoch 86/200\n",
            "19/19 [==============================] - 0s 12ms/step - loss: 0.0106\n",
            "Epoch 87/200\n",
            "19/19 [==============================] - 0s 12ms/step - loss: 0.0097\n",
            "Epoch 88/200\n",
            "19/19 [==============================] - 0s 12ms/step - loss: 0.0092\n",
            "Epoch 89/200\n",
            "19/19 [==============================] - 0s 13ms/step - loss: 0.0084\n",
            "Epoch 90/200\n",
            "19/19 [==============================] - 0s 12ms/step - loss: 0.0086\n",
            "Epoch 91/200\n",
            "19/19 [==============================] - 0s 12ms/step - loss: 0.0082\n",
            "Epoch 92/200\n",
            "19/19 [==============================] - 0s 12ms/step - loss: 0.0086\n",
            "Epoch 93/200\n",
            "19/19 [==============================] - 0s 11ms/step - loss: 0.0084\n",
            "Epoch 94/200\n",
            "19/19 [==============================] - 0s 13ms/step - loss: 0.0098\n",
            "Epoch 95/200\n",
            "19/19 [==============================] - 0s 16ms/step - loss: 0.0085\n",
            "Epoch 96/200\n",
            "19/19 [==============================] - 0s 21ms/step - loss: 0.0082\n",
            "Epoch 97/200\n",
            "19/19 [==============================] - 0s 21ms/step - loss: 0.0079\n",
            "Epoch 98/200\n",
            "19/19 [==============================] - 0s 19ms/step - loss: 0.0083\n",
            "Epoch 99/200\n",
            "19/19 [==============================] - 0s 20ms/step - loss: 0.0079\n",
            "Epoch 100/200\n",
            "19/19 [==============================] - 0s 22ms/step - loss: 0.0076\n",
            "Epoch 101/200\n",
            "19/19 [==============================] - 0s 22ms/step - loss: 0.0080\n",
            "Epoch 102/200\n",
            "19/19 [==============================] - 0s 21ms/step - loss: 0.0082\n",
            "Epoch 103/200\n",
            "19/19 [==============================] - 0s 20ms/step - loss: 0.0097\n",
            "Epoch 104/200\n",
            "19/19 [==============================] - 0s 20ms/step - loss: 0.0085\n",
            "Epoch 105/200\n",
            "19/19 [==============================] - 0s 21ms/step - loss: 0.0095\n",
            "Epoch 106/200\n",
            "19/19 [==============================] - 0s 13ms/step - loss: 0.0076\n",
            "Epoch 107/200\n",
            "19/19 [==============================] - 0s 12ms/step - loss: 0.0073\n",
            "Epoch 108/200\n",
            "19/19 [==============================] - 0s 12ms/step - loss: 0.0074\n",
            "Epoch 109/200\n",
            "19/19 [==============================] - 0s 14ms/step - loss: 0.0082\n",
            "Epoch 110/200\n",
            "19/19 [==============================] - 0s 20ms/step - loss: 0.0076\n",
            "Epoch 111/200\n",
            "19/19 [==============================] - 0s 20ms/step - loss: 0.0069\n",
            "Epoch 112/200\n",
            "19/19 [==============================] - 0s 20ms/step - loss: 0.0077\n",
            "Epoch 113/200\n",
            "19/19 [==============================] - 0s 20ms/step - loss: 0.0074\n",
            "Epoch 114/200\n",
            "19/19 [==============================] - 0s 21ms/step - loss: 0.0076\n",
            "Epoch 115/200\n",
            "19/19 [==============================] - 0s 21ms/step - loss: 0.0098\n",
            "Epoch 116/200\n",
            "19/19 [==============================] - 0s 20ms/step - loss: 0.0081\n",
            "Epoch 117/200\n",
            "19/19 [==============================] - 0s 21ms/step - loss: 0.0076\n",
            "Epoch 118/200\n",
            "19/19 [==============================] - 0s 20ms/step - loss: 0.0084\n",
            "Epoch 119/200\n",
            "19/19 [==============================] - 0s 20ms/step - loss: 0.0081\n",
            "Epoch 120/200\n",
            "19/19 [==============================] - 0s 15ms/step - loss: 0.0077\n",
            "Epoch 121/200\n",
            "19/19 [==============================] - 0s 12ms/step - loss: 0.0080\n",
            "Epoch 122/200\n",
            "19/19 [==============================] - 0s 12ms/step - loss: 0.0075\n",
            "Epoch 123/200\n",
            "19/19 [==============================] - 0s 12ms/step - loss: 0.0076\n",
            "Epoch 124/200\n",
            "19/19 [==============================] - 0s 13ms/step - loss: 0.0077\n",
            "Epoch 125/200\n",
            "19/19 [==============================] - 0s 12ms/step - loss: 0.0083\n",
            "Epoch 126/200\n",
            "19/19 [==============================] - 0s 12ms/step - loss: 0.0083\n",
            "Epoch 127/200\n",
            "19/19 [==============================] - 0s 12ms/step - loss: 0.0093\n",
            "Epoch 128/200\n",
            "19/19 [==============================] - 0s 12ms/step - loss: 0.0105\n",
            "Epoch 129/200\n",
            "19/19 [==============================] - 0s 11ms/step - loss: 0.0093\n",
            "Epoch 130/200\n",
            "19/19 [==============================] - 0s 12ms/step - loss: 0.0086\n",
            "Epoch 131/200\n",
            "19/19 [==============================] - 0s 12ms/step - loss: 0.0080\n",
            "Epoch 132/200\n",
            "19/19 [==============================] - 0s 12ms/step - loss: 0.0083\n",
            "Epoch 133/200\n",
            "19/19 [==============================] - 0s 13ms/step - loss: 0.0079\n",
            "Epoch 134/200\n",
            "19/19 [==============================] - 0s 12ms/step - loss: 0.0079\n",
            "Epoch 135/200\n",
            "19/19 [==============================] - 0s 12ms/step - loss: 0.0079\n",
            "Epoch 136/200\n",
            "19/19 [==============================] - 0s 13ms/step - loss: 0.0081\n",
            "Epoch 137/200\n",
            "19/19 [==============================] - 0s 12ms/step - loss: 0.0069\n",
            "Epoch 138/200\n",
            "19/19 [==============================] - 0s 12ms/step - loss: 0.0075\n",
            "Epoch 139/200\n",
            "19/19 [==============================] - 0s 12ms/step - loss: 0.0071\n",
            "Epoch 140/200\n",
            "19/19 [==============================] - 0s 12ms/step - loss: 0.0069\n",
            "Epoch 141/200\n",
            "19/19 [==============================] - 0s 13ms/step - loss: 0.0066\n",
            "Epoch 142/200\n",
            "19/19 [==============================] - 0s 12ms/step - loss: 0.0067\n",
            "Epoch 143/200\n",
            "19/19 [==============================] - 0s 12ms/step - loss: 0.0089\n",
            "Epoch 144/200\n",
            "19/19 [==============================] - 0s 12ms/step - loss: 0.0097\n",
            "Epoch 145/200\n",
            "19/19 [==============================] - 0s 12ms/step - loss: 0.0111\n",
            "Epoch 146/200\n",
            "19/19 [==============================] - 0s 13ms/step - loss: 0.0077\n",
            "Epoch 147/200\n",
            "19/19 [==============================] - 0s 12ms/step - loss: 0.0085\n",
            "Epoch 148/200\n",
            "19/19 [==============================] - 0s 12ms/step - loss: 0.0080\n",
            "Epoch 149/200\n",
            "19/19 [==============================] - 0s 12ms/step - loss: 0.0079\n",
            "Epoch 150/200\n",
            "19/19 [==============================] - 0s 13ms/step - loss: 0.0067\n",
            "Epoch 151/200\n",
            "19/19 [==============================] - 0s 13ms/step - loss: 0.0067\n",
            "Epoch 152/200\n",
            "19/19 [==============================] - 0s 13ms/step - loss: 0.0067\n",
            "Epoch 153/200\n",
            "19/19 [==============================] - 0s 12ms/step - loss: 0.0069\n",
            "Epoch 154/200\n",
            "19/19 [==============================] - 0s 13ms/step - loss: 0.0065\n",
            "Epoch 155/200\n",
            "19/19 [==============================] - 0s 12ms/step - loss: 0.0087\n",
            "Epoch 156/200\n",
            "19/19 [==============================] - 0s 12ms/step - loss: 0.0094\n",
            "Epoch 157/200\n",
            "19/19 [==============================] - 0s 12ms/step - loss: 0.0078\n",
            "Epoch 158/200\n",
            "19/19 [==============================] - 0s 12ms/step - loss: 0.0090\n",
            "Epoch 159/200\n",
            "19/19 [==============================] - 0s 12ms/step - loss: 0.0090\n",
            "Epoch 160/200\n",
            "19/19 [==============================] - 0s 12ms/step - loss: 0.0095\n",
            "Epoch 161/200\n",
            "19/19 [==============================] - 0s 13ms/step - loss: 0.0105\n",
            "Epoch 162/200\n",
            "19/19 [==============================] - 0s 18ms/step - loss: 0.0078\n",
            "Epoch 163/200\n",
            "19/19 [==============================] - 0s 20ms/step - loss: 0.0075\n",
            "Epoch 164/200\n",
            "19/19 [==============================] - 0s 20ms/step - loss: 0.0074\n",
            "Epoch 165/200\n",
            "19/19 [==============================] - 0s 20ms/step - loss: 0.0074\n",
            "Epoch 166/200\n",
            "19/19 [==============================] - 0s 20ms/step - loss: 0.0082\n",
            "Epoch 167/200\n",
            "19/19 [==============================] - 0s 21ms/step - loss: 0.0087\n",
            "Epoch 168/200\n",
            "19/19 [==============================] - 0s 23ms/step - loss: 0.0092\n",
            "Epoch 169/200\n",
            "19/19 [==============================] - 0s 21ms/step - loss: 0.0079\n",
            "Epoch 170/200\n",
            "19/19 [==============================] - 0s 21ms/step - loss: 0.0073\n",
            "Epoch 171/200\n",
            "19/19 [==============================] - 0s 21ms/step - loss: 0.0076\n",
            "Epoch 172/200\n",
            "19/19 [==============================] - 0s 16ms/step - loss: 0.0070\n",
            "Epoch 173/200\n",
            "19/19 [==============================] - 0s 12ms/step - loss: 0.0070\n",
            "Epoch 174/200\n",
            "19/19 [==============================] - 0s 13ms/step - loss: 0.0071\n",
            "Epoch 175/200\n",
            "19/19 [==============================] - 0s 12ms/step - loss: 0.0069\n",
            "Epoch 176/200\n",
            "19/19 [==============================] - 0s 11ms/step - loss: 0.0069\n",
            "Epoch 177/200\n",
            "19/19 [==============================] - 0s 12ms/step - loss: 0.0068\n",
            "Epoch 178/200\n",
            "19/19 [==============================] - 0s 12ms/step - loss: 0.0075\n",
            "Epoch 179/200\n",
            "19/19 [==============================] - 0s 12ms/step - loss: 0.0079\n",
            "Epoch 180/200\n",
            "19/19 [==============================] - 0s 12ms/step - loss: 0.0070\n",
            "Epoch 181/200\n",
            "19/19 [==============================] - 0s 12ms/step - loss: 0.0066\n",
            "Epoch 182/200\n",
            "19/19 [==============================] - 0s 13ms/step - loss: 0.0070\n",
            "Epoch 183/200\n",
            "19/19 [==============================] - 0s 13ms/step - loss: 0.0064\n",
            "Epoch 184/200\n",
            "19/19 [==============================] - 0s 13ms/step - loss: 0.0071\n",
            "Epoch 185/200\n",
            "19/19 [==============================] - 0s 12ms/step - loss: 0.0115\n",
            "Epoch 186/200\n",
            "19/19 [==============================] - 0s 12ms/step - loss: 0.0097\n",
            "Epoch 187/200\n",
            "19/19 [==============================] - 0s 13ms/step - loss: 0.0079\n",
            "Epoch 188/200\n",
            "19/19 [==============================] - 0s 13ms/step - loss: 0.0072\n",
            "Epoch 189/200\n",
            "19/19 [==============================] - 0s 12ms/step - loss: 0.0073\n",
            "Epoch 190/200\n",
            "19/19 [==============================] - 0s 12ms/step - loss: 0.0063\n",
            "Epoch 191/200\n",
            "19/19 [==============================] - 0s 13ms/step - loss: 0.0058\n",
            "Epoch 192/200\n",
            "19/19 [==============================] - 0s 12ms/step - loss: 0.0069\n",
            "Epoch 193/200\n",
            "19/19 [==============================] - 0s 12ms/step - loss: 0.0091\n",
            "Epoch 194/200\n",
            "19/19 [==============================] - 0s 12ms/step - loss: 0.0067\n",
            "Epoch 195/200\n",
            "19/19 [==============================] - 0s 13ms/step - loss: 0.0056\n",
            "Epoch 196/200\n",
            "19/19 [==============================] - 0s 12ms/step - loss: 0.0048\n",
            "Epoch 197/200\n",
            "19/19 [==============================] - 0s 12ms/step - loss: 0.0050\n",
            "Epoch 198/200\n",
            "19/19 [==============================] - 0s 12ms/step - loss: 0.0061\n",
            "Epoch 199/200\n",
            "19/19 [==============================] - 0s 13ms/step - loss: 0.0067\n",
            "Epoch 200/200\n",
            "19/19 [==============================] - 0s 12ms/step - loss: 0.0055\n",
            "2/2 [==============================] - 0s 12ms/step\n",
            "Predicted prices from 2024-04-01 to 2028-12-01:\n",
            "2024-04-01: 2.597\n",
            "2024-05-01: 2.435\n",
            "2024-06-01: 2.347\n",
            "2024-07-01: 2.288\n",
            "2024-08-01: 2.244\n",
            "2024-09-01: 2.214\n",
            "2024-10-01: 2.170\n",
            "2024-11-01: 2.115\n",
            "2024-12-01: 2.063\n",
            "2025-01-01: 2.009\n",
            "2025-02-01: 1.962\n",
            "2025-03-01: 1.922\n",
            "2025-04-01: 1.890\n",
            "2025-05-01: 1.864\n",
            "2025-06-01: 1.864\n",
            "2025-07-01: 1.864\n",
            "2025-08-01: 1.864\n",
            "2025-09-01: 1.864\n",
            "2025-10-01: 1.864\n",
            "2025-11-01: 1.864\n",
            "2025-12-01: 1.864\n",
            "2026-01-01: 1.864\n",
            "2026-02-01: 1.864\n",
            "2026-03-01: 1.864\n",
            "2026-04-01: 1.864\n",
            "2026-05-01: 1.864\n",
            "2026-06-01: 1.864\n",
            "2026-07-01: 1.864\n",
            "2026-08-01: 1.864\n",
            "2026-09-01: 1.864\n",
            "2026-10-01: 1.864\n",
            "2026-11-01: 1.864\n",
            "2026-12-01: 1.864\n",
            "2027-01-01: 1.864\n",
            "2027-02-01: 1.864\n",
            "2027-03-01: 1.864\n",
            "2027-04-01: 1.864\n",
            "2027-05-01: 1.864\n",
            "2027-06-01: 1.864\n",
            "2027-07-01: 1.864\n",
            "2027-08-01: 1.864\n",
            "2027-09-01: 1.864\n",
            "2027-10-01: 1.864\n",
            "2027-11-01: 1.864\n",
            "2027-12-01: 1.864\n",
            "2028-01-01: 1.864\n",
            "2028-02-01: 1.864\n",
            "2028-03-01: 1.864\n",
            "2028-04-01: 1.864\n",
            "2028-05-01: 1.864\n",
            "2028-06-01: 1.864\n",
            "2028-07-01: 1.864\n",
            "2028-08-01: 1.864\n",
            "2028-09-01: 1.864\n",
            "2028-10-01: 1.864\n",
            "2028-11-01: 1.864\n",
            "2028-12-01: 1.864\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from datetime import datetime\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import LSTM, Dense\n",
        "\n",
        "# Read the dataset\n",
        "df = pd.read_excel('LNG (High).xlsx')\n",
        "\n",
        "# Function to calculate the number of months between two dates\n",
        "def months_between(start_date, end_date):\n",
        "    start_date = datetime.strptime(start_date, \"%Y-%m-%d\")\n",
        "    end_date = datetime.strptime(end_date, \"%Y-%m-%d\")\n",
        "    return (end_date.year - start_date.year) * 12 + end_date.month - start_date.month + 1\n",
        "\n",
        "# Define the date range\n",
        "start_date = '2024-04-01'\n",
        "end_date = '2028-12-01'\n",
        "\n",
        "# Calculate the number of months to predict\n",
        "num_months = months_between(start_date, end_date)\n",
        "\n",
        "# Ensure data is sorted by date\n",
        "df['Date'] = pd.to_datetime(df['Date'], format='%b-%y')\n",
        "df = df.sort_values(by=\"Date\", ascending=True)\n",
        "\n",
        "# Normalize the data\n",
        "scaler = MinMaxScaler(feature_range=(0, 1))\n",
        "df['Price_normalized'] = scaler.fit_transform(df['Price'].values.reshape(-1,1))\n",
        "\n",
        "# Create a new feature representing the number of months since start date\n",
        "df['Months_since_start'] = (df['Date'] - pd.to_datetime(start_date)).dt.days / 30\n",
        "\n",
        "# Prepare data for training\n",
        "X_train = df['Months_since_start'].values.reshape(-1, 1, 1)\n",
        "y_train = df['Price_normalized'].values\n",
        "\n",
        "# Define and train the LSTM model\n",
        "model = Sequential()\n",
        "model.add(LSTM(256, activation='relu', return_sequences=True, input_shape=(1, 1)))\n",
        "model.add(LSTM(128, activation='relu', return_sequences=True))\n",
        "model.add(LSTM(64, activation='relu'))\n",
        "model.add(Dense(32, activation='relu'))\n",
        "model.add(Dense(1, activation='relu'))\n",
        "model.compile(optimizer='adam', loss='mean_squared_error')\n",
        "model.fit(X_train, y_train, epochs=200, batch_size=8)\n",
        "\n",
        "# Generate future indices for prediction\n",
        "X_future = np.arange(df['Months_since_start'].iloc[-1] + 1, df['Months_since_start'].iloc[-1] + 1 + num_months)\n",
        "X_future = X_future.reshape(-1, 1, 1)  # Reshape for LSTM input\n",
        "\n",
        "# Generate predictions\n",
        "y_pred_normalized = model.predict(X_future)\n",
        "\n",
        "# Define maximum allowed change between consecutive predictions\n",
        "max_change = 0.1  # Adjust as needed\n",
        "\n",
        "# Clip predictions to ensure maximum allowed change\n",
        "y_pred_normalized = np.clip(y_pred_normalized, y_pred_normalized - max_change, y_pred_normalized + max_change)\n",
        "\n",
        "# Inverse transform predictions to get actual prices\n",
        "y_pred = scaler.inverse_transform(y_pred_normalized)\n",
        "\n",
        "# Ensure predictions are non-negative\n",
        "y_pred = np.maximum(y_pred, 0)\n",
        "\n",
        "# Generate date range for the predictions\n",
        "dates = pd.date_range(start=start_date, periods=num_months, freq='MS')\n",
        "\n",
        "# Print predicted prices with corresponding dates\n",
        "print(\"Predicted prices from 2024-04-01 to 2028-12-01:\")\n",
        "for date, price in zip(dates, y_pred.flatten()):\n",
        "    print(f\"{date.strftime('%Y-%m-%d')}: {price:.3f}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SVvaKkTj7zzr",
        "outputId": "4679c964-7f3d-416f-863f-f1c1c31e6f7a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/200\n",
            "19/19 [==============================] - 6s 19ms/step - loss: 0.0633\n",
            "Epoch 2/200\n",
            "19/19 [==============================] - 0s 20ms/step - loss: 0.0452\n",
            "Epoch 3/200\n",
            "19/19 [==============================] - 0s 21ms/step - loss: 0.0374\n",
            "Epoch 4/200\n",
            "19/19 [==============================] - 0s 20ms/step - loss: 0.0282\n",
            "Epoch 5/200\n",
            "19/19 [==============================] - 0s 19ms/step - loss: 0.0248\n",
            "Epoch 6/200\n",
            "19/19 [==============================] - 0s 11ms/step - loss: 0.0247\n",
            "Epoch 7/200\n",
            "19/19 [==============================] - 0s 12ms/step - loss: 0.0231\n",
            "Epoch 8/200\n",
            "19/19 [==============================] - 0s 11ms/step - loss: 0.0250\n",
            "Epoch 9/200\n",
            "19/19 [==============================] - 0s 11ms/step - loss: 0.0230\n",
            "Epoch 10/200\n",
            "19/19 [==============================] - 0s 11ms/step - loss: 0.0236\n",
            "Epoch 11/200\n",
            "19/19 [==============================] - 0s 11ms/step - loss: 0.0188\n",
            "Epoch 12/200\n",
            "19/19 [==============================] - 0s 11ms/step - loss: 0.0198\n",
            "Epoch 13/200\n",
            "19/19 [==============================] - 0s 11ms/step - loss: 0.0216\n",
            "Epoch 14/200\n",
            "19/19 [==============================] - 0s 11ms/step - loss: 0.0212\n",
            "Epoch 15/200\n",
            "19/19 [==============================] - 0s 11ms/step - loss: 0.0212\n",
            "Epoch 16/200\n",
            "19/19 [==============================] - 0s 12ms/step - loss: 0.0196\n",
            "Epoch 17/200\n",
            "19/19 [==============================] - 0s 11ms/step - loss: 0.0162\n",
            "Epoch 18/200\n",
            "19/19 [==============================] - 0s 11ms/step - loss: 0.0227\n",
            "Epoch 19/200\n",
            "19/19 [==============================] - 0s 11ms/step - loss: 0.0206\n",
            "Epoch 20/200\n",
            "19/19 [==============================] - 0s 11ms/step - loss: 0.0175\n",
            "Epoch 21/200\n",
            "19/19 [==============================] - 0s 12ms/step - loss: 0.0227\n",
            "Epoch 22/200\n",
            "19/19 [==============================] - 0s 11ms/step - loss: 0.0190\n",
            "Epoch 23/200\n",
            "19/19 [==============================] - 0s 11ms/step - loss: 0.0223\n",
            "Epoch 24/200\n",
            "19/19 [==============================] - 0s 11ms/step - loss: 0.0257\n",
            "Epoch 25/200\n",
            "19/19 [==============================] - 0s 13ms/step - loss: 0.0174\n",
            "Epoch 26/200\n",
            "19/19 [==============================] - 0s 11ms/step - loss: 0.0206\n",
            "Epoch 27/200\n",
            "19/19 [==============================] - 0s 11ms/step - loss: 0.0177\n",
            "Epoch 28/200\n",
            "19/19 [==============================] - 0s 12ms/step - loss: 0.0173\n",
            "Epoch 29/200\n",
            "19/19 [==============================] - 0s 12ms/step - loss: 0.0198\n",
            "Epoch 30/200\n",
            "19/19 [==============================] - 0s 12ms/step - loss: 0.0151\n",
            "Epoch 31/200\n",
            "19/19 [==============================] - 0s 11ms/step - loss: 0.0197\n",
            "Epoch 32/200\n",
            "19/19 [==============================] - 0s 12ms/step - loss: 0.0177\n",
            "Epoch 33/200\n",
            "19/19 [==============================] - 0s 11ms/step - loss: 0.0216\n",
            "Epoch 34/200\n",
            "19/19 [==============================] - 0s 12ms/step - loss: 0.0193\n",
            "Epoch 35/200\n",
            "19/19 [==============================] - 0s 11ms/step - loss: 0.0190\n",
            "Epoch 36/200\n",
            "19/19 [==============================] - 0s 11ms/step - loss: 0.0222\n",
            "Epoch 37/200\n",
            "19/19 [==============================] - 0s 11ms/step - loss: 0.0158\n",
            "Epoch 38/200\n",
            "19/19 [==============================] - 0s 11ms/step - loss: 0.0161\n",
            "Epoch 39/200\n",
            "19/19 [==============================] - 0s 12ms/step - loss: 0.0189\n",
            "Epoch 40/200\n",
            "19/19 [==============================] - 0s 11ms/step - loss: 0.0172\n",
            "Epoch 41/200\n",
            "19/19 [==============================] - 0s 12ms/step - loss: 0.0218\n",
            "Epoch 42/200\n",
            "19/19 [==============================] - 0s 11ms/step - loss: 0.0173\n",
            "Epoch 43/200\n",
            "19/19 [==============================] - 0s 13ms/step - loss: 0.0185\n",
            "Epoch 44/200\n",
            "19/19 [==============================] - 0s 11ms/step - loss: 0.0198\n",
            "Epoch 45/200\n",
            "19/19 [==============================] - 0s 12ms/step - loss: 0.0139\n",
            "Epoch 46/200\n",
            "19/19 [==============================] - 0s 11ms/step - loss: 0.0196\n",
            "Epoch 47/200\n",
            "19/19 [==============================] - 0s 12ms/step - loss: 0.0196\n",
            "Epoch 48/200\n",
            "19/19 [==============================] - 0s 12ms/step - loss: 0.0155\n",
            "Epoch 49/200\n",
            "19/19 [==============================] - 0s 11ms/step - loss: 0.0158\n",
            "Epoch 50/200\n",
            "19/19 [==============================] - 0s 19ms/step - loss: 0.0118\n",
            "Epoch 51/200\n",
            "19/19 [==============================] - 0s 20ms/step - loss: 0.0142\n",
            "Epoch 52/200\n",
            "19/19 [==============================] - 0s 19ms/step - loss: 0.0143\n",
            "Epoch 53/200\n",
            "19/19 [==============================] - 0s 19ms/step - loss: 0.0108\n",
            "Epoch 54/200\n",
            "19/19 [==============================] - 0s 20ms/step - loss: 0.0125\n",
            "Epoch 55/200\n",
            "19/19 [==============================] - 0s 20ms/step - loss: 0.0162\n",
            "Epoch 56/200\n",
            "19/19 [==============================] - 0s 20ms/step - loss: 0.0124\n",
            "Epoch 57/200\n",
            "19/19 [==============================] - 0s 20ms/step - loss: 0.0146\n",
            "Epoch 58/200\n",
            "19/19 [==============================] - 0s 19ms/step - loss: 0.0137\n",
            "Epoch 59/200\n",
            "19/19 [==============================] - 0s 20ms/step - loss: 0.0120\n",
            "Epoch 60/200\n",
            "19/19 [==============================] - 0s 17ms/step - loss: 0.0127\n",
            "Epoch 61/200\n",
            "19/19 [==============================] - 0s 12ms/step - loss: 0.0163\n",
            "Epoch 62/200\n",
            "19/19 [==============================] - 0s 11ms/step - loss: 0.0178\n",
            "Epoch 63/200\n",
            "19/19 [==============================] - 0s 11ms/step - loss: 0.0159\n",
            "Epoch 64/200\n",
            "19/19 [==============================] - 0s 12ms/step - loss: 0.0138\n",
            "Epoch 65/200\n",
            "19/19 [==============================] - 0s 12ms/step - loss: 0.0203\n",
            "Epoch 66/200\n",
            "19/19 [==============================] - 0s 12ms/step - loss: 0.0170\n",
            "Epoch 67/200\n",
            "19/19 [==============================] - 0s 11ms/step - loss: 0.0153\n",
            "Epoch 68/200\n",
            "19/19 [==============================] - 0s 12ms/step - loss: 0.0151\n",
            "Epoch 69/200\n",
            "19/19 [==============================] - 0s 11ms/step - loss: 0.0175\n",
            "Epoch 70/200\n",
            "19/19 [==============================] - 0s 11ms/step - loss: 0.0154\n",
            "Epoch 71/200\n",
            "19/19 [==============================] - 0s 11ms/step - loss: 0.0111\n",
            "Epoch 72/200\n",
            "19/19 [==============================] - 0s 11ms/step - loss: 0.0139\n",
            "Epoch 73/200\n",
            "19/19 [==============================] - 0s 12ms/step - loss: 0.0154\n",
            "Epoch 74/200\n",
            "19/19 [==============================] - 0s 11ms/step - loss: 0.0117\n",
            "Epoch 75/200\n",
            "19/19 [==============================] - 0s 11ms/step - loss: 0.0112\n",
            "Epoch 76/200\n",
            "19/19 [==============================] - 0s 11ms/step - loss: 0.0126\n",
            "Epoch 77/200\n",
            "19/19 [==============================] - 0s 11ms/step - loss: 0.0149\n",
            "Epoch 78/200\n",
            "19/19 [==============================] - 0s 13ms/step - loss: 0.0160\n",
            "Epoch 79/200\n",
            "19/19 [==============================] - 0s 11ms/step - loss: 0.0118\n",
            "Epoch 80/200\n",
            "19/19 [==============================] - 0s 11ms/step - loss: 0.0155\n",
            "Epoch 81/200\n",
            "19/19 [==============================] - 0s 12ms/step - loss: 0.0142\n",
            "Epoch 82/200\n",
            "19/19 [==============================] - 0s 12ms/step - loss: 0.0145\n",
            "Epoch 83/200\n",
            "19/19 [==============================] - 0s 11ms/step - loss: 0.0132\n",
            "Epoch 84/200\n",
            "19/19 [==============================] - 0s 11ms/step - loss: 0.0123\n",
            "Epoch 85/200\n",
            "19/19 [==============================] - 0s 11ms/step - loss: 0.0130\n",
            "Epoch 86/200\n",
            "19/19 [==============================] - 0s 11ms/step - loss: 0.0126\n",
            "Epoch 87/200\n",
            "19/19 [==============================] - 0s 12ms/step - loss: 0.0122\n",
            "Epoch 88/200\n",
            "19/19 [==============================] - 0s 12ms/step - loss: 0.0130\n",
            "Epoch 89/200\n",
            "19/19 [==============================] - 0s 11ms/step - loss: 0.0128\n",
            "Epoch 90/200\n",
            "19/19 [==============================] - 0s 11ms/step - loss: 0.0158\n",
            "Epoch 91/200\n",
            "19/19 [==============================] - 0s 12ms/step - loss: 0.0153\n",
            "Epoch 92/200\n",
            "19/19 [==============================] - 0s 11ms/step - loss: 0.0134\n",
            "Epoch 93/200\n",
            "19/19 [==============================] - 0s 11ms/step - loss: 0.0111\n",
            "Epoch 94/200\n",
            "19/19 [==============================] - 0s 11ms/step - loss: 0.0100\n",
            "Epoch 95/200\n",
            "19/19 [==============================] - 0s 11ms/step - loss: 0.0138\n",
            "Epoch 96/200\n",
            "19/19 [==============================] - 0s 13ms/step - loss: 0.0125\n",
            "Epoch 97/200\n",
            "19/19 [==============================] - 0s 11ms/step - loss: 0.0153\n",
            "Epoch 98/200\n",
            "19/19 [==============================] - 0s 11ms/step - loss: 0.0133\n",
            "Epoch 99/200\n",
            "19/19 [==============================] - 0s 11ms/step - loss: 0.0138\n",
            "Epoch 100/200\n",
            "19/19 [==============================] - 0s 12ms/step - loss: 0.0129\n",
            "Epoch 101/200\n",
            "19/19 [==============================] - 0s 11ms/step - loss: 0.0143\n",
            "Epoch 102/200\n",
            "19/19 [==============================] - 0s 12ms/step - loss: 0.0132\n",
            "Epoch 103/200\n",
            "19/19 [==============================] - 0s 11ms/step - loss: 0.0097\n",
            "Epoch 104/200\n",
            "19/19 [==============================] - 0s 13ms/step - loss: 0.0114\n",
            "Epoch 105/200\n",
            "19/19 [==============================] - 0s 19ms/step - loss: 0.0109\n",
            "Epoch 106/200\n",
            "19/19 [==============================] - 0s 19ms/step - loss: 0.0094\n",
            "Epoch 107/200\n",
            "19/19 [==============================] - 0s 19ms/step - loss: 0.0106\n",
            "Epoch 108/200\n",
            "19/19 [==============================] - 0s 21ms/step - loss: 0.0148\n",
            "Epoch 109/200\n",
            "19/19 [==============================] - 0s 21ms/step - loss: 0.0166\n",
            "Epoch 110/200\n",
            "19/19 [==============================] - 0s 20ms/step - loss: 0.0147\n",
            "Epoch 111/200\n",
            "19/19 [==============================] - 0s 19ms/step - loss: 0.0119\n",
            "Epoch 112/200\n",
            "19/19 [==============================] - 0s 19ms/step - loss: 0.0111\n",
            "Epoch 113/200\n",
            "19/19 [==============================] - 0s 22ms/step - loss: 0.0102\n",
            "Epoch 114/200\n",
            "19/19 [==============================] - 0s 20ms/step - loss: 0.0121\n",
            "Epoch 115/200\n",
            "19/19 [==============================] - 0s 16ms/step - loss: 0.0096\n",
            "Epoch 116/200\n",
            "19/19 [==============================] - 0s 12ms/step - loss: 0.0112\n",
            "Epoch 117/200\n",
            "19/19 [==============================] - 0s 11ms/step - loss: 0.0112\n",
            "Epoch 118/200\n",
            "19/19 [==============================] - 0s 13ms/step - loss: 0.0140\n",
            "Epoch 119/200\n",
            "19/19 [==============================] - 0s 11ms/step - loss: 0.0106\n",
            "Epoch 120/200\n",
            "19/19 [==============================] - 0s 11ms/step - loss: 0.0093\n",
            "Epoch 121/200\n",
            "19/19 [==============================] - 0s 12ms/step - loss: 0.0132\n",
            "Epoch 122/200\n",
            "19/19 [==============================] - 0s 11ms/step - loss: 0.0117\n",
            "Epoch 123/200\n",
            "19/19 [==============================] - 0s 11ms/step - loss: 0.0145\n",
            "Epoch 124/200\n",
            "19/19 [==============================] - 0s 11ms/step - loss: 0.0107\n",
            "Epoch 125/200\n",
            "19/19 [==============================] - 0s 12ms/step - loss: 0.0106\n",
            "Epoch 126/200\n",
            "19/19 [==============================] - 0s 11ms/step - loss: 0.0120\n",
            "Epoch 127/200\n",
            "19/19 [==============================] - 0s 12ms/step - loss: 0.0117\n",
            "Epoch 128/200\n",
            "19/19 [==============================] - 0s 11ms/step - loss: 0.0099\n",
            "Epoch 129/200\n",
            "19/19 [==============================] - 0s 11ms/step - loss: 0.0109\n",
            "Epoch 130/200\n",
            "19/19 [==============================] - 0s 12ms/step - loss: 0.0119\n",
            "Epoch 131/200\n",
            "19/19 [==============================] - 0s 11ms/step - loss: 0.0112\n",
            "Epoch 132/200\n",
            "19/19 [==============================] - 0s 11ms/step - loss: 0.0108\n",
            "Epoch 133/200\n",
            "19/19 [==============================] - 0s 11ms/step - loss: 0.0138\n",
            "Epoch 134/200\n",
            "19/19 [==============================] - 0s 12ms/step - loss: 0.0103\n",
            "Epoch 135/200\n",
            "19/19 [==============================] - 0s 12ms/step - loss: 0.0096\n",
            "Epoch 136/200\n",
            "19/19 [==============================] - 0s 11ms/step - loss: 0.0112\n",
            "Epoch 137/200\n",
            "19/19 [==============================] - 0s 12ms/step - loss: 0.0123\n",
            "Epoch 138/200\n",
            "19/19 [==============================] - 0s 11ms/step - loss: 0.0133\n",
            "Epoch 139/200\n",
            "19/19 [==============================] - 0s 12ms/step - loss: 0.0117\n",
            "Epoch 140/200\n",
            "19/19 [==============================] - 0s 12ms/step - loss: 0.0101\n",
            "Epoch 141/200\n",
            "19/19 [==============================] - 0s 11ms/step - loss: 0.0092\n",
            "Epoch 142/200\n",
            "19/19 [==============================] - 0s 12ms/step - loss: 0.0152\n",
            "Epoch 143/200\n",
            "19/19 [==============================] - 0s 12ms/step - loss: 0.0102\n",
            "Epoch 144/200\n",
            "19/19 [==============================] - 0s 11ms/step - loss: 0.0140\n",
            "Epoch 145/200\n",
            "19/19 [==============================] - 0s 11ms/step - loss: 0.0114\n",
            "Epoch 146/200\n",
            "19/19 [==============================] - 0s 11ms/step - loss: 0.0099\n",
            "Epoch 147/200\n",
            "19/19 [==============================] - 0s 11ms/step - loss: 0.0099\n",
            "Epoch 148/200\n",
            "19/19 [==============================] - 0s 12ms/step - loss: 0.0110\n",
            "Epoch 149/200\n",
            "19/19 [==============================] - 0s 12ms/step - loss: 0.0106\n",
            "Epoch 150/200\n",
            "19/19 [==============================] - 0s 11ms/step - loss: 0.0116\n",
            "Epoch 151/200\n",
            "19/19 [==============================] - 0s 12ms/step - loss: 0.0122\n",
            "Epoch 152/200\n",
            "19/19 [==============================] - 0s 11ms/step - loss: 0.0122\n",
            "Epoch 153/200\n",
            "19/19 [==============================] - 0s 12ms/step - loss: 0.0116\n",
            "Epoch 154/200\n",
            "19/19 [==============================] - 0s 11ms/step - loss: 0.0095\n",
            "Epoch 155/200\n",
            "19/19 [==============================] - 0s 11ms/step - loss: 0.0115\n",
            "Epoch 156/200\n",
            "19/19 [==============================] - 0s 11ms/step - loss: 0.0110\n",
            "Epoch 157/200\n",
            "19/19 [==============================] - 0s 13ms/step - loss: 0.0083\n",
            "Epoch 158/200\n",
            "19/19 [==============================] - 0s 11ms/step - loss: 0.0098\n",
            "Epoch 159/200\n",
            "19/19 [==============================] - 0s 16ms/step - loss: 0.0127\n",
            "Epoch 160/200\n",
            "19/19 [==============================] - 0s 19ms/step - loss: 0.0113\n",
            "Epoch 161/200\n",
            "19/19 [==============================] - 0s 22ms/step - loss: 0.0132\n",
            "Epoch 162/200\n",
            "19/19 [==============================] - 0s 20ms/step - loss: 0.0115\n",
            "Epoch 163/200\n",
            "19/19 [==============================] - 0s 19ms/step - loss: 0.0106\n",
            "Epoch 164/200\n",
            "19/19 [==============================] - 0s 20ms/step - loss: 0.0131\n",
            "Epoch 165/200\n",
            "19/19 [==============================] - 0s 20ms/step - loss: 0.0102\n",
            "Epoch 166/200\n",
            "19/19 [==============================] - 0s 22ms/step - loss: 0.0120\n",
            "Epoch 167/200\n",
            "19/19 [==============================] - 0s 22ms/step - loss: 0.0121\n",
            "Epoch 168/200\n",
            "19/19 [==============================] - 0s 15ms/step - loss: 0.0094\n",
            "Epoch 169/200\n",
            "19/19 [==============================] - 0s 12ms/step - loss: 0.0087\n",
            "Epoch 170/200\n",
            "19/19 [==============================] - 0s 11ms/step - loss: 0.0115\n",
            "Epoch 171/200\n",
            "19/19 [==============================] - 0s 12ms/step - loss: 0.0119\n",
            "Epoch 172/200\n",
            "19/19 [==============================] - 0s 11ms/step - loss: 0.0095\n",
            "Epoch 173/200\n",
            "19/19 [==============================] - 0s 11ms/step - loss: 0.0122\n",
            "Epoch 174/200\n",
            "19/19 [==============================] - 0s 12ms/step - loss: 0.0103\n",
            "Epoch 175/200\n",
            "19/19 [==============================] - 0s 11ms/step - loss: 0.0092\n",
            "Epoch 176/200\n",
            "19/19 [==============================] - 0s 11ms/step - loss: 0.0117\n",
            "Epoch 177/200\n",
            "19/19 [==============================] - 0s 11ms/step - loss: 0.0088\n",
            "Epoch 178/200\n",
            "19/19 [==============================] - 0s 12ms/step - loss: 0.0083\n",
            "Epoch 179/200\n",
            "19/19 [==============================] - 0s 11ms/step - loss: 0.0114\n",
            "Epoch 180/200\n",
            "19/19 [==============================] - 0s 12ms/step - loss: 0.0099\n",
            "Epoch 181/200\n",
            "19/19 [==============================] - 0s 12ms/step - loss: 0.0143\n",
            "Epoch 182/200\n",
            "19/19 [==============================] - 0s 12ms/step - loss: 0.0110\n",
            "Epoch 183/200\n",
            "19/19 [==============================] - 0s 11ms/step - loss: 0.0102\n",
            "Epoch 184/200\n",
            "19/19 [==============================] - 0s 13ms/step - loss: 0.0097\n",
            "Epoch 185/200\n",
            "19/19 [==============================] - 0s 11ms/step - loss: 0.0099\n",
            "Epoch 186/200\n",
            "19/19 [==============================] - 0s 12ms/step - loss: 0.0114\n",
            "Epoch 187/200\n",
            "19/19 [==============================] - 0s 12ms/step - loss: 0.0096\n",
            "Epoch 188/200\n",
            "19/19 [==============================] - 0s 12ms/step - loss: 0.0113\n",
            "Epoch 189/200\n",
            "19/19 [==============================] - 0s 11ms/step - loss: 0.0111\n",
            "Epoch 190/200\n",
            "19/19 [==============================] - 0s 12ms/step - loss: 0.0115\n",
            "Epoch 191/200\n",
            "19/19 [==============================] - 0s 12ms/step - loss: 0.0125\n",
            "Epoch 192/200\n",
            "19/19 [==============================] - 0s 11ms/step - loss: 0.0121\n",
            "Epoch 193/200\n",
            "19/19 [==============================] - 0s 12ms/step - loss: 0.0095\n",
            "Epoch 194/200\n",
            "19/19 [==============================] - 0s 11ms/step - loss: 0.0118\n",
            "Epoch 195/200\n",
            "19/19 [==============================] - 0s 11ms/step - loss: 0.0081\n",
            "Epoch 196/200\n",
            "19/19 [==============================] - 0s 12ms/step - loss: 0.0117\n",
            "Epoch 197/200\n",
            "19/19 [==============================] - 0s 12ms/step - loss: 0.0123\n",
            "Epoch 198/200\n",
            "19/19 [==============================] - 0s 11ms/step - loss: 0.0111\n",
            "Epoch 199/200\n",
            "19/19 [==============================] - 0s 12ms/step - loss: 0.0103\n",
            "Epoch 200/200\n",
            "19/19 [==============================] - 0s 13ms/step - loss: 0.0102\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Predicted prices from 2024-04-01 to 2028-12-01:\n",
            "2024-04-01: 2.759\n",
            "2024-05-01: 2.478\n",
            "2024-06-01: 1.864\n",
            "2024-07-01: 1.864\n",
            "2024-08-01: 1.864\n",
            "2024-09-01: 1.864\n",
            "2024-10-01: 1.864\n",
            "2024-11-01: 1.864\n",
            "2024-12-01: 1.864\n",
            "2025-01-01: 1.864\n",
            "2025-02-01: 1.864\n",
            "2025-03-01: 1.864\n",
            "2025-04-01: 1.864\n",
            "2025-05-01: 1.864\n",
            "2025-06-01: 1.864\n",
            "2025-07-01: 1.864\n",
            "2025-08-01: 1.864\n",
            "2025-09-01: 1.864\n",
            "2025-10-01: 1.864\n",
            "2025-11-01: 1.864\n",
            "2025-12-01: 1.864\n",
            "2026-01-01: 1.864\n",
            "2026-02-01: 1.864\n",
            "2026-03-01: 1.864\n",
            "2026-04-01: 1.864\n",
            "2026-05-01: 1.864\n",
            "2026-06-01: 1.864\n",
            "2026-07-01: 1.864\n",
            "2026-08-01: 1.864\n",
            "2026-09-01: 1.864\n",
            "2026-10-01: 1.864\n",
            "2026-11-01: 1.864\n",
            "2026-12-01: 1.864\n",
            "2027-01-01: 1.864\n",
            "2027-02-01: 1.864\n",
            "2027-03-01: 1.864\n",
            "2027-04-01: 1.864\n",
            "2027-05-01: 1.864\n",
            "2027-06-01: 1.864\n",
            "2027-07-01: 1.864\n",
            "2027-08-01: 1.864\n",
            "2027-09-01: 1.864\n",
            "2027-10-01: 1.864\n",
            "2027-11-01: 1.864\n",
            "2027-12-01: 1.864\n",
            "2028-01-01: 1.864\n",
            "2028-02-01: 1.864\n",
            "2028-03-01: 1.864\n",
            "2028-04-01: 1.864\n",
            "2028-05-01: 1.864\n",
            "2028-06-01: 1.864\n",
            "2028-07-01: 1.864\n",
            "2028-08-01: 1.864\n",
            "2028-09-01: 1.864\n",
            "2028-10-01: 1.864\n",
            "2028-11-01: 1.864\n",
            "2028-12-01: 1.864\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from datetime import datetime\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import LSTM, Dense, Dropout\n",
        "\n",
        "# Read the dataset\n",
        "df = pd.read_excel('LNG (High).xlsx')\n",
        "\n",
        "# Function to calculate the number of months between two dates\n",
        "def months_between(start_date, end_date):\n",
        "    start_date = datetime.strptime(start_date, \"%Y-%m-%d\")\n",
        "    end_date = datetime.strptime(end_date, \"%Y-%m-%d\")\n",
        "    return (end_date.year - start_date.year) * 12 + end_date.month - start_date.month + 1\n",
        "\n",
        "# Define the date range\n",
        "start_date = '2024-04-01'\n",
        "end_date = '2028-12-01'\n",
        "\n",
        "# Calculate the number of months to predict\n",
        "num_months = months_between(start_date, end_date)\n",
        "\n",
        "# Ensure data is sorted by date\n",
        "df['Date'] = pd.to_datetime(df['Date'], format='%b-%y')\n",
        "df = df.sort_values(by=\"Date\", ascending=True)\n",
        "\n",
        "# Normalize the data\n",
        "scaler = MinMaxScaler(feature_range=(0, 1))\n",
        "df['Price_normalized'] = scaler.fit_transform(df['Price'].values.reshape(-1,1))\n",
        "\n",
        "# Create a new feature representing the number of months since start date\n",
        "df['Months_since_start'] = (df['Date'] - pd.to_datetime(start_date)).dt.days / 30\n",
        "\n",
        "# Prepare data for training\n",
        "X_train = df['Months_since_start'].values.reshape(-1, 1, 1)\n",
        "y_train = df['Price_normalized'].values\n",
        "\n",
        "# Define and train the LSTM model with dropout layers\n",
        "model = Sequential()\n",
        "model.add(LSTM(256, activation='relu', return_sequences=True, input_shape=(1, 1)))\n",
        "model.add(Dropout(0.2))  # Add dropout layer\n",
        "model.add(LSTM(128, activation='relu', return_sequences=True))\n",
        "model.add(Dropout(0.2))  # Add dropout layer\n",
        "model.add(LSTM(64, activation='relu'))\n",
        "model.add(Dropout(0.2))  # Add dropout layer\n",
        "model.add(Dense(32, activation='relu'))\n",
        "model.add(Dense(1, activation='relu'))\n",
        "model.compile(optimizer='adam', loss='mean_squared_error')\n",
        "model.fit(X_train, y_train, epochs=200, batch_size=8)\n",
        "\n",
        "# Generate future indices for prediction\n",
        "X_future = np.arange(df['Months_since_start'].iloc[-1] + 1, df['Months_since_start'].iloc[-1] + 1 + num_months)\n",
        "X_future = X_future.reshape(-1, 1, 1)  # Reshape for LSTM input\n",
        "\n",
        "# Generate predictions\n",
        "y_pred_normalized = model.predict(X_future)\n",
        "\n",
        "# Inverse transform predictions to get actual prices\n",
        "y_pred = scaler.inverse_transform(y_pred_normalized)\n",
        "\n",
        "# Ensure predictions are non-negative\n",
        "y_pred = np.maximum(y_pred, 0)\n",
        "\n",
        "# Generate date range for the predictions\n",
        "dates = pd.date_range(start=start_date, periods=num_months, freq='MS')\n",
        "\n",
        "# Print predicted prices with corresponding dates\n",
        "print(\"Predicted prices from 2024-04-01 to 2028-12-01:\")\n",
        "for date, price in zip(dates, y_pred.flatten()):\n",
        "    print(f\"{date.strftime('%Y-%m-%d')}: {price:.3f}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8BTmaS7R9iL2",
        "outputId": "c0b5e2f8-8366-42d2-8869-41f6739a4faa"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/200\n",
            "19/19 [==============================] - 8s 11ms/step - loss: 0.0631\n",
            "Epoch 2/200\n",
            "19/19 [==============================] - 0s 12ms/step - loss: 0.0519\n",
            "Epoch 3/200\n",
            "19/19 [==============================] - 0s 11ms/step - loss: 0.0417\n",
            "Epoch 4/200\n",
            "19/19 [==============================] - 0s 12ms/step - loss: 0.0374\n",
            "Epoch 5/200\n",
            "19/19 [==============================] - 0s 13ms/step - loss: 0.0359\n",
            "Epoch 6/200\n",
            "19/19 [==============================] - 0s 14ms/step - loss: 0.0326\n",
            "Epoch 7/200\n",
            "19/19 [==============================] - 0s 11ms/step - loss: 0.0293\n",
            "Epoch 8/200\n",
            "19/19 [==============================] - 0s 11ms/step - loss: 0.0316\n",
            "Epoch 9/200\n",
            "19/19 [==============================] - 0s 11ms/step - loss: 0.0265\n",
            "Epoch 10/200\n",
            "19/19 [==============================] - 0s 11ms/step - loss: 0.0319\n",
            "Epoch 11/200\n",
            "19/19 [==============================] - 0s 11ms/step - loss: 0.0293\n",
            "Epoch 12/200\n",
            "19/19 [==============================] - 0s 11ms/step - loss: 0.0238\n",
            "Epoch 13/200\n",
            "19/19 [==============================] - 0s 12ms/step - loss: 0.0353\n",
            "Epoch 14/200\n",
            "19/19 [==============================] - 0s 11ms/step - loss: 0.0341\n",
            "Epoch 15/200\n",
            "19/19 [==============================] - 0s 11ms/step - loss: 0.0280\n",
            "Epoch 16/200\n",
            "19/19 [==============================] - 0s 12ms/step - loss: 0.0318\n",
            "Epoch 17/200\n",
            "19/19 [==============================] - 0s 12ms/step - loss: 0.0248\n",
            "Epoch 18/200\n",
            "19/19 [==============================] - 0s 13ms/step - loss: 0.0262\n",
            "Epoch 19/200\n",
            "19/19 [==============================] - 0s 11ms/step - loss: 0.0317\n",
            "Epoch 20/200\n",
            "19/19 [==============================] - 0s 11ms/step - loss: 0.0328\n",
            "Epoch 21/200\n",
            "19/19 [==============================] - 0s 11ms/step - loss: 0.0333\n",
            "Epoch 22/200\n",
            "19/19 [==============================] - 0s 12ms/step - loss: 0.0268\n",
            "Epoch 23/200\n",
            "19/19 [==============================] - 0s 11ms/step - loss: 0.0275\n",
            "Epoch 24/200\n",
            "19/19 [==============================] - 0s 11ms/step - loss: 0.0284\n",
            "Epoch 25/200\n",
            "19/19 [==============================] - 0s 11ms/step - loss: 0.0283\n",
            "Epoch 26/200\n",
            "19/19 [==============================] - 0s 11ms/step - loss: 0.0277\n",
            "Epoch 27/200\n",
            "19/19 [==============================] - 0s 12ms/step - loss: 0.0206\n",
            "Epoch 28/200\n",
            "19/19 [==============================] - 0s 11ms/step - loss: 0.0230\n",
            "Epoch 29/200\n",
            "19/19 [==============================] - 0s 11ms/step - loss: 0.0231\n",
            "Epoch 30/200\n",
            "19/19 [==============================] - 0s 11ms/step - loss: 0.0230\n",
            "Epoch 31/200\n",
            "19/19 [==============================] - 0s 16ms/step - loss: 0.0287\n",
            "Epoch 32/200\n",
            "19/19 [==============================] - 0s 20ms/step - loss: 0.0281\n",
            "Epoch 33/200\n",
            "19/19 [==============================] - 0s 19ms/step - loss: 0.0274\n",
            "Epoch 34/200\n",
            "19/19 [==============================] - 0s 20ms/step - loss: 0.0312\n",
            "Epoch 35/200\n",
            "19/19 [==============================] - 0s 19ms/step - loss: 0.0298\n",
            "Epoch 36/200\n",
            "19/19 [==============================] - 0s 20ms/step - loss: 0.0240\n",
            "Epoch 37/200\n",
            "19/19 [==============================] - 0s 20ms/step - loss: 0.0291\n",
            "Epoch 38/200\n",
            "19/19 [==============================] - 0s 20ms/step - loss: 0.0259\n",
            "Epoch 39/200\n",
            "19/19 [==============================] - 0s 20ms/step - loss: 0.0283\n",
            "Epoch 40/200\n",
            "19/19 [==============================] - 0s 21ms/step - loss: 0.0268\n",
            "Epoch 41/200\n",
            "19/19 [==============================] - 0s 21ms/step - loss: 0.0217\n",
            "Epoch 42/200\n",
            "19/19 [==============================] - 0s 11ms/step - loss: 0.0311\n",
            "Epoch 43/200\n",
            "19/19 [==============================] - 0s 12ms/step - loss: 0.0287\n",
            "Epoch 44/200\n",
            "19/19 [==============================] - 0s 11ms/step - loss: 0.0239\n",
            "Epoch 45/200\n",
            "19/19 [==============================] - 0s 12ms/step - loss: 0.0214\n",
            "Epoch 46/200\n",
            "19/19 [==============================] - 0s 11ms/step - loss: 0.0224\n",
            "Epoch 47/200\n",
            "19/19 [==============================] - 0s 11ms/step - loss: 0.0280\n",
            "Epoch 48/200\n",
            "19/19 [==============================] - 0s 12ms/step - loss: 0.0244\n",
            "Epoch 49/200\n",
            "19/19 [==============================] - 0s 11ms/step - loss: 0.0296\n",
            "Epoch 50/200\n",
            "19/19 [==============================] - 0s 11ms/step - loss: 0.0246\n",
            "Epoch 51/200\n",
            "19/19 [==============================] - 0s 12ms/step - loss: 0.0227\n",
            "Epoch 52/200\n",
            "19/19 [==============================] - 0s 12ms/step - loss: 0.0251\n",
            "Epoch 53/200\n",
            "19/19 [==============================] - 0s 13ms/step - loss: 0.0298\n",
            "Epoch 54/200\n",
            "19/19 [==============================] - 0s 12ms/step - loss: 0.0238\n",
            "Epoch 55/200\n",
            "19/19 [==============================] - 0s 12ms/step - loss: 0.0200\n",
            "Epoch 56/200\n",
            "19/19 [==============================] - 0s 11ms/step - loss: 0.0253\n",
            "Epoch 57/200\n",
            "19/19 [==============================] - 0s 12ms/step - loss: 0.0288\n",
            "Epoch 58/200\n",
            "19/19 [==============================] - 0s 11ms/step - loss: 0.0221\n",
            "Epoch 59/200\n",
            "19/19 [==============================] - 0s 12ms/step - loss: 0.0232\n",
            "Epoch 60/200\n",
            "19/19 [==============================] - 0s 11ms/step - loss: 0.0255\n",
            "Epoch 61/200\n",
            "19/19 [==============================] - 0s 12ms/step - loss: 0.0311\n",
            "Epoch 62/200\n",
            "19/19 [==============================] - 0s 11ms/step - loss: 0.0218\n",
            "Epoch 63/200\n",
            "19/19 [==============================] - 0s 11ms/step - loss: 0.0204\n",
            "Epoch 64/200\n",
            "19/19 [==============================] - 0s 12ms/step - loss: 0.0234\n",
            "Epoch 65/200\n",
            "19/19 [==============================] - 0s 11ms/step - loss: 0.0183\n",
            "Epoch 66/200\n",
            "19/19 [==============================] - 0s 12ms/step - loss: 0.0272\n",
            "Epoch 67/200\n",
            "19/19 [==============================] - 0s 11ms/step - loss: 0.0183\n",
            "Epoch 68/200\n",
            "19/19 [==============================] - 0s 11ms/step - loss: 0.0227\n",
            "Epoch 69/200\n",
            "19/19 [==============================] - 0s 11ms/step - loss: 0.0225\n",
            "Epoch 70/200\n",
            "19/19 [==============================] - 0s 12ms/step - loss: 0.0251\n",
            "Epoch 71/200\n",
            "19/19 [==============================] - 0s 11ms/step - loss: 0.0225\n",
            "Epoch 72/200\n",
            "19/19 [==============================] - 0s 12ms/step - loss: 0.0223\n",
            "Epoch 73/200\n",
            "19/19 [==============================] - 0s 11ms/step - loss: 0.0290\n",
            "Epoch 74/200\n",
            "19/19 [==============================] - 0s 11ms/step - loss: 0.0235\n",
            "Epoch 75/200\n",
            "19/19 [==============================] - 0s 12ms/step - loss: 0.0213\n",
            "Epoch 76/200\n",
            "19/19 [==============================] - 0s 12ms/step - loss: 0.0189\n",
            "Epoch 77/200\n",
            "19/19 [==============================] - 0s 11ms/step - loss: 0.0248\n",
            "Epoch 78/200\n",
            "19/19 [==============================] - 0s 11ms/step - loss: 0.0248\n",
            "Epoch 79/200\n",
            "19/19 [==============================] - 0s 12ms/step - loss: 0.0159\n",
            "Epoch 80/200\n",
            "19/19 [==============================] - 0s 12ms/step - loss: 0.0182\n",
            "Epoch 81/200\n",
            "19/19 [==============================] - 0s 11ms/step - loss: 0.0218\n",
            "Epoch 82/200\n",
            "19/19 [==============================] - 0s 11ms/step - loss: 0.0176\n",
            "Epoch 83/200\n",
            "19/19 [==============================] - 0s 12ms/step - loss: 0.0216\n",
            "Epoch 84/200\n",
            "19/19 [==============================] - 0s 12ms/step - loss: 0.0218\n",
            "Epoch 85/200\n",
            "19/19 [==============================] - 0s 12ms/step - loss: 0.0197\n",
            "Epoch 86/200\n",
            "19/19 [==============================] - 0s 21ms/step - loss: 0.0310\n",
            "Epoch 87/200\n",
            "19/19 [==============================] - 0s 20ms/step - loss: 0.0190\n",
            "Epoch 88/200\n",
            "19/19 [==============================] - 0s 19ms/step - loss: 0.0188\n",
            "Epoch 89/200\n",
            "19/19 [==============================] - 0s 20ms/step - loss: 0.0240\n",
            "Epoch 90/200\n",
            "19/19 [==============================] - 0s 20ms/step - loss: 0.0194\n",
            "Epoch 91/200\n",
            "19/19 [==============================] - 0s 21ms/step - loss: 0.0206\n",
            "Epoch 92/200\n",
            "19/19 [==============================] - 0s 22ms/step - loss: 0.0217\n",
            "Epoch 93/200\n",
            "19/19 [==============================] - 0s 21ms/step - loss: 0.0160\n",
            "Epoch 94/200\n",
            "19/19 [==============================] - 0s 19ms/step - loss: 0.0236\n",
            "Epoch 95/200\n",
            "19/19 [==============================] - 0s 11ms/step - loss: 0.0242\n",
            "Epoch 96/200\n",
            "19/19 [==============================] - 0s 12ms/step - loss: 0.0199\n",
            "Epoch 97/200\n",
            "19/19 [==============================] - 0s 12ms/step - loss: 0.0225\n",
            "Epoch 98/200\n",
            "19/19 [==============================] - 0s 11ms/step - loss: 0.0226\n",
            "Epoch 99/200\n",
            "19/19 [==============================] - 0s 11ms/step - loss: 0.0217\n",
            "Epoch 100/200\n",
            "19/19 [==============================] - 0s 13ms/step - loss: 0.0176\n",
            "Epoch 101/200\n",
            "19/19 [==============================] - 0s 11ms/step - loss: 0.0256\n",
            "Epoch 102/200\n",
            "19/19 [==============================] - 0s 11ms/step - loss: 0.0197\n",
            "Epoch 103/200\n",
            "19/19 [==============================] - 0s 11ms/step - loss: 0.0205\n",
            "Epoch 104/200\n",
            "19/19 [==============================] - 0s 12ms/step - loss: 0.0243\n",
            "Epoch 105/200\n",
            "19/19 [==============================] - 0s 12ms/step - loss: 0.0133\n",
            "Epoch 106/200\n",
            "19/19 [==============================] - 0s 12ms/step - loss: 0.0222\n",
            "Epoch 107/200\n",
            "19/19 [==============================] - 0s 11ms/step - loss: 0.0168\n",
            "Epoch 108/200\n",
            "19/19 [==============================] - 0s 11ms/step - loss: 0.0165\n",
            "Epoch 109/200\n",
            "19/19 [==============================] - 0s 12ms/step - loss: 0.0213\n",
            "Epoch 110/200\n",
            "19/19 [==============================] - 0s 11ms/step - loss: 0.0163\n",
            "Epoch 111/200\n",
            "19/19 [==============================] - 0s 11ms/step - loss: 0.0204\n",
            "Epoch 112/200\n",
            "19/19 [==============================] - 0s 12ms/step - loss: 0.0180\n",
            "Epoch 113/200\n",
            "19/19 [==============================] - 0s 11ms/step - loss: 0.0177\n",
            "Epoch 114/200\n",
            "19/19 [==============================] - 0s 12ms/step - loss: 0.0158\n",
            "Epoch 115/200\n",
            "19/19 [==============================] - 0s 11ms/step - loss: 0.0250\n",
            "Epoch 116/200\n",
            "19/19 [==============================] - 0s 12ms/step - loss: 0.0184\n",
            "Epoch 117/200\n",
            "19/19 [==============================] - 0s 11ms/step - loss: 0.0145\n",
            "Epoch 118/200\n",
            "19/19 [==============================] - 0s 11ms/step - loss: 0.0193\n",
            "Epoch 119/200\n",
            "19/19 [==============================] - 0s 12ms/step - loss: 0.0159\n",
            "Epoch 120/200\n",
            "19/19 [==============================] - 0s 11ms/step - loss: 0.0267\n",
            "Epoch 121/200\n",
            "19/19 [==============================] - 0s 11ms/step - loss: 0.0216\n",
            "Epoch 122/200\n",
            "19/19 [==============================] - 0s 11ms/step - loss: 0.0166\n",
            "Epoch 123/200\n",
            "19/19 [==============================] - 0s 12ms/step - loss: 0.0191\n",
            "Epoch 124/200\n",
            "19/19 [==============================] - 0s 12ms/step - loss: 0.0305\n",
            "Epoch 125/200\n",
            "19/19 [==============================] - 0s 13ms/step - loss: 0.0195\n",
            "Epoch 126/200\n",
            "19/19 [==============================] - 0s 12ms/step - loss: 0.0160\n",
            "Epoch 127/200\n",
            "19/19 [==============================] - 0s 12ms/step - loss: 0.0156\n",
            "Epoch 128/200\n",
            "19/19 [==============================] - 0s 12ms/step - loss: 0.0192\n",
            "Epoch 129/200\n",
            "19/19 [==============================] - 0s 12ms/step - loss: 0.0157\n",
            "Epoch 130/200\n",
            "19/19 [==============================] - 0s 11ms/step - loss: 0.0210\n",
            "Epoch 131/200\n",
            "19/19 [==============================] - 0s 11ms/step - loss: 0.0217\n",
            "Epoch 132/200\n",
            "19/19 [==============================] - 0s 12ms/step - loss: 0.0157\n",
            "Epoch 133/200\n",
            "19/19 [==============================] - 0s 12ms/step - loss: 0.0184\n",
            "Epoch 134/200\n",
            "19/19 [==============================] - 0s 11ms/step - loss: 0.0190\n",
            "Epoch 135/200\n",
            "19/19 [==============================] - 0s 14ms/step - loss: 0.0201\n",
            "Epoch 136/200\n",
            "19/19 [==============================] - 0s 13ms/step - loss: 0.0185\n",
            "Epoch 137/200\n",
            "19/19 [==============================] - 0s 12ms/step - loss: 0.0175\n",
            "Epoch 138/200\n",
            "19/19 [==============================] - 0s 19ms/step - loss: 0.0182\n",
            "Epoch 139/200\n",
            "19/19 [==============================] - 0s 20ms/step - loss: 0.0163\n",
            "Epoch 140/200\n",
            "19/19 [==============================] - 0s 20ms/step - loss: 0.0163\n",
            "Epoch 141/200\n",
            "19/19 [==============================] - 0s 19ms/step - loss: 0.0172\n",
            "Epoch 142/200\n",
            "19/19 [==============================] - 0s 20ms/step - loss: 0.0146\n",
            "Epoch 143/200\n",
            "19/19 [==============================] - 0s 21ms/step - loss: 0.0167\n",
            "Epoch 144/200\n",
            "19/19 [==============================] - 0s 21ms/step - loss: 0.0150\n",
            "Epoch 145/200\n",
            "19/19 [==============================] - 0s 21ms/step - loss: 0.0156\n",
            "Epoch 146/200\n",
            "19/19 [==============================] - 0s 20ms/step - loss: 0.0225\n",
            "Epoch 147/200\n",
            "19/19 [==============================] - 0s 21ms/step - loss: 0.0136\n",
            "Epoch 148/200\n",
            "19/19 [==============================] - 0s 20ms/step - loss: 0.0158\n",
            "Epoch 149/200\n",
            "19/19 [==============================] - 0s 12ms/step - loss: 0.0228\n",
            "Epoch 150/200\n",
            "19/19 [==============================] - 0s 12ms/step - loss: 0.0153\n",
            "Epoch 151/200\n",
            "19/19 [==============================] - 0s 13ms/step - loss: 0.0166\n",
            "Epoch 152/200\n",
            "19/19 [==============================] - 0s 12ms/step - loss: 0.0172\n",
            "Epoch 153/200\n",
            "19/19 [==============================] - 0s 11ms/step - loss: 0.0156\n",
            "Epoch 154/200\n",
            "19/19 [==============================] - 0s 12ms/step - loss: 0.0148\n",
            "Epoch 155/200\n",
            "19/19 [==============================] - 0s 13ms/step - loss: 0.0173\n",
            "Epoch 156/200\n",
            "19/19 [==============================] - 0s 12ms/step - loss: 0.0207\n",
            "Epoch 157/200\n",
            "19/19 [==============================] - 0s 12ms/step - loss: 0.0197\n",
            "Epoch 158/200\n",
            "19/19 [==============================] - 0s 12ms/step - loss: 0.0205\n",
            "Epoch 159/200\n",
            "19/19 [==============================] - 0s 12ms/step - loss: 0.0186\n",
            "Epoch 160/200\n",
            "19/19 [==============================] - 0s 13ms/step - loss: 0.0162\n",
            "Epoch 161/200\n",
            "19/19 [==============================] - 0s 12ms/step - loss: 0.0164\n",
            "Epoch 162/200\n",
            "19/19 [==============================] - 0s 12ms/step - loss: 0.0139\n",
            "Epoch 163/200\n",
            "19/19 [==============================] - 0s 12ms/step - loss: 0.0172\n",
            "Epoch 164/200\n",
            "19/19 [==============================] - 0s 12ms/step - loss: 0.0156\n",
            "Epoch 165/200\n",
            "19/19 [==============================] - 0s 12ms/step - loss: 0.0144\n",
            "Epoch 166/200\n",
            "19/19 [==============================] - 0s 11ms/step - loss: 0.0216\n",
            "Epoch 167/200\n",
            "19/19 [==============================] - 0s 11ms/step - loss: 0.0160\n",
            "Epoch 168/200\n",
            "19/19 [==============================] - 0s 11ms/step - loss: 0.0144\n",
            "Epoch 169/200\n",
            "19/19 [==============================] - 0s 13ms/step - loss: 0.0164\n",
            "Epoch 170/200\n",
            "19/19 [==============================] - 0s 12ms/step - loss: 0.0155\n",
            "Epoch 171/200\n",
            "19/19 [==============================] - 0s 13ms/step - loss: 0.0165\n",
            "Epoch 172/200\n",
            "19/19 [==============================] - 0s 11ms/step - loss: 0.0150\n",
            "Epoch 173/200\n",
            "19/19 [==============================] - 0s 12ms/step - loss: 0.0191\n",
            "Epoch 174/200\n",
            "19/19 [==============================] - 0s 12ms/step - loss: 0.0126\n",
            "Epoch 175/200\n",
            "19/19 [==============================] - 0s 11ms/step - loss: 0.0170\n",
            "Epoch 176/200\n",
            "19/19 [==============================] - 0s 11ms/step - loss: 0.0128\n",
            "Epoch 177/200\n",
            "19/19 [==============================] - 0s 11ms/step - loss: 0.0171\n",
            "Epoch 178/200\n",
            "19/19 [==============================] - 0s 12ms/step - loss: 0.0170\n",
            "Epoch 179/200\n",
            "19/19 [==============================] - 0s 12ms/step - loss: 0.0228\n",
            "Epoch 180/200\n",
            "19/19 [==============================] - 0s 12ms/step - loss: 0.0167\n",
            "Epoch 181/200\n",
            "19/19 [==============================] - 0s 11ms/step - loss: 0.0144\n",
            "Epoch 182/200\n",
            "19/19 [==============================] - 0s 12ms/step - loss: 0.0158\n",
            "Epoch 183/200\n",
            "19/19 [==============================] - 0s 11ms/step - loss: 0.0182\n",
            "Epoch 184/200\n",
            "19/19 [==============================] - 0s 11ms/step - loss: 0.0165\n",
            "Epoch 185/200\n",
            "19/19 [==============================] - 0s 12ms/step - loss: 0.0227\n",
            "Epoch 186/200\n",
            "19/19 [==============================] - 0s 12ms/step - loss: 0.0175\n",
            "Epoch 187/200\n",
            "19/19 [==============================] - 0s 12ms/step - loss: 0.0142\n",
            "Epoch 188/200\n",
            "19/19 [==============================] - 0s 12ms/step - loss: 0.0169\n",
            "Epoch 189/200\n",
            "19/19 [==============================] - 0s 11ms/step - loss: 0.0163\n",
            "Epoch 190/200\n",
            "19/19 [==============================] - 0s 11ms/step - loss: 0.0159\n",
            "Epoch 191/200\n",
            "19/19 [==============================] - 0s 14ms/step - loss: 0.0165\n",
            "Epoch 192/200\n",
            "19/19 [==============================] - 0s 20ms/step - loss: 0.0143\n",
            "Epoch 193/200\n",
            "19/19 [==============================] - 0s 20ms/step - loss: 0.0188\n",
            "Epoch 194/200\n",
            "19/19 [==============================] - 0s 21ms/step - loss: 0.0183\n",
            "Epoch 195/200\n",
            "19/19 [==============================] - 0s 20ms/step - loss: 0.0138\n",
            "Epoch 196/200\n",
            "19/19 [==============================] - 0s 21ms/step - loss: 0.0195\n",
            "Epoch 197/200\n",
            "19/19 [==============================] - 0s 20ms/step - loss: 0.0129\n",
            "Epoch 198/200\n",
            "19/19 [==============================] - 0s 21ms/step - loss: 0.0237\n",
            "Epoch 199/200\n",
            "19/19 [==============================] - 0s 21ms/step - loss: 0.0191\n",
            "Epoch 200/200\n",
            "19/19 [==============================] - 0s 21ms/step - loss: 0.0141\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Predicted prices from 2024-04-01 to 2028-12-01:\n",
            "2024-04-01: 2.751\n",
            "2024-05-01: 2.746\n",
            "2024-06-01: 2.737\n",
            "2024-07-01: 2.730\n",
            "2024-08-01: 2.722\n",
            "2024-09-01: 2.713\n",
            "2024-10-01: 2.704\n",
            "2024-11-01: 2.693\n",
            "2024-12-01: 2.684\n",
            "2025-01-01: 2.679\n",
            "2025-02-01: 2.673\n",
            "2025-03-01: 2.678\n",
            "2025-04-01: 2.684\n",
            "2025-05-01: 2.691\n",
            "2025-06-01: 2.697\n",
            "2025-07-01: 2.706\n",
            "2025-08-01: 2.714\n",
            "2025-09-01: 2.723\n",
            "2025-10-01: 2.732\n",
            "2025-11-01: 2.742\n",
            "2025-12-01: 2.751\n",
            "2026-01-01: 2.761\n",
            "2026-02-01: 2.772\n",
            "2026-03-01: 2.783\n",
            "2026-04-01: 2.795\n",
            "2026-05-01: 2.811\n",
            "2026-06-01: 2.828\n",
            "2026-07-01: 2.846\n",
            "2026-08-01: 2.864\n",
            "2026-09-01: 2.872\n",
            "2026-10-01: 2.871\n",
            "2026-11-01: 2.870\n",
            "2026-12-01: 2.869\n",
            "2027-01-01: 2.868\n",
            "2027-02-01: 2.867\n",
            "2027-03-01: 2.865\n",
            "2027-04-01: 2.863\n",
            "2027-05-01: 2.861\n",
            "2027-06-01: 2.859\n",
            "2027-07-01: 2.857\n",
            "2027-08-01: 2.843\n",
            "2027-09-01: 2.824\n",
            "2027-10-01: 2.804\n",
            "2027-11-01: 2.784\n",
            "2027-12-01: 2.763\n",
            "2028-01-01: 2.734\n",
            "2028-02-01: 2.693\n",
            "2028-03-01: 2.651\n",
            "2028-04-01: 2.608\n",
            "2028-05-01: 2.564\n",
            "2028-06-01: 2.520\n",
            "2028-07-01: 2.474\n",
            "2028-08-01: 2.428\n",
            "2028-09-01: 2.381\n",
            "2028-10-01: 2.332\n",
            "2028-11-01: 2.278\n",
            "2028-12-01: 2.223\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from datetime import datetime\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import LSTM, Dense, Dropout\n",
        "\n",
        "# Read the dataset\n",
        "df = pd.read_excel('LNG (High).xlsx')\n",
        "\n",
        "# Function to calculate the number of months between two dates\n",
        "def months_between(start_date, end_date):\n",
        "    start_date = datetime.strptime(start_date, \"%Y-%m-%d\")\n",
        "    end_date = datetime.strptime(end_date, \"%Y-%m-%d\")\n",
        "    return (end_date.year - start_date.year) * 12 + end_date.month - start_date.month + 1\n",
        "\n",
        "# Define the date range\n",
        "start_date = '2024-04-01'\n",
        "end_date = '2028-12-01'\n",
        "\n",
        "# Calculate the number of months to predict\n",
        "num_months = months_between(start_date, end_date)\n",
        "\n",
        "# Ensure data is sorted by date\n",
        "df['Date'] = pd.to_datetime(df['Date'], format='%b-%y')\n",
        "df = df.sort_values(by=\"Date\", ascending=True)\n",
        "\n",
        "# Normalize the data\n",
        "scaler = MinMaxScaler(feature_range=(0, 1))\n",
        "df['Price_normalized'] = scaler.fit_transform(df['Price'].values.reshape(-1,1))\n",
        "\n",
        "# Create a new feature representing the number of months since start date\n",
        "df['Months_since_start'] = (df['Date'] - pd.to_datetime(start_date)).dt.days / 30\n",
        "\n",
        "# Prepare data for training\n",
        "X_train = df['Months_since_start'].values.reshape(-1, 1, 1)\n",
        "y_train = df['Price_normalized'].values\n",
        "\n",
        "# Define and train the LSTM model with increased dropout rate\n",
        "model = Sequential()\n",
        "model.add(LSTM(256, activation='relu', return_sequences=True, input_shape=(1, 1)))\n",
        "model.add(Dropout(0.5))  # Increase dropout rate\n",
        "model.add(LSTM(128, activation='relu', return_sequences=True))\n",
        "model.add(Dropout(0.5))  # Increase dropout rate\n",
        "model.add(LSTM(64, activation='relu'))\n",
        "model.add(Dropout(0.5))  # Increase dropout rate\n",
        "model.add(Dense(32, activation='relu'))\n",
        "model.add(Dense(1, activation='relu'))\n",
        "model.compile(optimizer='adam', loss='mean_squared_error')\n",
        "model.fit(X_train, y_train, epochs=200, batch_size=8)\n",
        "\n",
        "# Generate future indices for prediction\n",
        "X_future = np.arange(df['Months_since_start'].iloc[-1] + 1, df['Months_since_start'].iloc[-1] + 1 + num_months)\n",
        "X_future = X_future.reshape(-1, 1, 1)  # Reshape for LSTM input\n",
        "\n",
        "# Generate predictions\n",
        "y_pred_normalized = model.predict(X_future)\n",
        "\n",
        "# Inverse transform predictions to get actual prices\n",
        "y_pred = scaler.inverse_transform(y_pred_normalized)\n",
        "\n",
        "# Ensure predictions are non-negative\n",
        "y_pred = np.maximum(y_pred, 0)\n",
        "\n",
        "# Generate date range for the predictions\n",
        "dates = pd.date_range(start=start_date, periods=num_months, freq='MS')\n",
        "\n",
        "# Print predicted prices with corresponding dates\n",
        "print(\"Predicted prices from 2024-04-01 to 2028-12-01:\")\n",
        "for date, price in zip(dates, y_pred.flatten()):\n",
        "    print(f\"{date.strftime('%Y-%m-%d')}: {price:.3f}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "B7jZuook-Keu",
        "outputId": "9dcaf0f2-1710-4129-900f-51af111bce3a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/200\n",
            "19/19 [==============================] - 8s 12ms/step - loss: 0.0723\n",
            "Epoch 2/200\n",
            "19/19 [==============================] - 0s 12ms/step - loss: 0.0606\n",
            "Epoch 3/200\n",
            "19/19 [==============================] - 0s 12ms/step - loss: 0.0450\n",
            "Epoch 4/200\n",
            "19/19 [==============================] - 0s 12ms/step - loss: 0.0400\n",
            "Epoch 5/200\n",
            "19/19 [==============================] - 0s 15ms/step - loss: 0.0344\n",
            "Epoch 6/200\n",
            "19/19 [==============================] - 0s 11ms/step - loss: 0.0361\n",
            "Epoch 7/200\n",
            "19/19 [==============================] - 0s 11ms/step - loss: 0.0354\n",
            "Epoch 8/200\n",
            "19/19 [==============================] - 0s 11ms/step - loss: 0.0294\n",
            "Epoch 9/200\n",
            "19/19 [==============================] - 0s 11ms/step - loss: 0.0325\n",
            "Epoch 10/200\n",
            "19/19 [==============================] - 0s 12ms/step - loss: 0.0308\n",
            "Epoch 11/200\n",
            "19/19 [==============================] - 0s 12ms/step - loss: 0.0311\n",
            "Epoch 12/200\n",
            "19/19 [==============================] - 0s 12ms/step - loss: 0.0318\n",
            "Epoch 13/200\n",
            "19/19 [==============================] - 0s 11ms/step - loss: 0.0298\n",
            "Epoch 14/200\n",
            "19/19 [==============================] - 0s 11ms/step - loss: 0.0277\n",
            "Epoch 15/200\n",
            "19/19 [==============================] - 0s 12ms/step - loss: 0.0295\n",
            "Epoch 16/200\n",
            "19/19 [==============================] - 0s 12ms/step - loss: 0.0281\n",
            "Epoch 17/200\n",
            "19/19 [==============================] - 0s 11ms/step - loss: 0.0241\n",
            "Epoch 18/200\n",
            "19/19 [==============================] - 0s 11ms/step - loss: 0.0308\n",
            "Epoch 19/200\n",
            "19/19 [==============================] - 0s 12ms/step - loss: 0.0235\n",
            "Epoch 20/200\n",
            "19/19 [==============================] - 0s 12ms/step - loss: 0.0293\n",
            "Epoch 21/200\n",
            "19/19 [==============================] - 0s 12ms/step - loss: 0.0315\n",
            "Epoch 22/200\n",
            "19/19 [==============================] - 0s 12ms/step - loss: 0.0274\n",
            "Epoch 23/200\n",
            "19/19 [==============================] - 0s 11ms/step - loss: 0.0293\n",
            "Epoch 24/200\n",
            "19/19 [==============================] - 0s 11ms/step - loss: 0.0288\n",
            "Epoch 25/200\n",
            "19/19 [==============================] - 0s 12ms/step - loss: 0.0256\n",
            "Epoch 26/200\n",
            "19/19 [==============================] - 0s 11ms/step - loss: 0.0315\n",
            "Epoch 27/200\n",
            "19/19 [==============================] - 0s 11ms/step - loss: 0.0296\n",
            "Epoch 28/200\n",
            "19/19 [==============================] - 0s 11ms/step - loss: 0.0269\n",
            "Epoch 29/200\n",
            "19/19 [==============================] - 0s 11ms/step - loss: 0.0326\n",
            "Epoch 30/200\n",
            "19/19 [==============================] - 0s 11ms/step - loss: 0.0266\n",
            "Epoch 31/200\n",
            "19/19 [==============================] - 0s 11ms/step - loss: 0.0256\n",
            "Epoch 32/200\n",
            "19/19 [==============================] - 0s 11ms/step - loss: 0.0279\n",
            "Epoch 33/200\n",
            "19/19 [==============================] - 0s 11ms/step - loss: 0.0230\n",
            "Epoch 34/200\n",
            "19/19 [==============================] - 0s 12ms/step - loss: 0.0276\n",
            "Epoch 35/200\n",
            "19/19 [==============================] - 0s 11ms/step - loss: 0.0297\n",
            "Epoch 36/200\n",
            "19/19 [==============================] - 0s 17ms/step - loss: 0.0341\n",
            "Epoch 37/200\n",
            "19/19 [==============================] - 0s 20ms/step - loss: 0.0279\n",
            "Epoch 38/200\n",
            "19/19 [==============================] - 0s 21ms/step - loss: 0.0283\n",
            "Epoch 39/200\n",
            "19/19 [==============================] - 0s 18ms/step - loss: 0.0281\n",
            "Epoch 40/200\n",
            "19/19 [==============================] - 0s 20ms/step - loss: 0.0299\n",
            "Epoch 41/200\n",
            "19/19 [==============================] - 0s 19ms/step - loss: 0.0224\n",
            "Epoch 42/200\n",
            "19/19 [==============================] - 0s 19ms/step - loss: 0.0234\n",
            "Epoch 43/200\n",
            "19/19 [==============================] - 0s 20ms/step - loss: 0.0247\n",
            "Epoch 44/200\n",
            "19/19 [==============================] - 0s 20ms/step - loss: 0.0243\n",
            "Epoch 45/200\n",
            "19/19 [==============================] - 0s 19ms/step - loss: 0.0216\n",
            "Epoch 46/200\n",
            "19/19 [==============================] - 0s 20ms/step - loss: 0.0263\n",
            "Epoch 47/200\n",
            "19/19 [==============================] - 0s 14ms/step - loss: 0.0221\n",
            "Epoch 48/200\n",
            "19/19 [==============================] - 0s 11ms/step - loss: 0.0350\n",
            "Epoch 49/200\n",
            "19/19 [==============================] - 0s 11ms/step - loss: 0.0293\n",
            "Epoch 50/200\n",
            "19/19 [==============================] - 0s 12ms/step - loss: 0.0239\n",
            "Epoch 51/200\n",
            "19/19 [==============================] - 0s 11ms/step - loss: 0.0249\n",
            "Epoch 52/200\n",
            "19/19 [==============================] - 0s 11ms/step - loss: 0.0257\n",
            "Epoch 53/200\n",
            "19/19 [==============================] - 0s 11ms/step - loss: 0.0254\n",
            "Epoch 54/200\n",
            "19/19 [==============================] - 0s 11ms/step - loss: 0.0280\n",
            "Epoch 55/200\n",
            "19/19 [==============================] - 0s 12ms/step - loss: 0.0221\n",
            "Epoch 56/200\n",
            "19/19 [==============================] - 0s 11ms/step - loss: 0.0278\n",
            "Epoch 57/200\n",
            "19/19 [==============================] - 0s 11ms/step - loss: 0.0188\n",
            "Epoch 58/200\n",
            "19/19 [==============================] - 0s 11ms/step - loss: 0.0237\n",
            "Epoch 59/200\n",
            "19/19 [==============================] - 0s 12ms/step - loss: 0.0224\n",
            "Epoch 60/200\n",
            "19/19 [==============================] - 0s 13ms/step - loss: 0.0285\n",
            "Epoch 61/200\n",
            "19/19 [==============================] - 0s 11ms/step - loss: 0.0266\n",
            "Epoch 62/200\n",
            "19/19 [==============================] - 0s 11ms/step - loss: 0.0286\n",
            "Epoch 63/200\n",
            "19/19 [==============================] - 0s 11ms/step - loss: 0.0218\n",
            "Epoch 64/200\n",
            "19/19 [==============================] - 0s 12ms/step - loss: 0.0298\n",
            "Epoch 65/200\n",
            "19/19 [==============================] - 0s 12ms/step - loss: 0.0226\n",
            "Epoch 66/200\n",
            "19/19 [==============================] - 0s 11ms/step - loss: 0.0221\n",
            "Epoch 67/200\n",
            "19/19 [==============================] - 0s 11ms/step - loss: 0.0207\n",
            "Epoch 68/200\n",
            "19/19 [==============================] - 0s 11ms/step - loss: 0.0193\n",
            "Epoch 69/200\n",
            "19/19 [==============================] - 0s 12ms/step - loss: 0.0274\n",
            "Epoch 70/200\n",
            "19/19 [==============================] - 0s 11ms/step - loss: 0.0207\n",
            "Epoch 71/200\n",
            "19/19 [==============================] - 0s 11ms/step - loss: 0.0227\n",
            "Epoch 72/200\n",
            "19/19 [==============================] - 0s 11ms/step - loss: 0.0193\n",
            "Epoch 73/200\n",
            "19/19 [==============================] - 0s 12ms/step - loss: 0.0215\n",
            "Epoch 74/200\n",
            "19/19 [==============================] - 0s 11ms/step - loss: 0.0288\n",
            "Epoch 75/200\n",
            "19/19 [==============================] - 0s 11ms/step - loss: 0.0250\n",
            "Epoch 76/200\n",
            "19/19 [==============================] - 0s 11ms/step - loss: 0.0211\n",
            "Epoch 77/200\n",
            "19/19 [==============================] - 0s 11ms/step - loss: 0.0231\n",
            "Epoch 78/200\n",
            "19/19 [==============================] - 0s 12ms/step - loss: 0.0218\n",
            "Epoch 79/200\n",
            "19/19 [==============================] - 0s 12ms/step - loss: 0.0187\n",
            "Epoch 80/200\n",
            "19/19 [==============================] - 0s 11ms/step - loss: 0.0201\n",
            "Epoch 81/200\n",
            "19/19 [==============================] - 0s 12ms/step - loss: 0.0234\n",
            "Epoch 82/200\n",
            "19/19 [==============================] - 0s 12ms/step - loss: 0.0233\n",
            "Epoch 83/200\n",
            "19/19 [==============================] - 0s 11ms/step - loss: 0.0183\n",
            "Epoch 84/200\n",
            "19/19 [==============================] - 0s 11ms/step - loss: 0.0175\n",
            "Epoch 85/200\n",
            "19/19 [==============================] - 0s 11ms/step - loss: 0.0183\n",
            "Epoch 86/200\n",
            "19/19 [==============================] - 0s 12ms/step - loss: 0.0210\n",
            "Epoch 87/200\n",
            "19/19 [==============================] - 0s 12ms/step - loss: 0.0185\n",
            "Epoch 88/200\n",
            "19/19 [==============================] - 0s 12ms/step - loss: 0.0210\n",
            "Epoch 89/200\n",
            "19/19 [==============================] - 0s 11ms/step - loss: 0.0195\n",
            "Epoch 90/200\n",
            "19/19 [==============================] - 0s 11ms/step - loss: 0.0207\n",
            "Epoch 91/200\n",
            "19/19 [==============================] - 0s 13ms/step - loss: 0.0180\n",
            "Epoch 92/200\n",
            "19/19 [==============================] - 0s 20ms/step - loss: 0.0183\n",
            "Epoch 93/200\n",
            "19/19 [==============================] - 0s 19ms/step - loss: 0.0187\n",
            "Epoch 94/200\n",
            "19/19 [==============================] - 0s 21ms/step - loss: 0.0215\n",
            "Epoch 95/200\n",
            "19/19 [==============================] - 0s 19ms/step - loss: 0.0199\n",
            "Epoch 96/200\n",
            "19/19 [==============================] - 0s 20ms/step - loss: 0.0182\n",
            "Epoch 97/200\n",
            "19/19 [==============================] - 0s 20ms/step - loss: 0.0209\n",
            "Epoch 98/200\n",
            "19/19 [==============================] - 0s 20ms/step - loss: 0.0198\n",
            "Epoch 99/200\n",
            "19/19 [==============================] - 0s 21ms/step - loss: 0.0195\n",
            "Epoch 100/200\n",
            "19/19 [==============================] - 0s 21ms/step - loss: 0.0226\n",
            "Epoch 101/200\n",
            "19/19 [==============================] - 0s 20ms/step - loss: 0.0179\n",
            "Epoch 102/200\n",
            "19/19 [==============================] - 0s 13ms/step - loss: 0.0191\n",
            "Epoch 103/200\n",
            "19/19 [==============================] - 0s 12ms/step - loss: 0.0175\n",
            "Epoch 104/200\n",
            "19/19 [==============================] - 0s 11ms/step - loss: 0.0186\n",
            "Epoch 105/200\n",
            "19/19 [==============================] - 0s 12ms/step - loss: 0.0228\n",
            "Epoch 106/200\n",
            "19/19 [==============================] - 0s 11ms/step - loss: 0.0193\n",
            "Epoch 107/200\n",
            "19/19 [==============================] - 0s 11ms/step - loss: 0.0214\n",
            "Epoch 108/200\n",
            "19/19 [==============================] - 0s 12ms/step - loss: 0.0188\n",
            "Epoch 109/200\n",
            "19/19 [==============================] - 0s 11ms/step - loss: 0.0221\n",
            "Epoch 110/200\n",
            "19/19 [==============================] - 0s 11ms/step - loss: 0.0242\n",
            "Epoch 111/200\n",
            "19/19 [==============================] - 0s 11ms/step - loss: 0.0180\n",
            "Epoch 112/200\n",
            "19/19 [==============================] - 0s 12ms/step - loss: 0.0181\n",
            "Epoch 113/200\n",
            "19/19 [==============================] - 0s 11ms/step - loss: 0.0182\n",
            "Epoch 114/200\n",
            "19/19 [==============================] - 0s 11ms/step - loss: 0.0190\n",
            "Epoch 115/200\n",
            "19/19 [==============================] - 0s 11ms/step - loss: 0.0238\n",
            "Epoch 116/200\n",
            "19/19 [==============================] - 0s 11ms/step - loss: 0.0209\n",
            "Epoch 117/200\n",
            "19/19 [==============================] - 0s 12ms/step - loss: 0.0202\n",
            "Epoch 118/200\n",
            "19/19 [==============================] - 0s 11ms/step - loss: 0.0183\n",
            "Epoch 119/200\n",
            "19/19 [==============================] - 0s 11ms/step - loss: 0.0154\n",
            "Epoch 120/200\n",
            "19/19 [==============================] - 0s 11ms/step - loss: 0.0210\n",
            "Epoch 121/200\n",
            "19/19 [==============================] - 0s 11ms/step - loss: 0.0154\n",
            "Epoch 122/200\n",
            "19/19 [==============================] - 0s 12ms/step - loss: 0.0150\n",
            "Epoch 123/200\n",
            "19/19 [==============================] - 0s 11ms/step - loss: 0.0202\n",
            "Epoch 124/200\n",
            "19/19 [==============================] - 0s 13ms/step - loss: 0.0152\n",
            "Epoch 125/200\n",
            "19/19 [==============================] - 0s 11ms/step - loss: 0.0158\n",
            "Epoch 126/200\n",
            "19/19 [==============================] - 0s 12ms/step - loss: 0.0185\n",
            "Epoch 127/200\n",
            "19/19 [==============================] - 0s 11ms/step - loss: 0.0186\n",
            "Epoch 128/200\n",
            "19/19 [==============================] - 0s 11ms/step - loss: 0.0171\n",
            "Epoch 129/200\n",
            "19/19 [==============================] - 0s 12ms/step - loss: 0.0198\n",
            "Epoch 130/200\n",
            "19/19 [==============================] - 0s 11ms/step - loss: 0.0171\n",
            "Epoch 131/200\n",
            "19/19 [==============================] - 0s 12ms/step - loss: 0.0145\n",
            "Epoch 132/200\n",
            "19/19 [==============================] - 0s 11ms/step - loss: 0.0213\n",
            "Epoch 133/200\n",
            "19/19 [==============================] - 0s 12ms/step - loss: 0.0164\n",
            "Epoch 134/200\n",
            "19/19 [==============================] - 0s 11ms/step - loss: 0.0127\n",
            "Epoch 135/200\n",
            "19/19 [==============================] - 0s 12ms/step - loss: 0.0173\n",
            "Epoch 136/200\n",
            "19/19 [==============================] - 0s 12ms/step - loss: 0.0191\n",
            "Epoch 137/200\n",
            "19/19 [==============================] - 0s 12ms/step - loss: 0.0136\n",
            "Epoch 138/200\n",
            "19/19 [==============================] - 0s 12ms/step - loss: 0.0165\n",
            "Epoch 139/200\n",
            "19/19 [==============================] - 0s 11ms/step - loss: 0.0150\n",
            "Epoch 140/200\n",
            "19/19 [==============================] - 0s 13ms/step - loss: 0.0185\n",
            "Epoch 141/200\n",
            "19/19 [==============================] - 0s 11ms/step - loss: 0.0138\n",
            "Epoch 142/200\n",
            "19/19 [==============================] - 0s 13ms/step - loss: 0.0176\n",
            "Epoch 143/200\n",
            "19/19 [==============================] - 0s 11ms/step - loss: 0.0161\n",
            "Epoch 144/200\n",
            "19/19 [==============================] - 0s 12ms/step - loss: 0.0138\n",
            "Epoch 145/200\n",
            "19/19 [==============================] - 0s 12ms/step - loss: 0.0190\n",
            "Epoch 146/200\n",
            "19/19 [==============================] - 0s 19ms/step - loss: 0.0164\n",
            "Epoch 147/200\n",
            "19/19 [==============================] - 0s 20ms/step - loss: 0.0194\n",
            "Epoch 148/200\n",
            "19/19 [==============================] - 0s 19ms/step - loss: 0.0155\n",
            "Epoch 149/200\n",
            "19/19 [==============================] - 0s 19ms/step - loss: 0.0145\n",
            "Epoch 150/200\n",
            "19/19 [==============================] - 0s 20ms/step - loss: 0.0143\n",
            "Epoch 151/200\n",
            "19/19 [==============================] - 0s 20ms/step - loss: 0.0153\n",
            "Epoch 152/200\n",
            "19/19 [==============================] - 0s 21ms/step - loss: 0.0219\n",
            "Epoch 153/200\n",
            "19/19 [==============================] - 0s 21ms/step - loss: 0.0189\n",
            "Epoch 154/200\n",
            "19/19 [==============================] - 0s 20ms/step - loss: 0.0153\n",
            "Epoch 155/200\n",
            "19/19 [==============================] - 0s 20ms/step - loss: 0.0142\n",
            "Epoch 156/200\n",
            "19/19 [==============================] - 0s 21ms/step - loss: 0.0211\n",
            "Epoch 157/200\n",
            "19/19 [==============================] - 0s 11ms/step - loss: 0.0228\n",
            "Epoch 158/200\n",
            "19/19 [==============================] - 0s 12ms/step - loss: 0.0128\n",
            "Epoch 159/200\n",
            "19/19 [==============================] - 0s 11ms/step - loss: 0.0138\n",
            "Epoch 160/200\n",
            "19/19 [==============================] - 0s 12ms/step - loss: 0.0147\n",
            "Epoch 161/200\n",
            "19/19 [==============================] - 0s 12ms/step - loss: 0.0160\n",
            "Epoch 162/200\n",
            "19/19 [==============================] - 0s 11ms/step - loss: 0.0175\n",
            "Epoch 163/200\n",
            "19/19 [==============================] - 0s 11ms/step - loss: 0.0136\n",
            "Epoch 164/200\n",
            "19/19 [==============================] - 0s 12ms/step - loss: 0.0163\n",
            "Epoch 165/200\n",
            "19/19 [==============================] - 0s 11ms/step - loss: 0.0151\n",
            "Epoch 166/200\n",
            "19/19 [==============================] - 0s 11ms/step - loss: 0.0159\n",
            "Epoch 167/200\n",
            "19/19 [==============================] - 0s 11ms/step - loss: 0.0132\n",
            "Epoch 168/200\n",
            "19/19 [==============================] - 0s 12ms/step - loss: 0.0141\n",
            "Epoch 169/200\n",
            "19/19 [==============================] - 0s 12ms/step - loss: 0.0156\n",
            "Epoch 170/200\n",
            "19/19 [==============================] - 0s 11ms/step - loss: 0.0127\n",
            "Epoch 171/200\n",
            "19/19 [==============================] - 0s 11ms/step - loss: 0.0167\n",
            "Epoch 172/200\n",
            "19/19 [==============================] - 0s 11ms/step - loss: 0.0167\n",
            "Epoch 173/200\n",
            "19/19 [==============================] - 0s 12ms/step - loss: 0.0167\n",
            "Epoch 174/200\n",
            "19/19 [==============================] - 0s 11ms/step - loss: 0.0176\n",
            "Epoch 175/200\n",
            "19/19 [==============================] - 0s 11ms/step - loss: 0.0148\n",
            "Epoch 176/200\n",
            "19/19 [==============================] - 0s 11ms/step - loss: 0.0162\n",
            "Epoch 177/200\n",
            "19/19 [==============================] - 0s 11ms/step - loss: 0.0141\n",
            "Epoch 178/200\n",
            "19/19 [==============================] - 0s 13ms/step - loss: 0.0165\n",
            "Epoch 179/200\n",
            "19/19 [==============================] - 0s 12ms/step - loss: 0.0134\n",
            "Epoch 180/200\n",
            "19/19 [==============================] - 0s 11ms/step - loss: 0.0145\n",
            "Epoch 181/200\n",
            "19/19 [==============================] - 0s 12ms/step - loss: 0.0181\n",
            "Epoch 182/200\n",
            "19/19 [==============================] - 0s 12ms/step - loss: 0.0134\n",
            "Epoch 183/200\n",
            "19/19 [==============================] - 0s 11ms/step - loss: 0.0145\n",
            "Epoch 184/200\n",
            "19/19 [==============================] - 0s 11ms/step - loss: 0.0140\n",
            "Epoch 185/200\n",
            "19/19 [==============================] - 0s 12ms/step - loss: 0.0131\n",
            "Epoch 186/200\n",
            "19/19 [==============================] - 0s 11ms/step - loss: 0.0123\n",
            "Epoch 187/200\n",
            "19/19 [==============================] - 0s 12ms/step - loss: 0.0146\n",
            "Epoch 188/200\n",
            "19/19 [==============================] - 0s 11ms/step - loss: 0.0177\n",
            "Epoch 189/200\n",
            "19/19 [==============================] - 0s 12ms/step - loss: 0.0152\n",
            "Epoch 190/200\n",
            "19/19 [==============================] - 0s 12ms/step - loss: 0.0222\n",
            "Epoch 191/200\n",
            "19/19 [==============================] - 0s 12ms/step - loss: 0.0177\n",
            "Epoch 192/200\n",
            "19/19 [==============================] - 0s 12ms/step - loss: 0.0163\n",
            "Epoch 193/200\n",
            "19/19 [==============================] - 0s 11ms/step - loss: 0.0161\n",
            "Epoch 194/200\n",
            "19/19 [==============================] - 0s 12ms/step - loss: 0.0151\n",
            "Epoch 195/200\n",
            "19/19 [==============================] - 0s 11ms/step - loss: 0.0160\n",
            "Epoch 196/200\n",
            "19/19 [==============================] - 0s 13ms/step - loss: 0.0152\n",
            "Epoch 197/200\n",
            "19/19 [==============================] - 0s 12ms/step - loss: 0.0117\n",
            "Epoch 198/200\n",
            "19/19 [==============================] - 0s 12ms/step - loss: 0.0168\n",
            "Epoch 199/200\n",
            "19/19 [==============================] - 0s 12ms/step - loss: 0.0140\n",
            "Epoch 200/200\n",
            "19/19 [==============================] - 0s 14ms/step - loss: 0.0146\n",
            "2/2 [==============================] - 1s 8ms/step\n",
            "Predicted prices from 2024-04-01 to 2028-12-01:\n",
            "2024-04-01: 2.724\n",
            "2024-05-01: 2.737\n",
            "2024-06-01: 2.749\n",
            "2024-07-01: 2.760\n",
            "2024-08-01: 2.771\n",
            "2024-09-01: 2.781\n",
            "2024-10-01: 2.793\n",
            "2024-11-01: 2.804\n",
            "2024-12-01: 2.816\n",
            "2025-01-01: 2.828\n",
            "2025-02-01: 2.841\n",
            "2025-03-01: 2.854\n",
            "2025-04-01: 2.868\n",
            "2025-05-01: 2.882\n",
            "2025-06-01: 2.896\n",
            "2025-07-01: 2.911\n",
            "2025-08-01: 2.926\n",
            "2025-09-01: 2.941\n",
            "2025-10-01: 2.956\n",
            "2025-11-01: 2.972\n",
            "2025-12-01: 2.987\n",
            "2026-01-01: 3.003\n",
            "2026-02-01: 3.018\n",
            "2026-03-01: 3.034\n",
            "2026-04-01: 3.049\n",
            "2026-05-01: 3.065\n",
            "2026-06-01: 3.080\n",
            "2026-07-01: 3.095\n",
            "2026-08-01: 3.110\n",
            "2026-09-01: 3.125\n",
            "2026-10-01: 3.142\n",
            "2026-11-01: 3.159\n",
            "2026-12-01: 3.175\n",
            "2027-01-01: 3.191\n",
            "2027-02-01: 3.207\n",
            "2027-03-01: 3.216\n",
            "2027-04-01: 3.220\n",
            "2027-05-01: 3.225\n",
            "2027-06-01: 3.229\n",
            "2027-07-01: 3.232\n",
            "2027-08-01: 3.236\n",
            "2027-09-01: 3.239\n",
            "2027-10-01: 3.244\n",
            "2027-11-01: 3.250\n",
            "2027-12-01: 3.257\n",
            "2028-01-01: 3.264\n",
            "2028-02-01: 3.272\n",
            "2028-03-01: 3.282\n",
            "2028-04-01: 3.291\n",
            "2028-05-01: 3.300\n",
            "2028-06-01: 3.310\n",
            "2028-07-01: 3.319\n",
            "2028-08-01: 3.329\n",
            "2028-09-01: 3.338\n",
            "2028-10-01: 3.347\n",
            "2028-11-01: 3.356\n",
            "2028-12-01: 3.365\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from datetime import datetime\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import LSTM, Dense, Dropout\n",
        "\n",
        "# Read the dataset\n",
        "df = pd.read_excel('LNG (High).xlsx')\n",
        "\n",
        "# Function to calculate the number of months between two dates\n",
        "def months_between(start_date, end_date):\n",
        "    start_date = datetime.strptime(start_date, \"%Y-%m-%d\")\n",
        "    end_date = datetime.strptime(end_date, \"%Y-%m-%d\")\n",
        "    return (end_date.year - start_date.year) * 12 + end_date.month - start_date.month + 1\n",
        "\n",
        "# Define the date range\n",
        "start_date = '2024-04-01'\n",
        "end_date = '2028-12-01'\n",
        "\n",
        "# Calculate the number of months to predict\n",
        "num_months = months_between(start_date, end_date)\n",
        "\n",
        "# Ensure data is sorted by date\n",
        "df['Date'] = pd.to_datetime(df['Date'], format='%b-%y')\n",
        "df = df.sort_values(by=\"Date\", ascending=True)\n",
        "\n",
        "# Normalize the data\n",
        "scaler = MinMaxScaler(feature_range=(0, 1))\n",
        "df['Price_normalized'] = scaler.fit_transform(df['Price'].values.reshape(-1,1))\n",
        "\n",
        "# Create a new feature representing the number of months since start date\n",
        "df['Months_since_start'] = (df['Date'] - pd.to_datetime(start_date)).dt.days / 30\n",
        "\n",
        "# Prepare data for training\n",
        "X_train = df['Months_since_start'].values.reshape(-1, 1, 1)\n",
        "y_train = df['Price_normalized'].values\n",
        "\n",
        "# Define and train the LSTM model with increased dropout rate\n",
        "model = Sequential()\n",
        "model.add(LSTM(256, activation='relu', return_sequences=True, input_shape=(1, 1)))\n",
        "model.add(Dropout(0.5))  # Increase dropout rate\n",
        "model.add(LSTM(128, activation='relu', return_sequences=True))\n",
        "model.add(Dropout(0.5))  # Increase dropout rate\n",
        "model.add(LSTM(64, activation='relu'))\n",
        "model.add(Dropout(0.5))  # Increase dropout rate\n",
        "model.add(Dense(32, activation='relu'))\n",
        "model.add(Dense(1, activation='relu'))\n",
        "model.compile(optimizer='adam', loss='mean_squared_error')\n",
        "model.fit(X_train, y_train, epochs=200, batch_size=8)\n",
        "\n",
        "# Generate future indices for prediction\n",
        "X_future = np.arange(df['Months_since_start'].iloc[-1] + 1, df['Months_since_start'].iloc[-1] + 1 + num_months)\n",
        "X_future = X_future.reshape(-1, 1, 1)  # Reshape for LSTM input\n",
        "\n",
        "# Generate predictions\n",
        "y_pred_normalized = model.predict(X_future)\n",
        "\n",
        "# Inverse transform predictions to get actual prices\n",
        "y_pred = scaler.inverse_transform(y_pred_normalized)\n",
        "\n",
        "# Ensure predictions are non-negative\n",
        "y_pred = np.maximum(y_pred, 0)\n",
        "\n",
        "# Generate date range for the predictions\n",
        "dates = pd.date_range(start=start_date, periods=num_months, freq='MS')\n",
        "\n",
        "# Print predicted prices with corresponding dates\n",
        "print(\"Predicted prices from 2024-04-01 to 2028-12-01:\")\n",
        "for date, price in zip(dates, y_pred.flatten()):\n",
        "    print(f\"{date.strftime('%Y-%m-%d')}: {price:.3f}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZaXdMWqS-93z",
        "outputId": "c015f86c-ee2d-4b4a-d5f5-77db45582caa"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/200\n",
            "19/19 [==============================] - 9s 22ms/step - loss: 0.0780\n",
            "Epoch 2/200\n",
            "19/19 [==============================] - 0s 23ms/step - loss: 0.0599\n",
            "Epoch 3/200\n",
            "19/19 [==============================] - 0s 22ms/step - loss: 0.0482\n",
            "Epoch 4/200\n",
            "19/19 [==============================] - 0s 17ms/step - loss: 0.0456\n",
            "Epoch 5/200\n",
            "19/19 [==============================] - 0s 12ms/step - loss: 0.0411\n",
            "Epoch 6/200\n",
            "19/19 [==============================] - 0s 13ms/step - loss: 0.0404\n",
            "Epoch 7/200\n",
            "19/19 [==============================] - 0s 13ms/step - loss: 0.0397\n",
            "Epoch 8/200\n",
            "19/19 [==============================] - 0s 12ms/step - loss: 0.0377\n",
            "Epoch 9/200\n",
            "19/19 [==============================] - 0s 11ms/step - loss: 0.0368\n",
            "Epoch 10/200\n",
            "19/19 [==============================] - 0s 14ms/step - loss: 0.0345\n",
            "Epoch 11/200\n",
            "19/19 [==============================] - 0s 12ms/step - loss: 0.0355\n",
            "Epoch 12/200\n",
            "19/19 [==============================] - 0s 12ms/step - loss: 0.0347\n",
            "Epoch 13/200\n",
            "19/19 [==============================] - 0s 12ms/step - loss: 0.0298\n",
            "Epoch 14/200\n",
            "19/19 [==============================] - 0s 11ms/step - loss: 0.0302\n",
            "Epoch 15/200\n",
            "19/19 [==============================] - 0s 12ms/step - loss: 0.0301\n",
            "Epoch 16/200\n",
            "19/19 [==============================] - 0s 11ms/step - loss: 0.0303\n",
            "Epoch 17/200\n",
            "19/19 [==============================] - 0s 12ms/step - loss: 0.0249\n",
            "Epoch 18/200\n",
            "19/19 [==============================] - 0s 12ms/step - loss: 0.0227\n",
            "Epoch 19/200\n",
            "19/19 [==============================] - 0s 12ms/step - loss: 0.0285\n",
            "Epoch 20/200\n",
            "19/19 [==============================] - 0s 11ms/step - loss: 0.0277\n",
            "Epoch 21/200\n",
            "19/19 [==============================] - 0s 11ms/step - loss: 0.0306\n",
            "Epoch 22/200\n",
            "19/19 [==============================] - 0s 11ms/step - loss: 0.0289\n",
            "Epoch 23/200\n",
            "19/19 [==============================] - 0s 11ms/step - loss: 0.0281\n",
            "Epoch 24/200\n",
            "19/19 [==============================] - 0s 12ms/step - loss: 0.0196\n",
            "Epoch 25/200\n",
            "19/19 [==============================] - 0s 11ms/step - loss: 0.0282\n",
            "Epoch 26/200\n",
            "19/19 [==============================] - 0s 11ms/step - loss: 0.0268\n",
            "Epoch 27/200\n",
            "19/19 [==============================] - 0s 11ms/step - loss: 0.0275\n",
            "Epoch 28/200\n",
            "19/19 [==============================] - 0s 13ms/step - loss: 0.0306\n",
            "Epoch 29/200\n",
            "19/19 [==============================] - 0s 12ms/step - loss: 0.0346\n",
            "Epoch 30/200\n",
            "19/19 [==============================] - 0s 11ms/step - loss: 0.0280\n",
            "Epoch 31/200\n",
            "19/19 [==============================] - 0s 11ms/step - loss: 0.0309\n",
            "Epoch 32/200\n",
            "19/19 [==============================] - 0s 11ms/step - loss: 0.0247\n",
            "Epoch 33/200\n",
            "19/19 [==============================] - 0s 12ms/step - loss: 0.0194\n",
            "Epoch 34/200\n",
            "19/19 [==============================] - 0s 18ms/step - loss: 0.0305\n",
            "Epoch 35/200\n",
            "19/19 [==============================] - 0s 20ms/step - loss: 0.0277\n",
            "Epoch 36/200\n",
            "19/19 [==============================] - 0s 20ms/step - loss: 0.0269\n",
            "Epoch 37/200\n",
            "19/19 [==============================] - 0s 20ms/step - loss: 0.0304\n",
            "Epoch 38/200\n",
            "19/19 [==============================] - 0s 20ms/step - loss: 0.0281\n",
            "Epoch 39/200\n",
            "19/19 [==============================] - 0s 21ms/step - loss: 0.0279\n",
            "Epoch 40/200\n",
            "19/19 [==============================] - 0s 20ms/step - loss: 0.0297\n",
            "Epoch 41/200\n",
            "19/19 [==============================] - 0s 21ms/step - loss: 0.0234\n",
            "Epoch 42/200\n",
            "19/19 [==============================] - 0s 21ms/step - loss: 0.0223\n",
            "Epoch 43/200\n",
            "19/19 [==============================] - 0s 21ms/step - loss: 0.0238\n",
            "Epoch 44/200\n",
            "19/19 [==============================] - 0s 12ms/step - loss: 0.0214\n",
            "Epoch 45/200\n",
            "19/19 [==============================] - 0s 11ms/step - loss: 0.0229\n",
            "Epoch 46/200\n",
            "19/19 [==============================] - 0s 11ms/step - loss: 0.0271\n",
            "Epoch 47/200\n",
            "19/19 [==============================] - 0s 11ms/step - loss: 0.0245\n",
            "Epoch 48/200\n",
            "19/19 [==============================] - 0s 12ms/step - loss: 0.0223\n",
            "Epoch 49/200\n",
            "19/19 [==============================] - 0s 12ms/step - loss: 0.0251\n",
            "Epoch 50/200\n",
            "19/19 [==============================] - 0s 11ms/step - loss: 0.0285\n",
            "Epoch 51/200\n",
            "19/19 [==============================] - 0s 12ms/step - loss: 0.0246\n",
            "Epoch 52/200\n",
            "19/19 [==============================] - 0s 12ms/step - loss: 0.0244\n",
            "Epoch 53/200\n",
            "19/19 [==============================] - 0s 12ms/step - loss: 0.0223\n",
            "Epoch 54/200\n",
            "19/19 [==============================] - 0s 11ms/step - loss: 0.0216\n",
            "Epoch 55/200\n",
            "19/19 [==============================] - 0s 11ms/step - loss: 0.0210\n",
            "Epoch 56/200\n",
            "19/19 [==============================] - 0s 12ms/step - loss: 0.0250\n",
            "Epoch 57/200\n",
            "19/19 [==============================] - 0s 11ms/step - loss: 0.0247\n",
            "Epoch 58/200\n",
            "19/19 [==============================] - 0s 13ms/step - loss: 0.0237\n",
            "Epoch 59/200\n",
            "19/19 [==============================] - 0s 12ms/step - loss: 0.0259\n",
            "Epoch 60/200\n",
            "19/19 [==============================] - 0s 11ms/step - loss: 0.0212\n",
            "Epoch 61/200\n",
            "19/19 [==============================] - 0s 12ms/step - loss: 0.0197\n",
            "Epoch 62/200\n",
            "19/19 [==============================] - 0s 12ms/step - loss: 0.0221\n",
            "Epoch 63/200\n",
            "19/19 [==============================] - 0s 12ms/step - loss: 0.0175\n",
            "Epoch 64/200\n",
            "19/19 [==============================] - 0s 11ms/step - loss: 0.0194\n",
            "Epoch 65/200\n",
            "19/19 [==============================] - 0s 12ms/step - loss: 0.0303\n",
            "Epoch 66/200\n",
            "19/19 [==============================] - 0s 12ms/step - loss: 0.0223\n",
            "Epoch 67/200\n",
            "19/19 [==============================] - 0s 13ms/step - loss: 0.0273\n",
            "Epoch 68/200\n",
            "19/19 [==============================] - 0s 12ms/step - loss: 0.0245\n",
            "Epoch 69/200\n",
            "19/19 [==============================] - 0s 12ms/step - loss: 0.0263\n",
            "Epoch 70/200\n",
            "19/19 [==============================] - 0s 11ms/step - loss: 0.0170\n",
            "Epoch 71/200\n",
            "19/19 [==============================] - 0s 12ms/step - loss: 0.0192\n",
            "Epoch 72/200\n",
            "19/19 [==============================] - 0s 11ms/step - loss: 0.0191\n",
            "Epoch 73/200\n",
            "19/19 [==============================] - 0s 12ms/step - loss: 0.0159\n",
            "Epoch 74/200\n",
            "19/19 [==============================] - 0s 12ms/step - loss: 0.0263\n",
            "Epoch 75/200\n",
            "19/19 [==============================] - 0s 11ms/step - loss: 0.0230\n",
            "Epoch 76/200\n",
            "19/19 [==============================] - 0s 12ms/step - loss: 0.0161\n",
            "Epoch 77/200\n",
            "19/19 [==============================] - 0s 11ms/step - loss: 0.0183\n",
            "Epoch 78/200\n",
            "19/19 [==============================] - 0s 11ms/step - loss: 0.0207\n",
            "Epoch 79/200\n",
            "19/19 [==============================] - 0s 11ms/step - loss: 0.0213\n",
            "Epoch 80/200\n",
            "19/19 [==============================] - 0s 12ms/step - loss: 0.0156\n",
            "Epoch 81/200\n",
            "19/19 [==============================] - 0s 12ms/step - loss: 0.0221\n",
            "Epoch 82/200\n",
            "19/19 [==============================] - 0s 11ms/step - loss: 0.0209\n",
            "Epoch 83/200\n",
            "19/19 [==============================] - 0s 11ms/step - loss: 0.0209\n",
            "Epoch 84/200\n",
            "19/19 [==============================] - 0s 12ms/step - loss: 0.0169\n",
            "Epoch 85/200\n",
            "19/19 [==============================] - 0s 12ms/step - loss: 0.0239\n",
            "Epoch 86/200\n",
            "19/19 [==============================] - 0s 12ms/step - loss: 0.0210\n",
            "Epoch 87/200\n",
            "19/19 [==============================] - 0s 15ms/step - loss: 0.0179\n",
            "Epoch 88/200\n",
            "19/19 [==============================] - 0s 20ms/step - loss: 0.0201\n",
            "Epoch 89/200\n",
            "19/19 [==============================] - 0s 20ms/step - loss: 0.0233\n",
            "Epoch 90/200\n",
            "19/19 [==============================] - 0s 20ms/step - loss: 0.0150\n",
            "Epoch 91/200\n",
            "19/19 [==============================] - 0s 21ms/step - loss: 0.0190\n",
            "Epoch 92/200\n",
            "19/19 [==============================] - 0s 21ms/step - loss: 0.0192\n",
            "Epoch 93/200\n",
            "19/19 [==============================] - 0s 21ms/step - loss: 0.0193\n",
            "Epoch 94/200\n",
            "19/19 [==============================] - 0s 21ms/step - loss: 0.0242\n",
            "Epoch 95/200\n",
            "19/19 [==============================] - 0s 20ms/step - loss: 0.0172\n",
            "Epoch 96/200\n",
            "19/19 [==============================] - 0s 22ms/step - loss: 0.0201\n",
            "Epoch 97/200\n",
            "19/19 [==============================] - 0s 20ms/step - loss: 0.0165\n",
            "Epoch 98/200\n",
            "19/19 [==============================] - 0s 11ms/step - loss: 0.0157\n",
            "Epoch 99/200\n",
            "19/19 [==============================] - 0s 11ms/step - loss: 0.0158\n",
            "Epoch 100/200\n",
            "19/19 [==============================] - 0s 12ms/step - loss: 0.0178\n",
            "Epoch 101/200\n",
            "19/19 [==============================] - 0s 11ms/step - loss: 0.0213\n",
            "Epoch 102/200\n",
            "19/19 [==============================] - 0s 11ms/step - loss: 0.0242\n",
            "Epoch 103/200\n",
            "19/19 [==============================] - 0s 11ms/step - loss: 0.0203\n",
            "Epoch 104/200\n",
            "19/19 [==============================] - 0s 11ms/step - loss: 0.0157\n",
            "Epoch 105/200\n",
            "19/19 [==============================] - 0s 12ms/step - loss: 0.0189\n",
            "Epoch 106/200\n",
            "19/19 [==============================] - 0s 11ms/step - loss: 0.0184\n",
            "Epoch 107/200\n",
            "19/19 [==============================] - 0s 11ms/step - loss: 0.0153\n",
            "Epoch 108/200\n",
            "19/19 [==============================] - 0s 11ms/step - loss: 0.0141\n",
            "Epoch 109/200\n",
            "19/19 [==============================] - 0s 13ms/step - loss: 0.0158\n",
            "Epoch 110/200\n",
            "19/19 [==============================] - 0s 11ms/step - loss: 0.0160\n",
            "Epoch 111/200\n",
            "19/19 [==============================] - 0s 12ms/step - loss: 0.0197\n",
            "Epoch 112/200\n",
            "19/19 [==============================] - 0s 11ms/step - loss: 0.0236\n",
            "Epoch 113/200\n",
            "19/19 [==============================] - 0s 11ms/step - loss: 0.0151\n",
            "Epoch 114/200\n",
            "19/19 [==============================] - 0s 12ms/step - loss: 0.0149\n",
            "Epoch 115/200\n",
            "19/19 [==============================] - 0s 11ms/step - loss: 0.0137\n",
            "Epoch 116/200\n",
            "19/19 [==============================] - 0s 11ms/step - loss: 0.0170\n",
            "Epoch 117/200\n",
            "19/19 [==============================] - 0s 13ms/step - loss: 0.0174\n",
            "Epoch 118/200\n",
            "19/19 [==============================] - 0s 13ms/step - loss: 0.0189\n",
            "Epoch 119/200\n",
            "19/19 [==============================] - 0s 12ms/step - loss: 0.0186\n",
            "Epoch 120/200\n",
            "19/19 [==============================] - 0s 17ms/step - loss: 0.0160\n",
            "Epoch 121/200\n",
            "19/19 [==============================] - 0s 18ms/step - loss: 0.0158\n",
            "Epoch 122/200\n",
            "19/19 [==============================] - 0s 13ms/step - loss: 0.0192\n",
            "Epoch 123/200\n",
            "19/19 [==============================] - 0s 12ms/step - loss: 0.0190\n",
            "Epoch 124/200\n",
            "19/19 [==============================] - 0s 12ms/step - loss: 0.0126\n",
            "Epoch 125/200\n",
            "19/19 [==============================] - 0s 12ms/step - loss: 0.0179\n",
            "Epoch 126/200\n",
            "19/19 [==============================] - 0s 12ms/step - loss: 0.0175\n",
            "Epoch 127/200\n",
            "19/19 [==============================] - 0s 12ms/step - loss: 0.0140\n",
            "Epoch 128/200\n",
            "19/19 [==============================] - 0s 11ms/step - loss: 0.0209\n",
            "Epoch 129/200\n",
            "19/19 [==============================] - 0s 11ms/step - loss: 0.0152\n",
            "Epoch 130/200\n",
            "19/19 [==============================] - 0s 12ms/step - loss: 0.0137\n",
            "Epoch 131/200\n",
            "19/19 [==============================] - 0s 12ms/step - loss: 0.0114\n",
            "Epoch 132/200\n",
            "19/19 [==============================] - 0s 11ms/step - loss: 0.0166\n",
            "Epoch 133/200\n",
            "19/19 [==============================] - 0s 12ms/step - loss: 0.0163\n",
            "Epoch 134/200\n",
            "19/19 [==============================] - 0s 12ms/step - loss: 0.0173\n",
            "Epoch 135/200\n",
            "19/19 [==============================] - 0s 13ms/step - loss: 0.0152\n",
            "Epoch 136/200\n",
            "19/19 [==============================] - 0s 12ms/step - loss: 0.0209\n",
            "Epoch 137/200\n",
            "19/19 [==============================] - 0s 12ms/step - loss: 0.0177\n",
            "Epoch 138/200\n",
            "19/19 [==============================] - 0s 12ms/step - loss: 0.0155\n",
            "Epoch 139/200\n",
            "19/19 [==============================] - 0s 14ms/step - loss: 0.0160\n",
            "Epoch 140/200\n",
            "19/19 [==============================] - 0s 18ms/step - loss: 0.0189\n",
            "Epoch 141/200\n",
            "19/19 [==============================] - 0s 20ms/step - loss: 0.0170\n",
            "Epoch 142/200\n",
            "19/19 [==============================] - 0s 20ms/step - loss: 0.0167\n",
            "Epoch 143/200\n",
            "19/19 [==============================] - 0s 19ms/step - loss: 0.0149\n",
            "Epoch 144/200\n",
            "19/19 [==============================] - 0s 19ms/step - loss: 0.0144\n",
            "Epoch 145/200\n",
            "19/19 [==============================] - 0s 21ms/step - loss: 0.0166\n",
            "Epoch 146/200\n",
            "19/19 [==============================] - 0s 20ms/step - loss: 0.0154\n",
            "Epoch 147/200\n",
            "19/19 [==============================] - 0s 20ms/step - loss: 0.0203\n",
            "Epoch 148/200\n",
            "19/19 [==============================] - 0s 21ms/step - loss: 0.0198\n",
            "Epoch 149/200\n",
            "19/19 [==============================] - 0s 20ms/step - loss: 0.0199\n",
            "Epoch 150/200\n",
            "19/19 [==============================] - 0s 21ms/step - loss: 0.0193\n",
            "Epoch 151/200\n",
            "19/19 [==============================] - 0s 13ms/step - loss: 0.0133\n",
            "Epoch 152/200\n",
            "19/19 [==============================] - 0s 12ms/step - loss: 0.0159\n",
            "Epoch 153/200\n",
            "19/19 [==============================] - 0s 12ms/step - loss: 0.0132\n",
            "Epoch 154/200\n",
            "19/19 [==============================] - 0s 12ms/step - loss: 0.0141\n",
            "Epoch 155/200\n",
            "19/19 [==============================] - 0s 13ms/step - loss: 0.0159\n",
            "Epoch 156/200\n",
            "19/19 [==============================] - 0s 12ms/step - loss: 0.0158\n",
            "Epoch 157/200\n",
            "19/19 [==============================] - 0s 12ms/step - loss: 0.0184\n",
            "Epoch 158/200\n",
            "19/19 [==============================] - 0s 13ms/step - loss: 0.0164\n",
            "Epoch 159/200\n",
            "19/19 [==============================] - 0s 12ms/step - loss: 0.0136\n",
            "Epoch 160/200\n",
            "19/19 [==============================] - 0s 11ms/step - loss: 0.0143\n",
            "Epoch 161/200\n",
            "19/19 [==============================] - 0s 12ms/step - loss: 0.0161\n",
            "Epoch 162/200\n",
            "19/19 [==============================] - 0s 12ms/step - loss: 0.0160\n",
            "Epoch 163/200\n",
            "19/19 [==============================] - 0s 12ms/step - loss: 0.0142\n",
            "Epoch 164/200\n",
            "19/19 [==============================] - 0s 13ms/step - loss: 0.0186\n",
            "Epoch 165/200\n",
            "19/19 [==============================] - 0s 12ms/step - loss: 0.0209\n",
            "Epoch 166/200\n",
            "19/19 [==============================] - 0s 12ms/step - loss: 0.0135\n",
            "Epoch 167/200\n",
            "19/19 [==============================] - 0s 12ms/step - loss: 0.0165\n",
            "Epoch 168/200\n",
            "19/19 [==============================] - 0s 12ms/step - loss: 0.0122\n",
            "Epoch 169/200\n",
            "19/19 [==============================] - 0s 13ms/step - loss: 0.0169\n",
            "Epoch 170/200\n",
            "19/19 [==============================] - 0s 11ms/step - loss: 0.0125\n",
            "Epoch 171/200\n",
            "19/19 [==============================] - 0s 13ms/step - loss: 0.0133\n",
            "Epoch 172/200\n",
            "19/19 [==============================] - 0s 13ms/step - loss: 0.0142\n",
            "Epoch 173/200\n",
            "19/19 [==============================] - 0s 12ms/step - loss: 0.0172\n",
            "Epoch 174/200\n",
            "19/19 [==============================] - 0s 12ms/step - loss: 0.0115\n",
            "Epoch 175/200\n",
            "19/19 [==============================] - 0s 12ms/step - loss: 0.0173\n",
            "Epoch 176/200\n",
            "19/19 [==============================] - 0s 15ms/step - loss: 0.0143\n",
            "Epoch 177/200\n",
            "19/19 [==============================] - 0s 13ms/step - loss: 0.0154\n",
            "Epoch 178/200\n",
            "19/19 [==============================] - 0s 12ms/step - loss: 0.0158\n",
            "Epoch 179/200\n",
            "19/19 [==============================] - 0s 13ms/step - loss: 0.0151\n",
            "Epoch 180/200\n",
            "19/19 [==============================] - 0s 13ms/step - loss: 0.0129\n",
            "Epoch 181/200\n",
            "19/19 [==============================] - 0s 13ms/step - loss: 0.0161\n",
            "Epoch 182/200\n",
            "19/19 [==============================] - 0s 12ms/step - loss: 0.0172\n",
            "Epoch 183/200\n",
            "19/19 [==============================] - 0s 13ms/step - loss: 0.0134\n",
            "Epoch 184/200\n",
            "19/19 [==============================] - 0s 14ms/step - loss: 0.0152\n",
            "Epoch 185/200\n",
            "19/19 [==============================] - 0s 12ms/step - loss: 0.0193\n",
            "Epoch 186/200\n",
            "19/19 [==============================] - 0s 12ms/step - loss: 0.0133\n",
            "Epoch 187/200\n",
            "19/19 [==============================] - 0s 12ms/step - loss: 0.0148\n",
            "Epoch 188/200\n",
            "19/19 [==============================] - 0s 14ms/step - loss: 0.0154\n",
            "Epoch 189/200\n",
            "19/19 [==============================] - 0s 12ms/step - loss: 0.0137\n",
            "Epoch 190/200\n",
            "19/19 [==============================] - 0s 13ms/step - loss: 0.0134\n",
            "Epoch 191/200\n",
            "19/19 [==============================] - 0s 12ms/step - loss: 0.0150\n",
            "Epoch 192/200\n",
            "19/19 [==============================] - 0s 20ms/step - loss: 0.0140\n",
            "Epoch 193/200\n",
            "19/19 [==============================] - 0s 20ms/step - loss: 0.0135\n",
            "Epoch 194/200\n",
            "19/19 [==============================] - 0s 20ms/step - loss: 0.0144\n",
            "Epoch 195/200\n",
            "19/19 [==============================] - 0s 19ms/step - loss: 0.0124\n",
            "Epoch 196/200\n",
            "19/19 [==============================] - 0s 20ms/step - loss: 0.0158\n",
            "Epoch 197/200\n",
            "19/19 [==============================] - 0s 20ms/step - loss: 0.0165\n",
            "Epoch 198/200\n",
            "19/19 [==============================] - 0s 22ms/step - loss: 0.0136\n",
            "Epoch 199/200\n",
            "19/19 [==============================] - 0s 20ms/step - loss: 0.0121\n",
            "Epoch 200/200\n",
            "19/19 [==============================] - 0s 20ms/step - loss: 0.0142\n",
            "2/2 [==============================] - 1s 9ms/step\n",
            "Predicted prices from 2024-04-01 to 2028-12-01:\n",
            "2024-04-01: 2.558\n",
            "2024-05-01: 2.641\n",
            "2024-06-01: 2.716\n",
            "2024-07-01: 2.556\n",
            "2024-08-01: 2.704\n",
            "2024-09-01: 2.622\n",
            "2024-10-01: 2.753\n",
            "2024-11-01: 2.821\n",
            "2024-12-01: 2.785\n",
            "2025-01-01: 2.990\n",
            "2025-02-01: 3.142\n",
            "2025-03-01: 3.021\n",
            "2025-04-01: 3.131\n",
            "2025-05-01: 3.309\n",
            "2025-06-01: 3.354\n",
            "2025-07-01: 3.496\n",
            "2025-08-01: 3.629\n",
            "2025-09-01: 3.487\n",
            "2025-10-01: 3.597\n",
            "2025-11-01: 3.646\n",
            "2025-12-01: 3.627\n",
            "2026-01-01: 3.734\n",
            "2026-02-01: 3.671\n",
            "2026-03-01: 3.771\n",
            "2026-04-01: 3.872\n",
            "2026-05-01: 3.882\n",
            "2026-06-01: 3.744\n",
            "2026-07-01: 3.948\n",
            "2026-08-01: 3.935\n",
            "2026-09-01: 3.924\n",
            "2026-10-01: 3.900\n",
            "2026-11-01: 3.974\n",
            "2026-12-01: 4.074\n",
            "2027-01-01: 4.077\n",
            "2027-02-01: 4.093\n",
            "2027-03-01: 4.136\n",
            "2027-04-01: 4.116\n",
            "2027-05-01: 4.083\n",
            "2027-06-01: 4.275\n",
            "2027-07-01: 4.184\n",
            "2027-08-01: 4.152\n",
            "2027-09-01: 4.143\n",
            "2027-10-01: 4.226\n",
            "2027-11-01: 4.135\n",
            "2027-12-01: 4.153\n",
            "2028-01-01: 4.157\n",
            "2028-02-01: 4.147\n",
            "2028-03-01: 4.259\n",
            "2028-04-01: 4.187\n",
            "2028-05-01: 4.217\n",
            "2028-06-01: 4.178\n",
            "2028-07-01: 4.213\n",
            "2028-08-01: 4.046\n",
            "2028-09-01: 4.206\n",
            "2028-10-01: 4.045\n",
            "2028-11-01: 4.073\n",
            "2028-12-01: 4.107\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from datetime import datetime\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import LSTM, Dense, Dropout\n",
        "\n",
        "# Read the dataset\n",
        "df = pd.read_excel('LNG (High).xlsx')\n",
        "\n",
        "# Function to calculate the number of months between two dates\n",
        "def months_between(start_date, end_date):\n",
        "    start_date = datetime.strptime(start_date, \"%Y-%m-%d\")\n",
        "    end_date = datetime.strptime(end_date, \"%Y-%m-%d\")\n",
        "    return (end_date.year - start_date.year) * 12 + end_date.month - start_date.month + 1\n",
        "\n",
        "# Define the date range\n",
        "start_date = '2024-04-01'\n",
        "end_date = '2028-12-01'\n",
        "\n",
        "# Calculate the number of months to predict\n",
        "num_months = months_between(start_date, end_date)\n",
        "\n",
        "# Ensure data is sorted by date\n",
        "df['Date'] = pd.to_datetime(df['Date'], format='%b-%y')\n",
        "df = df.sort_values(by=\"Date\", ascending=True)\n",
        "\n",
        "# Normalize the data\n",
        "scaler = MinMaxScaler(feature_range=(0, 1))\n",
        "df['Price_normalized'] = scaler.fit_transform(df['Price'].values.reshape(-1,1))\n",
        "\n",
        "# Create a new feature representing the number of months since start date\n",
        "df['Months_since_start'] = (df['Date'] - pd.to_datetime(start_date)).dt.days / 30\n",
        "\n",
        "# Prepare data for training\n",
        "X_train = df['Months_since_start'].values.reshape(-1, 1, 1)\n",
        "y_train = df['Price_normalized'].values\n",
        "\n",
        "# Define and train the LSTM model with increased dropout rate\n",
        "model = Sequential()\n",
        "model.add(LSTM(256, activation='relu', return_sequences=True, input_shape=(1, 1)))\n",
        "model.add(Dropout(0.5))  # Increase dropout rate\n",
        "model.add(LSTM(128, activation='relu', return_sequences=True))\n",
        "model.add(Dropout(0.5))  # Increase dropout rate\n",
        "model.add(LSTM(64, activation='relu'))\n",
        "model.add(Dropout(0.5))  # Increase dropout rate\n",
        "model.add(Dense(32, activation='relu'))\n",
        "model.add(Dense(1, activation='relu'))\n",
        "model.compile(optimizer='adam', loss='mean_squared_error')\n",
        "model.fit(X_train, y_train, epochs=200, batch_size=8)\n",
        "\n",
        "# Generate future indices for prediction\n",
        "X_future = np.arange(df['Months_since_start'].iloc[-1] + 1, df['Months_since_start'].iloc[-1] + 1 + num_months)\n",
        "X_future = X_future.reshape(-1, 1, 1)  # Reshape for LSTM input\n",
        "\n",
        "# Generate predictions\n",
        "y_pred_normalized = model.predict(X_future)\n",
        "\n",
        "# Inverse transform predictions to get actual prices\n",
        "y_pred = scaler.inverse_transform(y_pred_normalized)\n",
        "\n",
        "# Add random noise to introduce variability\n",
        "noise = np.random.normal(0, 0.05, y_pred.shape)  # Adjust the scale of the noise as needed\n",
        "y_pred += noise\n",
        "\n",
        "# Ensure predictions are non-negative\n",
        "y_pred = np.maximum(y_pred, 0)\n",
        "\n",
        "# Generate date range for the predictions\n",
        "dates = pd.date_range(start=start_date, periods=num_months, freq='MS')\n",
        "\n",
        "# Print predicted prices with corresponding dates\n",
        "print(\"Predicted prices from 2024-04-01 to 2028-12-01:\")\n",
        "for date, pred in zip(dates, y_pred.flatten()):\n",
        "    print(f\"{date.strftime('%Y-%m-%d')}: {pred:.3f}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0scCGhBoAAG1",
        "outputId": "9b358d87-62d4-4961-b67c-5b8d964c5ea8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/200\n",
            "19/19 [==============================] - 9s 12ms/step - loss: 0.0715\n",
            "Epoch 2/200\n",
            "19/19 [==============================] - 0s 13ms/step - loss: 0.0492\n",
            "Epoch 3/200\n",
            "19/19 [==============================] - 0s 13ms/step - loss: 0.0425\n",
            "Epoch 4/200\n",
            "19/19 [==============================] - 0s 13ms/step - loss: 0.0408\n",
            "Epoch 5/200\n",
            "19/19 [==============================] - 0s 14ms/step - loss: 0.0371\n",
            "Epoch 6/200\n",
            "19/19 [==============================] - 0s 13ms/step - loss: 0.0376\n",
            "Epoch 7/200\n",
            "19/19 [==============================] - 0s 12ms/step - loss: 0.0390\n",
            "Epoch 8/200\n",
            "19/19 [==============================] - 0s 11ms/step - loss: 0.0371\n",
            "Epoch 9/200\n",
            "19/19 [==============================] - 0s 11ms/step - loss: 0.0360\n",
            "Epoch 10/200\n",
            "19/19 [==============================] - 0s 12ms/step - loss: 0.0369\n",
            "Epoch 11/200\n",
            "19/19 [==============================] - 0s 11ms/step - loss: 0.0341\n",
            "Epoch 12/200\n",
            "19/19 [==============================] - 0s 13ms/step - loss: 0.0352\n",
            "Epoch 13/200\n",
            "19/19 [==============================] - 0s 11ms/step - loss: 0.0356\n",
            "Epoch 14/200\n",
            "19/19 [==============================] - 0s 11ms/step - loss: 0.0304\n",
            "Epoch 15/200\n",
            "19/19 [==============================] - 0s 12ms/step - loss: 0.0331\n",
            "Epoch 16/200\n",
            "19/19 [==============================] - 0s 11ms/step - loss: 0.0288\n",
            "Epoch 17/200\n",
            "19/19 [==============================] - 0s 11ms/step - loss: 0.0325\n",
            "Epoch 18/200\n",
            "19/19 [==============================] - 0s 11ms/step - loss: 0.0300\n",
            "Epoch 19/200\n",
            "19/19 [==============================] - 0s 12ms/step - loss: 0.0329\n",
            "Epoch 20/200\n",
            "19/19 [==============================] - 0s 12ms/step - loss: 0.0336\n",
            "Epoch 21/200\n",
            "19/19 [==============================] - 0s 11ms/step - loss: 0.0296\n",
            "Epoch 22/200\n",
            "19/19 [==============================] - 0s 12ms/step - loss: 0.0249\n",
            "Epoch 23/200\n",
            "19/19 [==============================] - 1s 26ms/step - loss: 0.0281\n",
            "Epoch 24/200\n",
            "19/19 [==============================] - 0s 25ms/step - loss: 0.0251\n",
            "Epoch 25/200\n",
            "19/19 [==============================] - 0s 20ms/step - loss: 0.0275\n",
            "Epoch 26/200\n",
            "19/19 [==============================] - 0s 20ms/step - loss: 0.0239\n",
            "Epoch 27/200\n",
            "19/19 [==============================] - 0s 20ms/step - loss: 0.0288\n",
            "Epoch 28/200\n",
            "19/19 [==============================] - 0s 20ms/step - loss: 0.0298\n",
            "Epoch 29/200\n",
            "19/19 [==============================] - 0s 21ms/step - loss: 0.0236\n",
            "Epoch 30/200\n",
            "19/19 [==============================] - 0s 21ms/step - loss: 0.0253\n",
            "Epoch 31/200\n",
            "19/19 [==============================] - 0s 22ms/step - loss: 0.0291\n",
            "Epoch 32/200\n",
            "19/19 [==============================] - 0s 17ms/step - loss: 0.0244\n",
            "Epoch 33/200\n",
            "19/19 [==============================] - 0s 12ms/step - loss: 0.0229\n",
            "Epoch 34/200\n",
            "19/19 [==============================] - 0s 11ms/step - loss: 0.0244\n",
            "Epoch 35/200\n",
            "19/19 [==============================] - 0s 12ms/step - loss: 0.0214\n",
            "Epoch 36/200\n",
            "19/19 [==============================] - 0s 12ms/step - loss: 0.0283\n",
            "Epoch 37/200\n",
            "19/19 [==============================] - 0s 12ms/step - loss: 0.0224\n",
            "Epoch 38/200\n",
            "19/19 [==============================] - 0s 12ms/step - loss: 0.0270\n",
            "Epoch 39/200\n",
            "19/19 [==============================] - 0s 13ms/step - loss: 0.0225\n",
            "Epoch 40/200\n",
            "19/19 [==============================] - 0s 12ms/step - loss: 0.0232\n",
            "Epoch 41/200\n",
            "19/19 [==============================] - 0s 12ms/step - loss: 0.0291\n",
            "Epoch 42/200\n",
            "19/19 [==============================] - 0s 12ms/step - loss: 0.0292\n",
            "Epoch 43/200\n",
            "19/19 [==============================] - 0s 12ms/step - loss: 0.0253\n",
            "Epoch 44/200\n",
            "19/19 [==============================] - 0s 12ms/step - loss: 0.0277\n",
            "Epoch 45/200\n",
            "19/19 [==============================] - 0s 12ms/step - loss: 0.0265\n",
            "Epoch 46/200\n",
            "19/19 [==============================] - 0s 12ms/step - loss: 0.0307\n",
            "Epoch 47/200\n",
            "19/19 [==============================] - 0s 11ms/step - loss: 0.0244\n",
            "Epoch 48/200\n",
            "19/19 [==============================] - 0s 13ms/step - loss: 0.0266\n",
            "Epoch 49/200\n",
            "19/19 [==============================] - 0s 12ms/step - loss: 0.0268\n",
            "Epoch 50/200\n",
            "19/19 [==============================] - 0s 12ms/step - loss: 0.0261\n",
            "Epoch 51/200\n",
            "19/19 [==============================] - 0s 12ms/step - loss: 0.0204\n",
            "Epoch 52/200\n",
            "19/19 [==============================] - 0s 13ms/step - loss: 0.0240\n",
            "Epoch 53/200\n",
            "19/19 [==============================] - 0s 11ms/step - loss: 0.0220\n",
            "Epoch 54/200\n",
            "19/19 [==============================] - 0s 11ms/step - loss: 0.0311\n",
            "Epoch 55/200\n",
            "19/19 [==============================] - 0s 11ms/step - loss: 0.0283\n",
            "Epoch 56/200\n",
            "19/19 [==============================] - 0s 12ms/step - loss: 0.0284\n",
            "Epoch 57/200\n",
            "19/19 [==============================] - 0s 12ms/step - loss: 0.0271\n",
            "Epoch 58/200\n",
            "19/19 [==============================] - 0s 11ms/step - loss: 0.0253\n",
            "Epoch 59/200\n",
            "19/19 [==============================] - 0s 12ms/step - loss: 0.0266\n",
            "Epoch 60/200\n",
            "19/19 [==============================] - 0s 13ms/step - loss: 0.0201\n",
            "Epoch 61/200\n",
            "19/19 [==============================] - 0s 12ms/step - loss: 0.0203\n",
            "Epoch 62/200\n",
            "19/19 [==============================] - 0s 12ms/step - loss: 0.0234\n",
            "Epoch 63/200\n",
            "19/19 [==============================] - 0s 11ms/step - loss: 0.0267\n",
            "Epoch 64/200\n",
            "19/19 [==============================] - 0s 12ms/step - loss: 0.0278\n",
            "Epoch 65/200\n",
            "19/19 [==============================] - 0s 13ms/step - loss: 0.0253\n",
            "Epoch 66/200\n",
            "19/19 [==============================] - 0s 12ms/step - loss: 0.0287\n",
            "Epoch 67/200\n",
            "19/19 [==============================] - 0s 11ms/step - loss: 0.0228\n",
            "Epoch 68/200\n",
            "19/19 [==============================] - 0s 12ms/step - loss: 0.0230\n",
            "Epoch 69/200\n",
            "19/19 [==============================] - 0s 11ms/step - loss: 0.0242\n",
            "Epoch 70/200\n",
            "19/19 [==============================] - 0s 12ms/step - loss: 0.0193\n",
            "Epoch 71/200\n",
            "19/19 [==============================] - 0s 12ms/step - loss: 0.0192\n",
            "Epoch 72/200\n",
            "19/19 [==============================] - 0s 12ms/step - loss: 0.0175\n",
            "Epoch 73/200\n",
            "19/19 [==============================] - 0s 12ms/step - loss: 0.0234\n",
            "Epoch 74/200\n",
            "19/19 [==============================] - 0s 12ms/step - loss: 0.0212\n",
            "Epoch 75/200\n",
            "19/19 [==============================] - 0s 16ms/step - loss: 0.0215\n",
            "Epoch 76/200\n",
            "19/19 [==============================] - 0s 21ms/step - loss: 0.0268\n",
            "Epoch 77/200\n",
            "19/19 [==============================] - 0s 21ms/step - loss: 0.0249\n",
            "Epoch 78/200\n",
            "19/19 [==============================] - 0s 20ms/step - loss: 0.0249\n",
            "Epoch 79/200\n",
            "19/19 [==============================] - 0s 21ms/step - loss: 0.0192\n",
            "Epoch 80/200\n",
            "19/19 [==============================] - 0s 22ms/step - loss: 0.0232\n",
            "Epoch 81/200\n",
            "19/19 [==============================] - 0s 22ms/step - loss: 0.0242\n",
            "Epoch 82/200\n",
            "19/19 [==============================] - 0s 21ms/step - loss: 0.0201\n",
            "Epoch 83/200\n",
            "19/19 [==============================] - 0s 21ms/step - loss: 0.0181\n",
            "Epoch 84/200\n",
            "19/19 [==============================] - 0s 21ms/step - loss: 0.0197\n",
            "Epoch 85/200\n",
            "19/19 [==============================] - 0s 18ms/step - loss: 0.0190\n",
            "Epoch 86/200\n",
            "19/19 [==============================] - 0s 12ms/step - loss: 0.0203\n",
            "Epoch 87/200\n",
            "19/19 [==============================] - 0s 12ms/step - loss: 0.0196\n",
            "Epoch 88/200\n",
            "19/19 [==============================] - 0s 12ms/step - loss: 0.0233\n",
            "Epoch 89/200\n",
            "19/19 [==============================] - 0s 12ms/step - loss: 0.0212\n",
            "Epoch 90/200\n",
            "19/19 [==============================] - 0s 12ms/step - loss: 0.0213\n",
            "Epoch 91/200\n",
            "19/19 [==============================] - 0s 12ms/step - loss: 0.0200\n",
            "Epoch 92/200\n",
            "19/19 [==============================] - 0s 11ms/step - loss: 0.0224\n",
            "Epoch 93/200\n",
            "19/19 [==============================] - 0s 12ms/step - loss: 0.0193\n",
            "Epoch 94/200\n",
            "19/19 [==============================] - 0s 12ms/step - loss: 0.0199\n",
            "Epoch 95/200\n",
            "19/19 [==============================] - 0s 12ms/step - loss: 0.0176\n",
            "Epoch 96/200\n",
            "19/19 [==============================] - 0s 12ms/step - loss: 0.0151\n",
            "Epoch 97/200\n",
            "19/19 [==============================] - 0s 11ms/step - loss: 0.0207\n",
            "Epoch 98/200\n",
            "19/19 [==============================] - 0s 12ms/step - loss: 0.0156\n",
            "Epoch 99/200\n",
            "19/19 [==============================] - 0s 11ms/step - loss: 0.0204\n",
            "Epoch 100/200\n",
            "19/19 [==============================] - 0s 11ms/step - loss: 0.0224\n",
            "Epoch 101/200\n",
            "19/19 [==============================] - 0s 12ms/step - loss: 0.0343\n",
            "Epoch 102/200\n",
            "19/19 [==============================] - 0s 11ms/step - loss: 0.0207\n",
            "Epoch 103/200\n",
            "19/19 [==============================] - 0s 12ms/step - loss: 0.0209\n",
            "Epoch 104/200\n",
            "19/19 [==============================] - 0s 11ms/step - loss: 0.0194\n",
            "Epoch 105/200\n",
            "19/19 [==============================] - 0s 12ms/step - loss: 0.0179\n",
            "Epoch 106/200\n",
            "19/19 [==============================] - 0s 11ms/step - loss: 0.0143\n",
            "Epoch 107/200\n",
            "19/19 [==============================] - 0s 12ms/step - loss: 0.0184\n",
            "Epoch 108/200\n",
            "19/19 [==============================] - 0s 12ms/step - loss: 0.0174\n",
            "Epoch 109/200\n",
            "19/19 [==============================] - 0s 12ms/step - loss: 0.0158\n",
            "Epoch 110/200\n",
            "19/19 [==============================] - 0s 11ms/step - loss: 0.0197\n",
            "Epoch 111/200\n",
            "19/19 [==============================] - 0s 11ms/step - loss: 0.0168\n",
            "Epoch 112/200\n",
            "19/19 [==============================] - 0s 12ms/step - loss: 0.0192\n",
            "Epoch 113/200\n",
            "19/19 [==============================] - 0s 12ms/step - loss: 0.0169\n",
            "Epoch 114/200\n",
            "19/19 [==============================] - 0s 11ms/step - loss: 0.0144\n",
            "Epoch 115/200\n",
            "19/19 [==============================] - 0s 12ms/step - loss: 0.0147\n",
            "Epoch 116/200\n",
            "19/19 [==============================] - 0s 13ms/step - loss: 0.0168\n",
            "Epoch 117/200\n",
            "19/19 [==============================] - 0s 12ms/step - loss: 0.0168\n",
            "Epoch 118/200\n",
            "19/19 [==============================] - 0s 12ms/step - loss: 0.0183\n",
            "Epoch 119/200\n",
            "19/19 [==============================] - 0s 12ms/step - loss: 0.0183\n",
            "Epoch 120/200\n",
            "19/19 [==============================] - 0s 12ms/step - loss: 0.0248\n",
            "Epoch 121/200\n",
            "19/19 [==============================] - 0s 12ms/step - loss: 0.0164\n",
            "Epoch 122/200\n",
            "19/19 [==============================] - 0s 12ms/step - loss: 0.0169\n",
            "Epoch 123/200\n",
            "19/19 [==============================] - 0s 12ms/step - loss: 0.0161\n",
            "Epoch 124/200\n",
            "19/19 [==============================] - 0s 12ms/step - loss: 0.0187\n",
            "Epoch 125/200\n",
            "19/19 [==============================] - 0s 13ms/step - loss: 0.0140\n",
            "Epoch 126/200\n",
            "19/19 [==============================] - 0s 13ms/step - loss: 0.0139\n",
            "Epoch 127/200\n",
            "19/19 [==============================] - 0s 14ms/step - loss: 0.0158\n",
            "Epoch 128/200\n",
            "19/19 [==============================] - 0s 16ms/step - loss: 0.0192\n",
            "Epoch 129/200\n",
            "19/19 [==============================] - 0s 21ms/step - loss: 0.0164\n",
            "Epoch 130/200\n",
            "19/19 [==============================] - 0s 18ms/step - loss: 0.0175\n",
            "Epoch 131/200\n",
            "19/19 [==============================] - 0s 20ms/step - loss: 0.0113\n",
            "Epoch 132/200\n",
            "19/19 [==============================] - 0s 21ms/step - loss: 0.0122\n",
            "Epoch 133/200\n",
            "19/19 [==============================] - 0s 21ms/step - loss: 0.0200\n",
            "Epoch 134/200\n",
            "19/19 [==============================] - 0s 22ms/step - loss: 0.0180\n",
            "Epoch 135/200\n",
            "19/19 [==============================] - 0s 21ms/step - loss: 0.0155\n",
            "Epoch 136/200\n",
            "19/19 [==============================] - 0s 21ms/step - loss: 0.0163\n",
            "Epoch 137/200\n",
            "19/19 [==============================] - 0s 21ms/step - loss: 0.0120\n",
            "Epoch 138/200\n",
            "19/19 [==============================] - 0s 20ms/step - loss: 0.0158\n",
            "Epoch 139/200\n",
            "19/19 [==============================] - 0s 12ms/step - loss: 0.0133\n",
            "Epoch 140/200\n",
            "19/19 [==============================] - 0s 13ms/step - loss: 0.0151\n",
            "Epoch 141/200\n",
            "19/19 [==============================] - 0s 12ms/step - loss: 0.0125\n",
            "Epoch 142/200\n",
            "19/19 [==============================] - 0s 12ms/step - loss: 0.0182\n",
            "Epoch 143/200\n",
            "19/19 [==============================] - 0s 12ms/step - loss: 0.0184\n",
            "Epoch 144/200\n",
            "19/19 [==============================] - 0s 12ms/step - loss: 0.0159\n",
            "Epoch 145/200\n",
            "19/19 [==============================] - 0s 12ms/step - loss: 0.0177\n",
            "Epoch 146/200\n",
            "19/19 [==============================] - 0s 11ms/step - loss: 0.0157\n",
            "Epoch 147/200\n",
            "19/19 [==============================] - 0s 11ms/step - loss: 0.0139\n",
            "Epoch 148/200\n",
            "19/19 [==============================] - 0s 12ms/step - loss: 0.0180\n",
            "Epoch 149/200\n",
            "19/19 [==============================] - 0s 12ms/step - loss: 0.0133\n",
            "Epoch 150/200\n",
            "19/19 [==============================] - 0s 11ms/step - loss: 0.0165\n",
            "Epoch 151/200\n",
            "19/19 [==============================] - 0s 11ms/step - loss: 0.0184\n",
            "Epoch 152/200\n",
            "19/19 [==============================] - 0s 12ms/step - loss: 0.0130\n",
            "Epoch 153/200\n",
            "19/19 [==============================] - 0s 12ms/step - loss: 0.0173\n",
            "Epoch 154/200\n",
            "19/19 [==============================] - 0s 12ms/step - loss: 0.0148\n",
            "Epoch 155/200\n",
            "19/19 [==============================] - 0s 12ms/step - loss: 0.0153\n",
            "Epoch 156/200\n",
            "19/19 [==============================] - 0s 12ms/step - loss: 0.0160\n",
            "Epoch 157/200\n",
            "19/19 [==============================] - 0s 12ms/step - loss: 0.0178\n",
            "Epoch 158/200\n",
            "19/19 [==============================] - 0s 13ms/step - loss: 0.0182\n",
            "Epoch 159/200\n",
            "19/19 [==============================] - 0s 12ms/step - loss: 0.0110\n",
            "Epoch 160/200\n",
            "19/19 [==============================] - 0s 12ms/step - loss: 0.0165\n",
            "Epoch 161/200\n",
            "19/19 [==============================] - 0s 12ms/step - loss: 0.0151\n",
            "Epoch 162/200\n",
            "19/19 [==============================] - 0s 12ms/step - loss: 0.0197\n",
            "Epoch 163/200\n",
            "19/19 [==============================] - 0s 12ms/step - loss: 0.0168\n",
            "Epoch 164/200\n",
            "19/19 [==============================] - 0s 12ms/step - loss: 0.0155\n",
            "Epoch 165/200\n",
            "19/19 [==============================] - 0s 13ms/step - loss: 0.0132\n",
            "Epoch 166/200\n",
            "19/19 [==============================] - 0s 12ms/step - loss: 0.0147\n",
            "Epoch 167/200\n",
            "19/19 [==============================] - 0s 14ms/step - loss: 0.0147\n",
            "Epoch 168/200\n",
            "19/19 [==============================] - 0s 12ms/step - loss: 0.0163\n",
            "Epoch 169/200\n",
            "19/19 [==============================] - 0s 12ms/step - loss: 0.0165\n",
            "Epoch 170/200\n",
            "19/19 [==============================] - 0s 12ms/step - loss: 0.0176\n",
            "Epoch 171/200\n",
            "19/19 [==============================] - 0s 13ms/step - loss: 0.0151\n",
            "Epoch 172/200\n",
            "19/19 [==============================] - 0s 12ms/step - loss: 0.0194\n",
            "Epoch 173/200\n",
            "19/19 [==============================] - 0s 12ms/step - loss: 0.0145\n",
            "Epoch 174/200\n",
            "19/19 [==============================] - 0s 13ms/step - loss: 0.0153\n",
            "Epoch 175/200\n",
            "19/19 [==============================] - 0s 14ms/step - loss: 0.0134\n",
            "Epoch 176/200\n",
            "19/19 [==============================] - 0s 12ms/step - loss: 0.0125\n",
            "Epoch 177/200\n",
            "19/19 [==============================] - 0s 12ms/step - loss: 0.0174\n",
            "Epoch 178/200\n",
            "19/19 [==============================] - 0s 12ms/step - loss: 0.0132\n",
            "Epoch 179/200\n",
            "19/19 [==============================] - 0s 12ms/step - loss: 0.0113\n",
            "Epoch 180/200\n",
            "19/19 [==============================] - 0s 12ms/step - loss: 0.0145\n",
            "Epoch 181/200\n",
            "19/19 [==============================] - 0s 21ms/step - loss: 0.0175\n",
            "Epoch 182/200\n",
            "19/19 [==============================] - 0s 21ms/step - loss: 0.0154\n",
            "Epoch 183/200\n",
            "19/19 [==============================] - 0s 21ms/step - loss: 0.0131\n",
            "Epoch 184/200\n",
            "19/19 [==============================] - 0s 20ms/step - loss: 0.0119\n",
            "Epoch 185/200\n",
            "19/19 [==============================] - 0s 21ms/step - loss: 0.0144\n",
            "Epoch 186/200\n",
            "19/19 [==============================] - 0s 21ms/step - loss: 0.0142\n",
            "Epoch 187/200\n",
            "19/19 [==============================] - 0s 21ms/step - loss: 0.0158\n",
            "Epoch 188/200\n",
            "19/19 [==============================] - 0s 21ms/step - loss: 0.0152\n",
            "Epoch 189/200\n",
            "19/19 [==============================] - 0s 20ms/step - loss: 0.0132\n",
            "Epoch 190/200\n",
            "19/19 [==============================] - 0s 20ms/step - loss: 0.0123\n",
            "Epoch 191/200\n",
            "19/19 [==============================] - 0s 20ms/step - loss: 0.0148\n",
            "Epoch 192/200\n",
            "19/19 [==============================] - 0s 12ms/step - loss: 0.0122\n",
            "Epoch 193/200\n",
            "19/19 [==============================] - 0s 12ms/step - loss: 0.0140\n",
            "Epoch 194/200\n",
            "19/19 [==============================] - 0s 12ms/step - loss: 0.0128\n",
            "Epoch 195/200\n",
            "19/19 [==============================] - 0s 12ms/step - loss: 0.0128\n",
            "Epoch 196/200\n",
            "19/19 [==============================] - 0s 12ms/step - loss: 0.0154\n",
            "Epoch 197/200\n",
            "19/19 [==============================] - 0s 12ms/step - loss: 0.0133\n",
            "Epoch 198/200\n",
            "19/19 [==============================] - 0s 12ms/step - loss: 0.0177\n",
            "Epoch 199/200\n",
            "19/19 [==============================] - 0s 13ms/step - loss: 0.0169\n",
            "Epoch 200/200\n",
            "19/19 [==============================] - 0s 12ms/step - loss: 0.0129\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Predicted prices from 2024-04-01 to 2028-12-01:\n",
            "2024-04-01: 2.544 (Lower Bound: 2.532, Upper Bound: 2.555)\n",
            "2024-05-01: 2.561 (Lower Bound: 2.549, Upper Bound: 2.572)\n",
            "2024-06-01: 2.568 (Lower Bound: 2.556, Upper Bound: 2.580)\n",
            "2024-07-01: 2.573 (Lower Bound: 2.562, Upper Bound: 2.585)\n",
            "2024-08-01: 2.578 (Lower Bound: 2.566, Upper Bound: 2.590)\n",
            "2024-09-01: 2.577 (Lower Bound: 2.565, Upper Bound: 2.588)\n",
            "2024-10-01: 2.574 (Lower Bound: 2.562, Upper Bound: 2.586)\n",
            "2024-11-01: 2.571 (Lower Bound: 2.559, Upper Bound: 2.582)\n",
            "2024-12-01: 2.566 (Lower Bound: 2.555, Upper Bound: 2.578)\n",
            "2025-01-01: 2.566 (Lower Bound: 2.554, Upper Bound: 2.578)\n",
            "2025-02-01: 2.565 (Lower Bound: 2.554, Upper Bound: 2.577)\n",
            "2025-03-01: 2.565 (Lower Bound: 2.553, Upper Bound: 2.576)\n",
            "2025-04-01: 2.564 (Lower Bound: 2.552, Upper Bound: 2.576)\n",
            "2025-05-01: 2.564 (Lower Bound: 2.552, Upper Bound: 2.575)\n",
            "2025-06-01: 2.563 (Lower Bound: 2.551, Upper Bound: 2.574)\n",
            "2025-07-01: 2.562 (Lower Bound: 2.551, Upper Bound: 2.574)\n",
            "2025-08-01: 2.561 (Lower Bound: 2.550, Upper Bound: 2.573)\n",
            "2025-09-01: 2.561 (Lower Bound: 2.549, Upper Bound: 2.572)\n",
            "2025-10-01: 2.560 (Lower Bound: 2.548, Upper Bound: 2.572)\n",
            "2025-11-01: 2.562 (Lower Bound: 2.550, Upper Bound: 2.573)\n",
            "2025-12-01: 2.568 (Lower Bound: 2.556, Upper Bound: 2.580)\n",
            "2026-01-01: 2.575 (Lower Bound: 2.563, Upper Bound: 2.586)\n",
            "2026-02-01: 2.581 (Lower Bound: 2.570, Upper Bound: 2.593)\n",
            "2026-03-01: 2.588 (Lower Bound: 2.576, Upper Bound: 2.600)\n",
            "2026-04-01: 2.595 (Lower Bound: 2.583, Upper Bound: 2.607)\n",
            "2026-05-01: 2.602 (Lower Bound: 2.590, Upper Bound: 2.614)\n",
            "2026-06-01: 2.609 (Lower Bound: 2.598, Upper Bound: 2.621)\n",
            "2026-07-01: 2.617 (Lower Bound: 2.605, Upper Bound: 2.628)\n",
            "2026-08-01: 2.624 (Lower Bound: 2.612, Upper Bound: 2.636)\n",
            "2026-09-01: 2.631 (Lower Bound: 2.620, Upper Bound: 2.643)\n",
            "2026-10-01: 2.639 (Lower Bound: 2.627, Upper Bound: 2.650)\n",
            "2026-11-01: 2.647 (Lower Bound: 2.635, Upper Bound: 2.658)\n",
            "2026-12-01: 2.654 (Lower Bound: 2.643, Upper Bound: 2.666)\n",
            "2027-01-01: 2.662 (Lower Bound: 2.651, Upper Bound: 2.674)\n",
            "2027-02-01: 2.670 (Lower Bound: 2.658, Upper Bound: 2.682)\n",
            "2027-03-01: 2.678 (Lower Bound: 2.666, Upper Bound: 2.689)\n",
            "2027-04-01: 2.682 (Lower Bound: 2.671, Upper Bound: 2.694)\n",
            "2027-05-01: 2.687 (Lower Bound: 2.675, Upper Bound: 2.699)\n",
            "2027-06-01: 2.691 (Lower Bound: 2.680, Upper Bound: 2.703)\n",
            "2027-07-01: 2.696 (Lower Bound: 2.684, Upper Bound: 2.708)\n",
            "2027-08-01: 2.701 (Lower Bound: 2.689, Upper Bound: 2.712)\n",
            "2027-09-01: 2.705 (Lower Bound: 2.694, Upper Bound: 2.717)\n",
            "2027-10-01: 2.710 (Lower Bound: 2.698, Upper Bound: 2.721)\n",
            "2027-11-01: 2.714 (Lower Bound: 2.703, Upper Bound: 2.726)\n",
            "2027-12-01: 2.719 (Lower Bound: 2.707, Upper Bound: 2.731)\n",
            "2028-01-01: 2.724 (Lower Bound: 2.712, Upper Bound: 2.735)\n",
            "2028-02-01: 2.728 (Lower Bound: 2.717, Upper Bound: 2.740)\n",
            "2028-03-01: 2.733 (Lower Bound: 2.721, Upper Bound: 2.745)\n",
            "2028-04-01: 2.738 (Lower Bound: 2.726, Upper Bound: 2.749)\n",
            "2028-05-01: 2.742 (Lower Bound: 2.731, Upper Bound: 2.754)\n",
            "2028-06-01: 2.747 (Lower Bound: 2.735, Upper Bound: 2.759)\n",
            "2028-07-01: 2.752 (Lower Bound: 2.740, Upper Bound: 2.763)\n",
            "2028-08-01: 2.756 (Lower Bound: 2.744, Upper Bound: 2.768)\n",
            "2028-09-01: 2.761 (Lower Bound: 2.749, Upper Bound: 2.772)\n",
            "2028-10-01: 2.765 (Lower Bound: 2.753, Upper Bound: 2.777)\n",
            "2028-11-01: 2.766 (Lower Bound: 2.754, Upper Bound: 2.778)\n",
            "2028-12-01: 2.766 (Lower Bound: 2.754, Upper Bound: 2.778)\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from datetime import datetime\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import LSTM, Dense, Dropout\n",
        "\n",
        "# Read the dataset\n",
        "df = pd.read_excel('LNG (High).xlsx')\n",
        "\n",
        "# Function to calculate the number of months between two dates\n",
        "def months_between(start_date, end_date):\n",
        "    start_date = datetime.strptime(start_date, \"%Y-%m-%d\")\n",
        "    end_date = datetime.strptime(end_date, \"%Y-%m-%d\")\n",
        "    return (end_date.year - start_date.year) * 12 + end_date.month - start_date.month + 1\n",
        "\n",
        "# Define the date range\n",
        "start_date = '2024-04-01'\n",
        "end_date = '2028-12-01'\n",
        "\n",
        "# Calculate the number of months to predict\n",
        "num_months = months_between(start_date, end_date)\n",
        "\n",
        "# Ensure data is sorted by date\n",
        "df['Date'] = pd.to_datetime(df['Date'], format='%b-%y')\n",
        "df = df.sort_values(by=\"Date\", ascending=True)\n",
        "\n",
        "# Normalize the data\n",
        "scaler = MinMaxScaler(feature_range=(0, 1))\n",
        "df['Price_normalized'] = scaler.fit_transform(df['Price'].values.reshape(-1,1))\n",
        "\n",
        "# Create a new feature representing the number of months since start date\n",
        "df['Months_since_start'] = (df['Date'] - pd.to_datetime(start_date)).dt.days / 30\n",
        "\n",
        "# Prepare data for training\n",
        "X_train = df['Months_since_start'].values.reshape(-1, 1, 1)\n",
        "y_train = df['Price_normalized'].values\n",
        "\n",
        "# Define and train the LSTM model with increased dropout rate\n",
        "model = Sequential()\n",
        "model.add(LSTM(256, activation='relu', return_sequences=True, input_shape=(1, 1)))\n",
        "model.add(Dropout(0.5))  # Increase dropout rate\n",
        "model.add(LSTM(128, activation='relu', return_sequences=True))\n",
        "model.add(Dropout(0.5))  # Increase dropout rate\n",
        "model.add(LSTM(64, activation='relu'))\n",
        "model.add(Dropout(0.5))  # Increase dropout rate\n",
        "model.add(Dense(32, activation='relu'))\n",
        "model.add(Dense(1, activation='relu'))\n",
        "model.compile(optimizer='adam', loss='mean_squared_error')\n",
        "model.fit(X_train, y_train, epochs=200, batch_size=8)\n",
        "\n",
        "# Generate future indices for prediction\n",
        "X_future = np.arange(df['Months_since_start'].iloc[-1] + 1, df['Months_since_start'].iloc[-1] + 1 + num_months)\n",
        "X_future = X_future.reshape(-1, 1, 1)  # Reshape for LSTM input\n",
        "\n",
        "# Generate predictions\n",
        "y_pred_normalized = model.predict(X_future)\n",
        "\n",
        "# Inverse transform predictions to get actual prices\n",
        "y_pred = scaler.inverse_transform(y_pred_normalized)\n",
        "\n",
        "# Ensure predictions are non-negative\n",
        "y_pred = np.maximum(y_pred, 0)\n",
        "\n",
        "# Compute confidence interval bounds\n",
        "confidence_level = 0.80  # Set confidence level\n",
        "std_dev = np.std(y_pred_normalized)  # Compute standard deviation\n",
        "margin_of_error = std_dev * 1.28  # 1.28 is the z-score for 80% confidence interval\n",
        "lower_bound = y_pred - margin_of_error\n",
        "upper_bound = y_pred + margin_of_error\n",
        "\n",
        "# Generate date range for the predictions\n",
        "dates = pd.date_range(start=start_date, periods=num_months, freq='MS')\n",
        "\n",
        "# Print predicted prices with corresponding dates and confidence intervals\n",
        "print(\"Predicted prices from 2024-04-01 to 2028-12-01:\")\n",
        "for date, pred, lower, upper in zip(dates, y_pred.flatten(), lower_bound.flatten(), upper_bound.flatten()):\n",
        "    print(f\"{date.strftime('%Y-%m-%d')}: {pred:.3f} (Lower Bound: {lower:.3f}, Upper Bound: {upper:.3f})\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RL441RVFCLHF",
        "outputId": "b773daae-d33d-41a7-cf7b-dda3da6dc68a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/200\n",
            "19/19 [==============================] - 7s 22ms/step - loss: 0.0732\n",
            "Epoch 2/200\n",
            "19/19 [==============================] - 0s 21ms/step - loss: 0.0511\n",
            "Epoch 3/200\n",
            "19/19 [==============================] - 0s 23ms/step - loss: 0.0456\n",
            "Epoch 4/200\n",
            "19/19 [==============================] - 1s 32ms/step - loss: 0.0388\n",
            "Epoch 5/200\n",
            "19/19 [==============================] - 0s 26ms/step - loss: 0.0372\n",
            "Epoch 6/200\n",
            "19/19 [==============================] - 0s 23ms/step - loss: 0.0337\n",
            "Epoch 7/200\n",
            "19/19 [==============================] - 0s 23ms/step - loss: 0.0333\n",
            "Epoch 8/200\n",
            "19/19 [==============================] - 0s 26ms/step - loss: 0.0310\n",
            "Epoch 9/200\n",
            "19/19 [==============================] - 1s 29ms/step - loss: 0.0323\n",
            "Epoch 10/200\n",
            "19/19 [==============================] - 1s 26ms/step - loss: 0.0315\n",
            "Epoch 11/200\n",
            "19/19 [==============================] - 1s 28ms/step - loss: 0.0309\n",
            "Epoch 12/200\n",
            "19/19 [==============================] - 0s 23ms/step - loss: 0.0294\n",
            "Epoch 13/200\n",
            "19/19 [==============================] - 0s 22ms/step - loss: 0.0254\n",
            "Epoch 14/200\n",
            "19/19 [==============================] - 0s 21ms/step - loss: 0.0272\n",
            "Epoch 15/200\n",
            "19/19 [==============================] - 0s 23ms/step - loss: 0.0311\n",
            "Epoch 16/200\n",
            "19/19 [==============================] - 0s 22ms/step - loss: 0.0265\n",
            "Epoch 17/200\n",
            "19/19 [==============================] - 0s 13ms/step - loss: 0.0276\n",
            "Epoch 18/200\n",
            "19/19 [==============================] - 0s 11ms/step - loss: 0.0299\n",
            "Epoch 19/200\n",
            "19/19 [==============================] - 0s 12ms/step - loss: 0.0351\n",
            "Epoch 20/200\n",
            "19/19 [==============================] - 0s 12ms/step - loss: 0.0331\n",
            "Epoch 21/200\n",
            "19/19 [==============================] - 0s 12ms/step - loss: 0.0299\n",
            "Epoch 22/200\n",
            "19/19 [==============================] - 0s 12ms/step - loss: 0.0258\n",
            "Epoch 23/200\n",
            "19/19 [==============================] - 0s 13ms/step - loss: 0.0366\n",
            "Epoch 24/200\n",
            "19/19 [==============================] - 0s 12ms/step - loss: 0.0286\n",
            "Epoch 25/200\n",
            "19/19 [==============================] - 0s 12ms/step - loss: 0.0281\n",
            "Epoch 26/200\n",
            "19/19 [==============================] - 0s 12ms/step - loss: 0.0220\n",
            "Epoch 27/200\n",
            "19/19 [==============================] - 0s 13ms/step - loss: 0.0258\n",
            "Epoch 28/200\n",
            "19/19 [==============================] - 0s 13ms/step - loss: 0.0253\n",
            "Epoch 29/200\n",
            "19/19 [==============================] - 0s 12ms/step - loss: 0.0251\n",
            "Epoch 30/200\n",
            "19/19 [==============================] - 0s 13ms/step - loss: 0.0230\n",
            "Epoch 31/200\n",
            "19/19 [==============================] - 0s 13ms/step - loss: 0.0300\n",
            "Epoch 32/200\n",
            "19/19 [==============================] - 0s 12ms/step - loss: 0.0237\n",
            "Epoch 33/200\n",
            "19/19 [==============================] - 0s 12ms/step - loss: 0.0235\n",
            "Epoch 34/200\n",
            "19/19 [==============================] - 0s 12ms/step - loss: 0.0306\n",
            "Epoch 35/200\n",
            "19/19 [==============================] - 0s 11ms/step - loss: 0.0221\n",
            "Epoch 36/200\n",
            "19/19 [==============================] - 0s 12ms/step - loss: 0.0227\n",
            "Epoch 37/200\n",
            "19/19 [==============================] - 0s 11ms/step - loss: 0.0241\n",
            "Epoch 38/200\n",
            "19/19 [==============================] - 0s 12ms/step - loss: 0.0226\n",
            "Epoch 39/200\n",
            "19/19 [==============================] - 0s 12ms/step - loss: 0.0293\n",
            "Epoch 40/200\n",
            "19/19 [==============================] - 0s 12ms/step - loss: 0.0271\n",
            "Epoch 41/200\n",
            "19/19 [==============================] - 0s 11ms/step - loss: 0.0256\n",
            "Epoch 42/200\n",
            "19/19 [==============================] - 0s 11ms/step - loss: 0.0265\n",
            "Epoch 43/200\n",
            "19/19 [==============================] - 0s 13ms/step - loss: 0.0314\n",
            "Epoch 44/200\n",
            "19/19 [==============================] - 0s 12ms/step - loss: 0.0209\n",
            "Epoch 45/200\n",
            "19/19 [==============================] - 0s 11ms/step - loss: 0.0265\n",
            "Epoch 46/200\n",
            "19/19 [==============================] - 0s 12ms/step - loss: 0.0255\n",
            "Epoch 47/200\n",
            "19/19 [==============================] - 0s 12ms/step - loss: 0.0247\n",
            "Epoch 48/200\n",
            "19/19 [==============================] - 0s 12ms/step - loss: 0.0281\n",
            "Epoch 49/200\n",
            "19/19 [==============================] - 0s 12ms/step - loss: 0.0281\n",
            "Epoch 50/200\n",
            "19/19 [==============================] - 0s 12ms/step - loss: 0.0197\n",
            "Epoch 51/200\n",
            "19/19 [==============================] - 0s 21ms/step - loss: 0.0226\n",
            "Epoch 52/200\n",
            "19/19 [==============================] - 0s 20ms/step - loss: 0.0196\n",
            "Epoch 53/200\n",
            "19/19 [==============================] - 0s 19ms/step - loss: 0.0241\n",
            "Epoch 54/200\n",
            "19/19 [==============================] - 0s 20ms/step - loss: 0.0286\n",
            "Epoch 55/200\n",
            "19/19 [==============================] - 0s 21ms/step - loss: 0.0258\n",
            "Epoch 56/200\n",
            "19/19 [==============================] - 0s 20ms/step - loss: 0.0292\n",
            "Epoch 57/200\n",
            "19/19 [==============================] - 0s 21ms/step - loss: 0.0216\n",
            "Epoch 58/200\n",
            "19/19 [==============================] - 0s 20ms/step - loss: 0.0228\n",
            "Epoch 59/200\n",
            "19/19 [==============================] - 0s 20ms/step - loss: 0.0236\n",
            "Epoch 60/200\n",
            "19/19 [==============================] - 0s 16ms/step - loss: 0.0326\n",
            "Epoch 61/200\n",
            "19/19 [==============================] - 0s 12ms/step - loss: 0.0253\n",
            "Epoch 62/200\n",
            "19/19 [==============================] - 0s 12ms/step - loss: 0.0225\n",
            "Epoch 63/200\n",
            "19/19 [==============================] - 0s 11ms/step - loss: 0.0210\n",
            "Epoch 64/200\n",
            "19/19 [==============================] - 0s 13ms/step - loss: 0.0192\n",
            "Epoch 65/200\n",
            "19/19 [==============================] - 0s 11ms/step - loss: 0.0195\n",
            "Epoch 66/200\n",
            "19/19 [==============================] - 0s 12ms/step - loss: 0.0202\n",
            "Epoch 67/200\n",
            "19/19 [==============================] - 0s 11ms/step - loss: 0.0216\n",
            "Epoch 68/200\n",
            "19/19 [==============================] - 0s 13ms/step - loss: 0.0230\n",
            "Epoch 69/200\n",
            "19/19 [==============================] - 0s 12ms/step - loss: 0.0177\n",
            "Epoch 70/200\n",
            "19/19 [==============================] - 0s 11ms/step - loss: 0.0248\n",
            "Epoch 71/200\n",
            "19/19 [==============================] - 0s 12ms/step - loss: 0.0245\n",
            "Epoch 72/200\n",
            "19/19 [==============================] - 0s 11ms/step - loss: 0.0201\n",
            "Epoch 73/200\n",
            "19/19 [==============================] - 0s 12ms/step - loss: 0.0288\n",
            "Epoch 74/200\n",
            "19/19 [==============================] - 0s 11ms/step - loss: 0.0229\n",
            "Epoch 75/200\n",
            "19/19 [==============================] - 0s 12ms/step - loss: 0.0210\n",
            "Epoch 76/200\n",
            "19/19 [==============================] - 0s 11ms/step - loss: 0.0205\n",
            "Epoch 77/200\n",
            "19/19 [==============================] - 0s 12ms/step - loss: 0.0261\n",
            "Epoch 78/200\n",
            "19/19 [==============================] - 0s 11ms/step - loss: 0.0211\n",
            "Epoch 79/200\n",
            "19/19 [==============================] - 0s 11ms/step - loss: 0.0249\n",
            "Epoch 80/200\n",
            "19/19 [==============================] - 0s 12ms/step - loss: 0.0218\n",
            "Epoch 81/200\n",
            "19/19 [==============================] - 0s 11ms/step - loss: 0.0182\n",
            "Epoch 82/200\n",
            "19/19 [==============================] - 0s 12ms/step - loss: 0.0205\n",
            "Epoch 83/200\n",
            "19/19 [==============================] - 0s 11ms/step - loss: 0.0229\n",
            "Epoch 84/200\n",
            "19/19 [==============================] - 0s 11ms/step - loss: 0.0218\n",
            "Epoch 85/200\n",
            "19/19 [==============================] - 0s 11ms/step - loss: 0.0200\n",
            "Epoch 86/200\n",
            "19/19 [==============================] - 0s 12ms/step - loss: 0.0199\n",
            "Epoch 87/200\n",
            "19/19 [==============================] - 0s 11ms/step - loss: 0.0153\n",
            "Epoch 88/200\n",
            "19/19 [==============================] - 0s 12ms/step - loss: 0.0174\n",
            "Epoch 89/200\n",
            "19/19 [==============================] - 0s 12ms/step - loss: 0.0209\n",
            "Epoch 90/200\n",
            "19/19 [==============================] - 0s 12ms/step - loss: 0.0216\n",
            "Epoch 91/200\n",
            "19/19 [==============================] - 0s 13ms/step - loss: 0.0214\n",
            "Epoch 92/200\n",
            "19/19 [==============================] - 0s 11ms/step - loss: 0.0174\n",
            "Epoch 93/200\n",
            "19/19 [==============================] - 0s 12ms/step - loss: 0.0195\n",
            "Epoch 94/200\n",
            "19/19 [==============================] - 0s 12ms/step - loss: 0.0199\n",
            "Epoch 95/200\n",
            "19/19 [==============================] - 0s 13ms/step - loss: 0.0170\n",
            "Epoch 96/200\n",
            "19/19 [==============================] - 0s 12ms/step - loss: 0.0162\n",
            "Epoch 97/200\n",
            "19/19 [==============================] - 0s 12ms/step - loss: 0.0201\n",
            "Epoch 98/200\n",
            "19/19 [==============================] - 0s 12ms/step - loss: 0.0270\n",
            "Epoch 99/200\n",
            "19/19 [==============================] - 0s 12ms/step - loss: 0.0205\n",
            "Epoch 100/200\n",
            "19/19 [==============================] - 0s 12ms/step - loss: 0.0193\n",
            "Epoch 101/200\n",
            "19/19 [==============================] - 0s 12ms/step - loss: 0.0226\n",
            "Epoch 102/200\n",
            "19/19 [==============================] - 0s 12ms/step - loss: 0.0264\n",
            "Epoch 103/200\n",
            "19/19 [==============================] - 0s 13ms/step - loss: 0.0194\n",
            "Epoch 104/200\n",
            "19/19 [==============================] - 0s 21ms/step - loss: 0.0171\n",
            "Epoch 105/200\n",
            "19/19 [==============================] - 0s 20ms/step - loss: 0.0179\n",
            "Epoch 106/200\n",
            "19/19 [==============================] - 0s 22ms/step - loss: 0.0223\n",
            "Epoch 107/200\n",
            "19/19 [==============================] - 0s 18ms/step - loss: 0.0176\n",
            "Epoch 108/200\n",
            "19/19 [==============================] - 0s 21ms/step - loss: 0.0173\n",
            "Epoch 109/200\n",
            "19/19 [==============================] - 0s 22ms/step - loss: 0.0174\n",
            "Epoch 110/200\n",
            "19/19 [==============================] - 0s 19ms/step - loss: 0.0165\n",
            "Epoch 111/200\n",
            "19/19 [==============================] - 0s 21ms/step - loss: 0.0175\n",
            "Epoch 112/200\n",
            "19/19 [==============================] - 0s 21ms/step - loss: 0.0310\n",
            "Epoch 113/200\n",
            "19/19 [==============================] - 0s 22ms/step - loss: 0.0232\n",
            "Epoch 114/200\n",
            "19/19 [==============================] - 0s 11ms/step - loss: 0.0213\n",
            "Epoch 115/200\n",
            "19/19 [==============================] - 0s 13ms/step - loss: 0.0132\n",
            "Epoch 116/200\n",
            "19/19 [==============================] - 0s 12ms/step - loss: 0.0179\n",
            "Epoch 117/200\n",
            "19/19 [==============================] - 0s 12ms/step - loss: 0.0174\n",
            "Epoch 118/200\n",
            "19/19 [==============================] - 0s 12ms/step - loss: 0.0199\n",
            "Epoch 119/200\n",
            "19/19 [==============================] - 0s 12ms/step - loss: 0.0222\n",
            "Epoch 120/200\n",
            "19/19 [==============================] - 0s 13ms/step - loss: 0.0211\n",
            "Epoch 121/200\n",
            "19/19 [==============================] - 0s 11ms/step - loss: 0.0157\n",
            "Epoch 122/200\n",
            "19/19 [==============================] - 0s 12ms/step - loss: 0.0147\n",
            "Epoch 123/200\n",
            "19/19 [==============================] - 0s 12ms/step - loss: 0.0175\n",
            "Epoch 124/200\n",
            "19/19 [==============================] - 0s 12ms/step - loss: 0.0180\n",
            "Epoch 125/200\n",
            "19/19 [==============================] - 0s 12ms/step - loss: 0.0191\n",
            "Epoch 126/200\n",
            "19/19 [==============================] - 0s 11ms/step - loss: 0.0166\n",
            "Epoch 127/200\n",
            "19/19 [==============================] - 0s 12ms/step - loss: 0.0176\n",
            "Epoch 128/200\n",
            "19/19 [==============================] - 0s 11ms/step - loss: 0.0143\n",
            "Epoch 129/200\n",
            "19/19 [==============================] - 0s 12ms/step - loss: 0.0183\n",
            "Epoch 130/200\n",
            "19/19 [==============================] - 0s 12ms/step - loss: 0.0180\n",
            "Epoch 131/200\n",
            "19/19 [==============================] - 0s 12ms/step - loss: 0.0180\n",
            "Epoch 132/200\n",
            "19/19 [==============================] - 0s 12ms/step - loss: 0.0205\n",
            "Epoch 133/200\n",
            "19/19 [==============================] - 0s 13ms/step - loss: 0.0190\n",
            "Epoch 134/200\n",
            "19/19 [==============================] - 0s 11ms/step - loss: 0.0150\n",
            "Epoch 135/200\n",
            "19/19 [==============================] - 0s 12ms/step - loss: 0.0198\n",
            "Epoch 136/200\n",
            "19/19 [==============================] - 0s 11ms/step - loss: 0.0131\n",
            "Epoch 137/200\n",
            "19/19 [==============================] - 0s 13ms/step - loss: 0.0170\n",
            "Epoch 138/200\n",
            "19/19 [==============================] - 0s 12ms/step - loss: 0.0117\n",
            "Epoch 139/200\n",
            "19/19 [==============================] - 0s 12ms/step - loss: 0.0196\n",
            "Epoch 140/200\n",
            "19/19 [==============================] - 0s 12ms/step - loss: 0.0198\n",
            "Epoch 141/200\n",
            "19/19 [==============================] - 0s 12ms/step - loss: 0.0164\n",
            "Epoch 142/200\n",
            "19/19 [==============================] - 0s 12ms/step - loss: 0.0184\n",
            "Epoch 143/200\n",
            "19/19 [==============================] - 0s 13ms/step - loss: 0.0167\n",
            "Epoch 144/200\n",
            "19/19 [==============================] - 0s 12ms/step - loss: 0.0186\n",
            "Epoch 145/200\n",
            "19/19 [==============================] - 0s 12ms/step - loss: 0.0152\n",
            "Epoch 146/200\n",
            "19/19 [==============================] - 0s 13ms/step - loss: 0.0172\n",
            "Epoch 147/200\n",
            "19/19 [==============================] - 0s 12ms/step - loss: 0.0182\n",
            "Epoch 148/200\n",
            "19/19 [==============================] - 0s 12ms/step - loss: 0.0147\n",
            "Epoch 149/200\n",
            "19/19 [==============================] - 0s 12ms/step - loss: 0.0163\n",
            "Epoch 150/200\n",
            "19/19 [==============================] - 0s 13ms/step - loss: 0.0122\n",
            "Epoch 151/200\n",
            "19/19 [==============================] - 0s 12ms/step - loss: 0.0128\n",
            "Epoch 152/200\n",
            "19/19 [==============================] - 0s 11ms/step - loss: 0.0144\n",
            "Epoch 153/200\n",
            "19/19 [==============================] - 0s 12ms/step - loss: 0.0161\n",
            "Epoch 154/200\n",
            "19/19 [==============================] - 0s 12ms/step - loss: 0.0128\n",
            "Epoch 155/200\n",
            "19/19 [==============================] - 0s 13ms/step - loss: 0.0157\n",
            "Epoch 156/200\n",
            "19/19 [==============================] - 0s 16ms/step - loss: 0.0147\n",
            "Epoch 157/200\n",
            "19/19 [==============================] - 0s 21ms/step - loss: 0.0176\n",
            "Epoch 158/200\n",
            "19/19 [==============================] - 0s 20ms/step - loss: 0.0146\n",
            "Epoch 159/200\n",
            "19/19 [==============================] - 0s 19ms/step - loss: 0.0135\n",
            "Epoch 160/200\n",
            "19/19 [==============================] - 0s 19ms/step - loss: 0.0157\n",
            "Epoch 161/200\n",
            "19/19 [==============================] - 0s 22ms/step - loss: 0.0138\n",
            "Epoch 162/200\n",
            "19/19 [==============================] - 0s 21ms/step - loss: 0.0136\n",
            "Epoch 163/200\n",
            "19/19 [==============================] - 0s 21ms/step - loss: 0.0134\n",
            "Epoch 164/200\n",
            "19/19 [==============================] - 0s 21ms/step - loss: 0.0134\n",
            "Epoch 165/200\n",
            "19/19 [==============================] - 0s 21ms/step - loss: 0.0165\n",
            "Epoch 166/200\n",
            "19/19 [==============================] - 0s 21ms/step - loss: 0.0158\n",
            "Epoch 167/200\n",
            "19/19 [==============================] - 0s 12ms/step - loss: 0.0204\n",
            "Epoch 168/200\n",
            "19/19 [==============================] - 0s 12ms/step - loss: 0.0153\n",
            "Epoch 169/200\n",
            "19/19 [==============================] - 0s 12ms/step - loss: 0.0158\n",
            "Epoch 170/200\n",
            "19/19 [==============================] - 0s 13ms/step - loss: 0.0147\n",
            "Epoch 171/200\n",
            "19/19 [==============================] - 0s 12ms/step - loss: 0.0158\n",
            "Epoch 172/200\n",
            "19/19 [==============================] - 0s 12ms/step - loss: 0.0155\n",
            "Epoch 173/200\n",
            "19/19 [==============================] - 0s 12ms/step - loss: 0.0150\n",
            "Epoch 174/200\n",
            "19/19 [==============================] - 0s 12ms/step - loss: 0.0166\n",
            "Epoch 175/200\n",
            "19/19 [==============================] - 0s 12ms/step - loss: 0.0139\n",
            "Epoch 176/200\n",
            "19/19 [==============================] - 0s 11ms/step - loss: 0.0169\n",
            "Epoch 177/200\n",
            "19/19 [==============================] - 0s 12ms/step - loss: 0.0152\n",
            "Epoch 178/200\n",
            "19/19 [==============================] - 0s 12ms/step - loss: 0.0163\n",
            "Epoch 179/200\n",
            "19/19 [==============================] - 0s 13ms/step - loss: 0.0144\n",
            "Epoch 180/200\n",
            "19/19 [==============================] - 0s 12ms/step - loss: 0.0127\n",
            "Epoch 181/200\n",
            "19/19 [==============================] - 0s 12ms/step - loss: 0.0197\n",
            "Epoch 182/200\n",
            "19/19 [==============================] - 0s 12ms/step - loss: 0.0145\n",
            "Epoch 183/200\n",
            "19/19 [==============================] - 0s 13ms/step - loss: 0.0148\n",
            "Epoch 184/200\n",
            "19/19 [==============================] - 0s 12ms/step - loss: 0.0168\n",
            "Epoch 185/200\n",
            "19/19 [==============================] - 0s 12ms/step - loss: 0.0171\n",
            "Epoch 186/200\n",
            "19/19 [==============================] - 0s 12ms/step - loss: 0.0140\n",
            "Epoch 187/200\n",
            "19/19 [==============================] - 0s 14ms/step - loss: 0.0145\n",
            "Epoch 188/200\n",
            "19/19 [==============================] - 0s 12ms/step - loss: 0.0126\n",
            "Epoch 189/200\n",
            "19/19 [==============================] - 0s 12ms/step - loss: 0.0191\n",
            "Epoch 190/200\n",
            "19/19 [==============================] - 0s 12ms/step - loss: 0.0144\n",
            "Epoch 191/200\n",
            "19/19 [==============================] - 0s 12ms/step - loss: 0.0145\n",
            "Epoch 192/200\n",
            "19/19 [==============================] - 0s 12ms/step - loss: 0.0121\n",
            "Epoch 193/200\n",
            "19/19 [==============================] - 0s 12ms/step - loss: 0.0146\n",
            "Epoch 194/200\n",
            "19/19 [==============================] - 0s 12ms/step - loss: 0.0118\n",
            "Epoch 195/200\n",
            "19/19 [==============================] - 0s 11ms/step - loss: 0.0171\n",
            "Epoch 196/200\n",
            "19/19 [==============================] - 0s 13ms/step - loss: 0.0151\n",
            "Epoch 197/200\n",
            "19/19 [==============================] - 0s 12ms/step - loss: 0.0203\n",
            "Epoch 198/200\n",
            "19/19 [==============================] - 0s 12ms/step - loss: 0.0130\n",
            "Epoch 199/200\n",
            "19/19 [==============================] - 0s 12ms/step - loss: 0.0156\n",
            "Epoch 200/200\n",
            "19/19 [==============================] - 0s 13ms/step - loss: 0.0172\n",
            "2/2 [==============================] - 1s 12ms/step\n",
            "Predicted prices from 2024-04-01 to 2028-12-01:\n",
            "2024-04-01: 2.802 (Lower Bound: 2.749, Upper Bound: 2.854)\n",
            "2024-05-01: 2.805 (Lower Bound: 2.753, Upper Bound: 2.858)\n",
            "2024-06-01: 2.809 (Lower Bound: 2.757, Upper Bound: 2.862)\n",
            "2024-07-01: 2.814 (Lower Bound: 2.762, Upper Bound: 2.866)\n",
            "2024-08-01: 2.820 (Lower Bound: 2.767, Upper Bound: 2.872)\n",
            "2024-09-01: 2.826 (Lower Bound: 2.774, Upper Bound: 2.879)\n",
            "2024-10-01: 2.836 (Lower Bound: 2.783, Upper Bound: 2.888)\n",
            "2024-11-01: 2.852 (Lower Bound: 2.800, Upper Bound: 2.905)\n",
            "2024-12-01: 2.871 (Lower Bound: 2.818, Upper Bound: 2.923)\n",
            "2025-01-01: 2.890 (Lower Bound: 2.838, Upper Bound: 2.943)\n",
            "2025-02-01: 2.911 (Lower Bound: 2.858, Upper Bound: 2.963)\n",
            "2025-03-01: 2.931 (Lower Bound: 2.879, Upper Bound: 2.984)\n",
            "2025-04-01: 2.952 (Lower Bound: 2.900, Upper Bound: 3.005)\n",
            "2025-05-01: 2.974 (Lower Bound: 2.921, Upper Bound: 3.026)\n",
            "2025-06-01: 2.995 (Lower Bound: 2.943, Upper Bound: 3.048)\n",
            "2025-07-01: 3.025 (Lower Bound: 2.972, Upper Bound: 3.077)\n",
            "2025-08-01: 3.057 (Lower Bound: 3.004, Upper Bound: 3.109)\n",
            "2025-09-01: 3.090 (Lower Bound: 3.037, Upper Bound: 3.142)\n",
            "2025-10-01: 3.124 (Lower Bound: 3.071, Upper Bound: 3.176)\n",
            "2025-11-01: 3.158 (Lower Bound: 3.106, Upper Bound: 3.211)\n",
            "2025-12-01: 3.193 (Lower Bound: 3.141, Upper Bound: 3.246)\n",
            "2026-01-01: 3.229 (Lower Bound: 3.176, Upper Bound: 3.281)\n",
            "2026-02-01: 3.264 (Lower Bound: 3.212, Upper Bound: 3.317)\n",
            "2026-03-01: 3.300 (Lower Bound: 3.247, Upper Bound: 3.352)\n",
            "2026-04-01: 3.335 (Lower Bound: 3.283, Upper Bound: 3.388)\n",
            "2026-05-01: 3.370 (Lower Bound: 3.318, Upper Bound: 3.423)\n",
            "2026-06-01: 3.405 (Lower Bound: 3.353, Upper Bound: 3.458)\n",
            "2026-07-01: 3.440 (Lower Bound: 3.388, Upper Bound: 3.493)\n",
            "2026-08-01: 3.475 (Lower Bound: 3.422, Upper Bound: 3.527)\n",
            "2026-09-01: 3.509 (Lower Bound: 3.457, Upper Bound: 3.562)\n",
            "2026-10-01: 3.542 (Lower Bound: 3.489, Upper Bound: 3.594)\n",
            "2026-11-01: 3.553 (Lower Bound: 3.501, Upper Bound: 3.606)\n",
            "2026-12-01: 3.568 (Lower Bound: 3.516, Upper Bound: 3.621)\n",
            "2027-01-01: 3.583 (Lower Bound: 3.531, Upper Bound: 3.636)\n",
            "2027-02-01: 3.598 (Lower Bound: 3.546, Upper Bound: 3.651)\n",
            "2027-03-01: 3.613 (Lower Bound: 3.561, Upper Bound: 3.666)\n",
            "2027-04-01: 3.629 (Lower Bound: 3.576, Upper Bound: 3.681)\n",
            "2027-05-01: 3.644 (Lower Bound: 3.591, Upper Bound: 3.696)\n",
            "2027-06-01: 3.652 (Lower Bound: 3.600, Upper Bound: 3.705)\n",
            "2027-07-01: 3.655 (Lower Bound: 3.603, Upper Bound: 3.708)\n",
            "2027-08-01: 3.657 (Lower Bound: 3.605, Upper Bound: 3.710)\n",
            "2027-09-01: 3.659 (Lower Bound: 3.607, Upper Bound: 3.712)\n",
            "2027-10-01: 3.662 (Lower Bound: 3.610, Upper Bound: 3.714)\n",
            "2027-11-01: 3.665 (Lower Bound: 3.612, Upper Bound: 3.717)\n",
            "2027-12-01: 3.668 (Lower Bound: 3.615, Upper Bound: 3.720)\n",
            "2028-01-01: 3.671 (Lower Bound: 3.619, Upper Bound: 3.724)\n",
            "2028-02-01: 3.675 (Lower Bound: 3.622, Upper Bound: 3.727)\n",
            "2028-03-01: 3.679 (Lower Bound: 3.626, Upper Bound: 3.731)\n",
            "2028-04-01: 3.683 (Lower Bound: 3.631, Upper Bound: 3.735)\n",
            "2028-05-01: 3.687 (Lower Bound: 3.635, Upper Bound: 3.740)\n",
            "2028-06-01: 3.689 (Lower Bound: 3.637, Upper Bound: 3.742)\n",
            "2028-07-01: 3.686 (Lower Bound: 3.634, Upper Bound: 3.739)\n",
            "2028-08-01: 3.683 (Lower Bound: 3.631, Upper Bound: 3.736)\n",
            "2028-09-01: 3.681 (Lower Bound: 3.628, Upper Bound: 3.733)\n",
            "2028-10-01: 3.678 (Lower Bound: 3.625, Upper Bound: 3.730)\n",
            "2028-11-01: 3.675 (Lower Bound: 3.623, Upper Bound: 3.728)\n",
            "2028-12-01: 3.673 (Lower Bound: 3.621, Upper Bound: 3.726)\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from datetime import datetime\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import LSTM, Dense, Dropout\n",
        "\n",
        "# Read the dataset\n",
        "df = pd.read_excel('LNG (High).xlsx')\n",
        "\n",
        "# Function to calculate the number of months between two dates\n",
        "def months_between(start_date, end_date):\n",
        "    start_date = datetime.strptime(start_date, \"%Y-%m-%d\")\n",
        "    end_date = datetime.strptime(end_date, \"%Y-%m-%d\")\n",
        "    return (end_date.year - start_date.year) * 12 + end_date.month - start_date.month + 1\n",
        "\n",
        "# Define the date range\n",
        "start_date = '2024-04-01'\n",
        "end_date = '2028-12-01'\n",
        "\n",
        "# Calculate the number of months to predict\n",
        "num_months = months_between(start_date, end_date)\n",
        "\n",
        "# Ensure data is sorted by date\n",
        "df['Date'] = pd.to_datetime(df['Date'], format='%b-%y')\n",
        "df = df.sort_values(by=\"Date\", ascending=True)\n",
        "\n",
        "# Normalize the data\n",
        "scaler = MinMaxScaler(feature_range=(0, 1))\n",
        "df['Price_normalized'] = scaler.fit_transform(df['Price'].values.reshape(-1,1))\n",
        "\n",
        "# Create a new feature representing the number of months since start date\n",
        "df['Months_since_start'] = (df['Date'] - pd.to_datetime(start_date)).dt.days / 30\n",
        "\n",
        "# Prepare data for training\n",
        "X_train = df['Months_since_start'].values.reshape(-1, 1, 1)\n",
        "y_train = df['Price_normalized'].values\n",
        "\n",
        "# Define and train the LSTM model with increased dropout rate\n",
        "model = Sequential()\n",
        "model.add(LSTM(256, activation='relu', return_sequences=True, input_shape=(1, 1)))\n",
        "model.add(Dropout(0.5))  # Increase dropout rate\n",
        "model.add(LSTM(128, activation='relu', return_sequences=True))\n",
        "model.add(Dropout(0.5))  # Increase dropout rate\n",
        "model.add(LSTM(64, activation='relu'))\n",
        "model.add(Dropout(0.5))  # Increase dropout rate\n",
        "model.add(Dense(32, activation='relu'))\n",
        "model.add(Dense(1, activation='relu'))\n",
        "model.compile(optimizer='adam', loss='mean_squared_error')\n",
        "model.fit(X_train, y_train, epochs=200, batch_size=8)\n",
        "\n",
        "# Generate future indices for prediction\n",
        "X_future = np.arange(df['Months_since_start'].iloc[-1] + 1, df['Months_since_start'].iloc[-1] + 1 + num_months)\n",
        "X_future = X_future.reshape(-1, 1, 1)  # Reshape for LSTM input\n",
        "\n",
        "# Generate predictions\n",
        "y_pred_normalized = model.predict(X_future)\n",
        "\n",
        "# Inverse transform predictions to get actual prices\n",
        "y_pred = scaler.inverse_transform(y_pred_normalized)\n",
        "\n",
        "# Ensure predictions are non-negative\n",
        "y_pred = np.maximum(y_pred, 0)\n",
        "\n",
        "# Compute confidence interval bounds\n",
        "confidence_level = 0.80  # Set confidence level\n",
        "z_score = 1.28  # Z-score for 80% confidence level\n",
        "std_dev = np.std(y_pred_normalized)  # Compute standard deviation\n",
        "margin_of_error = z_score * std_dev  # Margin of error\n",
        "lower_bound = y_pred - margin_of_error\n",
        "upper_bound = y_pred + margin_of_error\n",
        "\n",
        "# Generate date range for the predictions\n",
        "dates = pd.date_range(start=start_date, periods=num_months, freq='MS')\n",
        "\n",
        "# Print predicted prices with corresponding dates and confidence intervals\n",
        "print(\"Predicted prices from 2024-04-01 to 2028-12-01:\")\n",
        "for date, pred, lower, upper in zip(dates, y_pred.flatten(), lower_bound.flatten(), upper_bound.flatten()):\n",
        "    print(f\"{date.strftime('%Y-%m-%d')}: {pred:.3f} (Lower Bound: {lower:.3f}, Upper Bound: {upper:.3f})\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iQZTl5g2D_ca",
        "outputId": "bd3b04b8-eef0-4cbd-c2d8-e97f3477dde0"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/200\n",
            "19/19 [==============================] - 7s 21ms/step - loss: 0.0744\n",
            "Epoch 2/200\n",
            "19/19 [==============================] - 0s 24ms/step - loss: 0.0505\n",
            "Epoch 3/200\n",
            "19/19 [==============================] - 0s 24ms/step - loss: 0.0430\n",
            "Epoch 4/200\n",
            "19/19 [==============================] - 0s 21ms/step - loss: 0.0408\n",
            "Epoch 5/200\n",
            "19/19 [==============================] - 0s 23ms/step - loss: 0.0371\n",
            "Epoch 6/200\n",
            "19/19 [==============================] - 1s 30ms/step - loss: 0.0365\n",
            "Epoch 7/200\n",
            "19/19 [==============================] - 1s 28ms/step - loss: 0.0367\n",
            "Epoch 8/200\n",
            "19/19 [==============================] - 1s 31ms/step - loss: 0.0366\n",
            "Epoch 9/200\n",
            "19/19 [==============================] - 1s 27ms/step - loss: 0.0297\n",
            "Epoch 10/200\n",
            "19/19 [==============================] - 0s 26ms/step - loss: 0.0254\n",
            "Epoch 11/200\n",
            "19/19 [==============================] - 1s 28ms/step - loss: 0.0271\n",
            "Epoch 12/200\n",
            "19/19 [==============================] - 0s 25ms/step - loss: 0.0307\n",
            "Epoch 13/200\n",
            "19/19 [==============================] - 0s 25ms/step - loss: 0.0297\n",
            "Epoch 14/200\n",
            "19/19 [==============================] - 0s 25ms/step - loss: 0.0304\n",
            "Epoch 15/200\n",
            "19/19 [==============================] - 0s 23ms/step - loss: 0.0290\n",
            "Epoch 16/200\n",
            "19/19 [==============================] - 0s 22ms/step - loss: 0.0320\n",
            "Epoch 17/200\n",
            "19/19 [==============================] - 0s 23ms/step - loss: 0.0307\n",
            "Epoch 18/200\n",
            "19/19 [==============================] - 0s 20ms/step - loss: 0.0279\n",
            "Epoch 19/200\n",
            "19/19 [==============================] - 0s 12ms/step - loss: 0.0288\n",
            "Epoch 20/200\n",
            "19/19 [==============================] - 0s 11ms/step - loss: 0.0321\n",
            "Epoch 21/200\n",
            "19/19 [==============================] - 0s 13ms/step - loss: 0.0232\n",
            "Epoch 22/200\n",
            "19/19 [==============================] - 0s 12ms/step - loss: 0.0300\n",
            "Epoch 23/200\n",
            "19/19 [==============================] - 0s 12ms/step - loss: 0.0327\n",
            "Epoch 24/200\n",
            "19/19 [==============================] - 0s 12ms/step - loss: 0.0300\n",
            "Epoch 25/200\n",
            "19/19 [==============================] - 0s 14ms/step - loss: 0.0232\n",
            "Epoch 26/200\n",
            "19/19 [==============================] - 0s 12ms/step - loss: 0.0237\n",
            "Epoch 27/200\n",
            "19/19 [==============================] - 0s 11ms/step - loss: 0.0347\n",
            "Epoch 28/200\n",
            "19/19 [==============================] - 0s 11ms/step - loss: 0.0242\n",
            "Epoch 29/200\n",
            "19/19 [==============================] - 0s 12ms/step - loss: 0.0339\n",
            "Epoch 30/200\n",
            "19/19 [==============================] - 0s 12ms/step - loss: 0.0272\n",
            "Epoch 31/200\n",
            "19/19 [==============================] - 0s 12ms/step - loss: 0.0284\n",
            "Epoch 32/200\n",
            "19/19 [==============================] - 0s 11ms/step - loss: 0.0233\n",
            "Epoch 33/200\n",
            "19/19 [==============================] - 0s 12ms/step - loss: 0.0331\n",
            "Epoch 34/200\n",
            "19/19 [==============================] - 0s 13ms/step - loss: 0.0327\n",
            "Epoch 35/200\n",
            "19/19 [==============================] - 0s 12ms/step - loss: 0.0317\n",
            "Epoch 36/200\n",
            "19/19 [==============================] - 0s 12ms/step - loss: 0.0288\n",
            "Epoch 37/200\n",
            "19/19 [==============================] - 0s 11ms/step - loss: 0.0270\n",
            "Epoch 38/200\n",
            "19/19 [==============================] - 0s 12ms/step - loss: 0.0269\n",
            "Epoch 39/200\n",
            "19/19 [==============================] - 0s 13ms/step - loss: 0.0251\n",
            "Epoch 40/200\n",
            "19/19 [==============================] - 0s 11ms/step - loss: 0.0294\n",
            "Epoch 41/200\n",
            "19/19 [==============================] - 0s 11ms/step - loss: 0.0250\n",
            "Epoch 42/200\n",
            "19/19 [==============================] - 0s 12ms/step - loss: 0.0271\n",
            "Epoch 43/200\n",
            "19/19 [==============================] - 0s 12ms/step - loss: 0.0262\n",
            "Epoch 44/200\n",
            "19/19 [==============================] - 0s 11ms/step - loss: 0.0222\n",
            "Epoch 45/200\n",
            "19/19 [==============================] - 0s 11ms/step - loss: 0.0290\n",
            "Epoch 46/200\n",
            "19/19 [==============================] - 0s 12ms/step - loss: 0.0290\n",
            "Epoch 47/200\n",
            "19/19 [==============================] - 0s 11ms/step - loss: 0.0233\n",
            "Epoch 48/200\n",
            "19/19 [==============================] - 0s 12ms/step - loss: 0.0205\n",
            "Epoch 49/200\n",
            "19/19 [==============================] - 0s 11ms/step - loss: 0.0293\n",
            "Epoch 50/200\n",
            "19/19 [==============================] - 0s 12ms/step - loss: 0.0252\n",
            "Epoch 51/200\n",
            "19/19 [==============================] - 0s 12ms/step - loss: 0.0234\n",
            "Epoch 52/200\n",
            "19/19 [==============================] - 0s 12ms/step - loss: 0.0268\n",
            "Epoch 53/200\n",
            "19/19 [==============================] - 0s 12ms/step - loss: 0.0243\n",
            "Epoch 54/200\n",
            "19/19 [==============================] - 0s 19ms/step - loss: 0.0206\n",
            "Epoch 55/200\n",
            "19/19 [==============================] - 0s 22ms/step - loss: 0.0248\n",
            "Epoch 56/200\n",
            "19/19 [==============================] - 0s 20ms/step - loss: 0.0203\n",
            "Epoch 57/200\n",
            "19/19 [==============================] - 0s 20ms/step - loss: 0.0202\n",
            "Epoch 58/200\n",
            "19/19 [==============================] - 0s 20ms/step - loss: 0.0215\n",
            "Epoch 59/200\n",
            "19/19 [==============================] - 0s 20ms/step - loss: 0.0218\n",
            "Epoch 60/200\n",
            "19/19 [==============================] - 0s 21ms/step - loss: 0.0190\n",
            "Epoch 61/200\n",
            "19/19 [==============================] - 0s 21ms/step - loss: 0.0206\n",
            "Epoch 62/200\n",
            "19/19 [==============================] - 0s 21ms/step - loss: 0.0215\n",
            "Epoch 63/200\n",
            "19/19 [==============================] - 0s 22ms/step - loss: 0.0178\n",
            "Epoch 64/200\n",
            "19/19 [==============================] - 0s 12ms/step - loss: 0.0199\n",
            "Epoch 65/200\n",
            "19/19 [==============================] - 0s 12ms/step - loss: 0.0225\n",
            "Epoch 66/200\n",
            "19/19 [==============================] - 0s 12ms/step - loss: 0.0242\n",
            "Epoch 67/200\n",
            "19/19 [==============================] - 0s 12ms/step - loss: 0.0195\n",
            "Epoch 68/200\n",
            "19/19 [==============================] - 0s 12ms/step - loss: 0.0213\n",
            "Epoch 69/200\n",
            "19/19 [==============================] - 0s 11ms/step - loss: 0.0225\n",
            "Epoch 70/200\n",
            "19/19 [==============================] - 0s 12ms/step - loss: 0.0197\n",
            "Epoch 71/200\n",
            "19/19 [==============================] - 0s 12ms/step - loss: 0.0229\n",
            "Epoch 72/200\n",
            "19/19 [==============================] - 0s 13ms/step - loss: 0.0187\n",
            "Epoch 73/200\n",
            "19/19 [==============================] - 0s 11ms/step - loss: 0.0212\n",
            "Epoch 74/200\n",
            "19/19 [==============================] - 0s 11ms/step - loss: 0.0250\n",
            "Epoch 75/200\n",
            "19/19 [==============================] - 0s 11ms/step - loss: 0.0202\n",
            "Epoch 76/200\n",
            "19/19 [==============================] - 0s 11ms/step - loss: 0.0188\n",
            "Epoch 77/200\n",
            "19/19 [==============================] - 0s 12ms/step - loss: 0.0232\n",
            "Epoch 78/200\n",
            "19/19 [==============================] - 0s 11ms/step - loss: 0.0273\n",
            "Epoch 79/200\n",
            "19/19 [==============================] - 0s 12ms/step - loss: 0.0225\n",
            "Epoch 80/200\n",
            "19/19 [==============================] - 0s 12ms/step - loss: 0.0187\n",
            "Epoch 81/200\n",
            "19/19 [==============================] - 0s 12ms/step - loss: 0.0162\n",
            "Epoch 82/200\n",
            "19/19 [==============================] - 0s 12ms/step - loss: 0.0192\n",
            "Epoch 83/200\n",
            "19/19 [==============================] - 0s 12ms/step - loss: 0.0224\n",
            "Epoch 84/200\n",
            "19/19 [==============================] - 0s 12ms/step - loss: 0.0211\n",
            "Epoch 85/200\n",
            "19/19 [==============================] - 0s 12ms/step - loss: 0.0193\n",
            "Epoch 86/200\n",
            "19/19 [==============================] - 0s 12ms/step - loss: 0.0229\n",
            "Epoch 87/200\n",
            "19/19 [==============================] - 0s 13ms/step - loss: 0.0185\n",
            "Epoch 88/200\n",
            "19/19 [==============================] - 0s 12ms/step - loss: 0.0164\n",
            "Epoch 89/200\n",
            "19/19 [==============================] - 0s 11ms/step - loss: 0.0160\n",
            "Epoch 90/200\n",
            "19/19 [==============================] - 0s 12ms/step - loss: 0.0151\n",
            "Epoch 91/200\n",
            "19/19 [==============================] - 0s 12ms/step - loss: 0.0170\n",
            "Epoch 92/200\n",
            "19/19 [==============================] - 0s 12ms/step - loss: 0.0204\n",
            "Epoch 93/200\n",
            "19/19 [==============================] - 0s 11ms/step - loss: 0.0171\n",
            "Epoch 94/200\n",
            "19/19 [==============================] - 0s 12ms/step - loss: 0.0183\n",
            "Epoch 95/200\n",
            "19/19 [==============================] - 0s 11ms/step - loss: 0.0151\n",
            "Epoch 96/200\n",
            "19/19 [==============================] - 0s 12ms/step - loss: 0.0182\n",
            "Epoch 97/200\n",
            "19/19 [==============================] - 0s 12ms/step - loss: 0.0168\n",
            "Epoch 98/200\n",
            "19/19 [==============================] - 0s 12ms/step - loss: 0.0199\n",
            "Epoch 99/200\n",
            "19/19 [==============================] - 0s 12ms/step - loss: 0.0167\n",
            "Epoch 100/200\n",
            "19/19 [==============================] - 0s 11ms/step - loss: 0.0220\n",
            "Epoch 101/200\n",
            "19/19 [==============================] - 0s 12ms/step - loss: 0.0194\n",
            "Epoch 102/200\n",
            "19/19 [==============================] - 0s 12ms/step - loss: 0.0206\n",
            "Epoch 103/200\n",
            "19/19 [==============================] - 0s 12ms/step - loss: 0.0198\n",
            "Epoch 104/200\n",
            "19/19 [==============================] - 0s 11ms/step - loss: 0.0162\n",
            "Epoch 105/200\n",
            "19/19 [==============================] - 0s 12ms/step - loss: 0.0205\n",
            "Epoch 106/200\n",
            "19/19 [==============================] - 0s 12ms/step - loss: 0.0169\n",
            "Epoch 107/200\n",
            "19/19 [==============================] - 0s 19ms/step - loss: 0.0165\n",
            "Epoch 108/200\n",
            "19/19 [==============================] - 0s 20ms/step - loss: 0.0192\n",
            "Epoch 109/200\n",
            "19/19 [==============================] - 0s 21ms/step - loss: 0.0152\n",
            "Epoch 110/200\n",
            "19/19 [==============================] - 0s 20ms/step - loss: 0.0165\n",
            "Epoch 111/200\n",
            "19/19 [==============================] - 0s 21ms/step - loss: 0.0131\n",
            "Epoch 112/200\n",
            "19/19 [==============================] - 0s 21ms/step - loss: 0.0167\n",
            "Epoch 113/200\n",
            "19/19 [==============================] - 0s 22ms/step - loss: 0.0136\n",
            "Epoch 114/200\n",
            "19/19 [==============================] - 0s 20ms/step - loss: 0.0144\n",
            "Epoch 115/200\n",
            "19/19 [==============================] - 0s 20ms/step - loss: 0.0159\n",
            "Epoch 116/200\n",
            "19/19 [==============================] - 0s 22ms/step - loss: 0.0177\n",
            "Epoch 117/200\n",
            "19/19 [==============================] - 0s 14ms/step - loss: 0.0201\n",
            "Epoch 118/200\n",
            "19/19 [==============================] - 0s 12ms/step - loss: 0.0123\n",
            "Epoch 119/200\n",
            "19/19 [==============================] - 0s 12ms/step - loss: 0.0166\n",
            "Epoch 120/200\n",
            "19/19 [==============================] - 0s 12ms/step - loss: 0.0141\n",
            "Epoch 121/200\n",
            "19/19 [==============================] - 0s 12ms/step - loss: 0.0171\n",
            "Epoch 122/200\n",
            "19/19 [==============================] - 0s 11ms/step - loss: 0.0171\n",
            "Epoch 123/200\n",
            "19/19 [==============================] - 0s 12ms/step - loss: 0.0202\n",
            "Epoch 124/200\n",
            "19/19 [==============================] - 0s 12ms/step - loss: 0.0245\n",
            "Epoch 125/200\n",
            "19/19 [==============================] - 0s 12ms/step - loss: 0.0171\n",
            "Epoch 126/200\n",
            "19/19 [==============================] - 0s 12ms/step - loss: 0.0165\n",
            "Epoch 127/200\n",
            "19/19 [==============================] - 0s 11ms/step - loss: 0.0152\n",
            "Epoch 128/200\n",
            "19/19 [==============================] - 0s 13ms/step - loss: 0.0165\n",
            "Epoch 129/200\n",
            "19/19 [==============================] - 0s 12ms/step - loss: 0.0194\n",
            "Epoch 130/200\n",
            "19/19 [==============================] - 0s 11ms/step - loss: 0.0185\n",
            "Epoch 131/200\n",
            "19/19 [==============================] - 0s 12ms/step - loss: 0.0154\n",
            "Epoch 132/200\n",
            "19/19 [==============================] - 0s 12ms/step - loss: 0.0181\n",
            "Epoch 133/200\n",
            "19/19 [==============================] - 0s 12ms/step - loss: 0.0161\n",
            "Epoch 134/200\n",
            "19/19 [==============================] - 0s 12ms/step - loss: 0.0216\n",
            "Epoch 135/200\n",
            "19/19 [==============================] - 0s 11ms/step - loss: 0.0146\n",
            "Epoch 136/200\n",
            "19/19 [==============================] - 0s 12ms/step - loss: 0.0137\n",
            "Epoch 137/200\n",
            "19/19 [==============================] - 0s 13ms/step - loss: 0.0198\n",
            "Epoch 138/200\n",
            "19/19 [==============================] - 0s 12ms/step - loss: 0.0245\n",
            "Epoch 139/200\n",
            "19/19 [==============================] - 0s 11ms/step - loss: 0.0171\n",
            "Epoch 140/200\n",
            "19/19 [==============================] - 0s 11ms/step - loss: 0.0155\n",
            "Epoch 141/200\n",
            "19/19 [==============================] - 0s 12ms/step - loss: 0.0139\n",
            "Epoch 142/200\n",
            "19/19 [==============================] - 0s 11ms/step - loss: 0.0123\n",
            "Epoch 143/200\n",
            "19/19 [==============================] - 0s 12ms/step - loss: 0.0150\n",
            "Epoch 144/200\n",
            "19/19 [==============================] - 0s 12ms/step - loss: 0.0131\n",
            "Epoch 145/200\n",
            "19/19 [==============================] - 0s 11ms/step - loss: 0.0108\n",
            "Epoch 146/200\n",
            "19/19 [==============================] - 0s 13ms/step - loss: 0.0155\n",
            "Epoch 147/200\n",
            "19/19 [==============================] - 0s 11ms/step - loss: 0.0142\n",
            "Epoch 148/200\n",
            "19/19 [==============================] - 0s 11ms/step - loss: 0.0136\n",
            "Epoch 149/200\n",
            "19/19 [==============================] - 0s 13ms/step - loss: 0.0191\n",
            "Epoch 150/200\n",
            "19/19 [==============================] - 0s 13ms/step - loss: 0.0156\n",
            "Epoch 151/200\n",
            "19/19 [==============================] - 0s 12ms/step - loss: 0.0162\n",
            "Epoch 152/200\n",
            "19/19 [==============================] - 0s 11ms/step - loss: 0.0184\n",
            "Epoch 153/200\n",
            "19/19 [==============================] - 0s 12ms/step - loss: 0.0152\n",
            "Epoch 154/200\n",
            "19/19 [==============================] - 0s 13ms/step - loss: 0.0125\n",
            "Epoch 155/200\n",
            "19/19 [==============================] - 0s 12ms/step - loss: 0.0191\n",
            "Epoch 156/200\n",
            "19/19 [==============================] - 0s 12ms/step - loss: 0.0160\n",
            "Epoch 157/200\n",
            "19/19 [==============================] - 0s 12ms/step - loss: 0.0162\n",
            "Epoch 158/200\n",
            "19/19 [==============================] - 0s 12ms/step - loss: 0.0140\n",
            "Epoch 159/200\n",
            "19/19 [==============================] - 0s 13ms/step - loss: 0.0156\n",
            "Epoch 160/200\n",
            "19/19 [==============================] - 0s 21ms/step - loss: 0.0118\n",
            "Epoch 161/200\n",
            "19/19 [==============================] - 0s 20ms/step - loss: 0.0174\n",
            "Epoch 162/200\n",
            "19/19 [==============================] - 0s 21ms/step - loss: 0.0177\n",
            "Epoch 163/200\n",
            "19/19 [==============================] - 0s 20ms/step - loss: 0.0133\n",
            "Epoch 164/200\n",
            "19/19 [==============================] - 0s 21ms/step - loss: 0.0134\n",
            "Epoch 165/200\n",
            "19/19 [==============================] - 0s 20ms/step - loss: 0.0131\n",
            "Epoch 166/200\n",
            "19/19 [==============================] - 0s 21ms/step - loss: 0.0148\n",
            "Epoch 167/200\n",
            "19/19 [==============================] - 0s 21ms/step - loss: 0.0144\n",
            "Epoch 168/200\n",
            "19/19 [==============================] - 0s 20ms/step - loss: 0.0169\n",
            "Epoch 169/200\n",
            "19/19 [==============================] - 0s 22ms/step - loss: 0.0203\n",
            "Epoch 170/200\n",
            "19/19 [==============================] - 0s 13ms/step - loss: 0.0170\n",
            "Epoch 171/200\n",
            "19/19 [==============================] - 0s 12ms/step - loss: 0.0135\n",
            "Epoch 172/200\n",
            "19/19 [==============================] - 0s 12ms/step - loss: 0.0156\n",
            "Epoch 173/200\n",
            "19/19 [==============================] - 0s 12ms/step - loss: 0.0132\n",
            "Epoch 174/200\n",
            "19/19 [==============================] - 0s 13ms/step - loss: 0.0137\n",
            "Epoch 175/200\n",
            "19/19 [==============================] - 0s 12ms/step - loss: 0.0169\n",
            "Epoch 176/200\n",
            "19/19 [==============================] - 0s 12ms/step - loss: 0.0149\n",
            "Epoch 177/200\n",
            "19/19 [==============================] - 0s 12ms/step - loss: 0.0160\n",
            "Epoch 178/200\n",
            "19/19 [==============================] - 0s 13ms/step - loss: 0.0129\n",
            "Epoch 179/200\n",
            "19/19 [==============================] - 0s 12ms/step - loss: 0.0114\n",
            "Epoch 180/200\n",
            "19/19 [==============================] - 0s 12ms/step - loss: 0.0147\n",
            "Epoch 181/200\n",
            "19/19 [==============================] - 0s 12ms/step - loss: 0.0131\n",
            "Epoch 182/200\n",
            "19/19 [==============================] - 0s 12ms/step - loss: 0.0152\n",
            "Epoch 183/200\n",
            "19/19 [==============================] - 0s 12ms/step - loss: 0.0127\n",
            "Epoch 184/200\n",
            "19/19 [==============================] - 0s 12ms/step - loss: 0.0180\n",
            "Epoch 185/200\n",
            "19/19 [==============================] - 0s 12ms/step - loss: 0.0137\n",
            "Epoch 186/200\n",
            "19/19 [==============================] - 0s 12ms/step - loss: 0.0121\n",
            "Epoch 187/200\n",
            "19/19 [==============================] - 0s 13ms/step - loss: 0.0148\n",
            "Epoch 188/200\n",
            "19/19 [==============================] - 0s 12ms/step - loss: 0.0168\n",
            "Epoch 189/200\n",
            "19/19 [==============================] - 0s 12ms/step - loss: 0.0180\n",
            "Epoch 190/200\n",
            "19/19 [==============================] - 0s 12ms/step - loss: 0.0159\n",
            "Epoch 191/200\n",
            "19/19 [==============================] - 0s 12ms/step - loss: 0.0149\n",
            "Epoch 192/200\n",
            "19/19 [==============================] - 0s 12ms/step - loss: 0.0129\n",
            "Epoch 193/200\n",
            "19/19 [==============================] - 0s 12ms/step - loss: 0.0146\n",
            "Epoch 194/200\n",
            "19/19 [==============================] - 0s 12ms/step - loss: 0.0140\n",
            "Epoch 195/200\n",
            "19/19 [==============================] - 0s 11ms/step - loss: 0.0151\n",
            "Epoch 196/200\n",
            "19/19 [==============================] - 0s 13ms/step - loss: 0.0130\n",
            "Epoch 197/200\n",
            "19/19 [==============================] - 0s 12ms/step - loss: 0.0157\n",
            "Epoch 198/200\n",
            "19/19 [==============================] - 0s 12ms/step - loss: 0.0171\n",
            "Epoch 199/200\n",
            "19/19 [==============================] - 0s 12ms/step - loss: 0.0157\n",
            "Epoch 200/200\n",
            "19/19 [==============================] - 0s 13ms/step - loss: 0.0123\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Predicted prices from 2024-04-01 to 2028-12-01:\n",
            "2024-04-01: 2.674 (Lower Bound: 2.618, Upper Bound: 2.731)\n",
            "2024-05-01: 2.677 (Lower Bound: 2.621, Upper Bound: 2.733)\n",
            "2024-06-01: 2.669 (Lower Bound: 2.613, Upper Bound: 2.726)\n",
            "2024-07-01: 2.659 (Lower Bound: 2.602, Upper Bound: 2.715)\n",
            "2024-08-01: 2.651 (Lower Bound: 2.595, Upper Bound: 2.707)\n",
            "2024-09-01: 2.641 (Lower Bound: 2.585, Upper Bound: 2.698)\n",
            "2024-10-01: 2.633 (Lower Bound: 2.577, Upper Bound: 2.690)\n",
            "2024-11-01: 2.634 (Lower Bound: 2.578, Upper Bound: 2.691)\n",
            "2024-12-01: 2.639 (Lower Bound: 2.582, Upper Bound: 2.695)\n",
            "2025-01-01: 2.643 (Lower Bound: 2.586, Upper Bound: 2.699)\n",
            "2025-02-01: 2.647 (Lower Bound: 2.590, Upper Bound: 2.703)\n",
            "2025-03-01: 2.645 (Lower Bound: 2.588, Upper Bound: 2.701)\n",
            "2025-04-01: 2.642 (Lower Bound: 2.585, Upper Bound: 2.698)\n",
            "2025-05-01: 2.644 (Lower Bound: 2.587, Upper Bound: 2.700)\n",
            "2025-06-01: 2.649 (Lower Bound: 2.593, Upper Bound: 2.706)\n",
            "2025-07-01: 2.656 (Lower Bound: 2.600, Upper Bound: 2.713)\n",
            "2025-08-01: 2.665 (Lower Bound: 2.609, Upper Bound: 2.721)\n",
            "2025-09-01: 2.675 (Lower Bound: 2.619, Upper Bound: 2.732)\n",
            "2025-10-01: 2.687 (Lower Bound: 2.631, Upper Bound: 2.743)\n",
            "2025-11-01: 2.700 (Lower Bound: 2.644, Upper Bound: 2.757)\n",
            "2025-12-01: 2.715 (Lower Bound: 2.659, Upper Bound: 2.772)\n",
            "2026-01-01: 2.732 (Lower Bound: 2.675, Upper Bound: 2.788)\n",
            "2026-02-01: 2.749 (Lower Bound: 2.693, Upper Bound: 2.806)\n",
            "2026-03-01: 2.768 (Lower Bound: 2.712, Upper Bound: 2.825)\n",
            "2026-04-01: 2.789 (Lower Bound: 2.732, Upper Bound: 2.845)\n",
            "2026-05-01: 2.813 (Lower Bound: 2.756, Upper Bound: 2.869)\n",
            "2026-06-01: 2.799 (Lower Bound: 2.743, Upper Bound: 2.856)\n",
            "2026-07-01: 2.786 (Lower Bound: 2.729, Upper Bound: 2.842)\n",
            "2026-08-01: 2.756 (Lower Bound: 2.700, Upper Bound: 2.812)\n",
            "2026-09-01: 2.713 (Lower Bound: 2.656, Upper Bound: 2.769)\n",
            "2026-10-01: 2.669 (Lower Bound: 2.613, Upper Bound: 2.726)\n",
            "2026-11-01: 2.627 (Lower Bound: 2.570, Upper Bound: 2.683)\n",
            "2026-12-01: 2.584 (Lower Bound: 2.528, Upper Bound: 2.640)\n",
            "2027-01-01: 2.542 (Lower Bound: 2.485, Upper Bound: 2.598)\n",
            "2027-02-01: 2.500 (Lower Bound: 2.444, Upper Bound: 2.557)\n",
            "2027-03-01: 2.460 (Lower Bound: 2.403, Upper Bound: 2.516)\n",
            "2027-04-01: 2.423 (Lower Bound: 2.367, Upper Bound: 2.480)\n",
            "2027-05-01: 2.398 (Lower Bound: 2.341, Upper Bound: 2.454)\n",
            "2027-06-01: 2.374 (Lower Bound: 2.317, Upper Bound: 2.430)\n",
            "2027-07-01: 2.351 (Lower Bound: 2.295, Upper Bound: 2.408)\n",
            "2027-08-01: 2.330 (Lower Bound: 2.274, Upper Bound: 2.387)\n",
            "2027-09-01: 2.311 (Lower Bound: 2.254, Upper Bound: 2.367)\n",
            "2027-10-01: 2.292 (Lower Bound: 2.236, Upper Bound: 2.349)\n",
            "2027-11-01: 2.276 (Lower Bound: 2.219, Upper Bound: 2.332)\n",
            "2027-12-01: 2.260 (Lower Bound: 2.204, Upper Bound: 2.317)\n",
            "2028-01-01: 2.246 (Lower Bound: 2.190, Upper Bound: 2.302)\n",
            "2028-02-01: 2.206 (Lower Bound: 2.150, Upper Bound: 2.263)\n",
            "2028-03-01: 2.161 (Lower Bound: 2.105, Upper Bound: 2.218)\n",
            "2028-04-01: 2.117 (Lower Bound: 2.061, Upper Bound: 2.173)\n",
            "2028-05-01: 2.073 (Lower Bound: 2.017, Upper Bound: 2.129)\n",
            "2028-06-01: 2.030 (Lower Bound: 1.973, Upper Bound: 2.086)\n",
            "2028-07-01: 1.986 (Lower Bound: 1.930, Upper Bound: 2.043)\n",
            "2028-08-01: 1.943 (Lower Bound: 1.887, Upper Bound: 2.000)\n",
            "2028-09-01: 1.900 (Lower Bound: 1.844, Upper Bound: 1.957)\n",
            "2028-10-01: 1.864 (Lower Bound: 1.808, Upper Bound: 1.920)\n",
            "2028-11-01: 1.864 (Lower Bound: 1.808, Upper Bound: 1.920)\n",
            "2028-12-01: 1.864 (Lower Bound: 1.808, Upper Bound: 1.920)\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from datetime import datetime\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import LSTM, Dense, Dropout\n",
        "\n",
        "# Read the dataset\n",
        "df = pd.read_excel('LNG (High).xlsx')\n",
        "\n",
        "# Function to calculate the number of months between two dates\n",
        "def months_between(start_date, end_date):\n",
        "    start_date = datetime.strptime(start_date, \"%Y-%m-%d\")\n",
        "    end_date = datetime.strptime(end_date, \"%Y-%m-%d\")\n",
        "    return (end_date.year - start_date.year) * 12 + end_date.month - start_date.month + 1\n",
        "\n",
        "# Define the date range\n",
        "start_date = '2024-04-01'\n",
        "end_date = '2028-12-01'\n",
        "\n",
        "# Calculate the number of months to predict\n",
        "num_months = months_between(start_date, end_date)\n",
        "\n",
        "# Ensure data is sorted by date\n",
        "df['Date'] = pd.to_datetime(df['Date'], format='%b-%y')\n",
        "df = df.sort_values(by=\"Date\", ascending=True)\n",
        "\n",
        "# Normalize the data\n",
        "scaler = MinMaxScaler(feature_range=(0, 1))\n",
        "df['Price_normalized'] = scaler.fit_transform(df['Price'].values.reshape(-1,1))\n",
        "\n",
        "# Create a new feature representing the number of months since start date\n",
        "df['Months_since_start'] = (df['Date'] - pd.to_datetime(start_date)).dt.days / 30\n",
        "\n",
        "# Prepare data for training\n",
        "X_train = df['Months_since_start'].values.reshape(-1, 1, 1)\n",
        "y_train = df['Price_normalized'].values\n",
        "\n",
        "# Define and train the LSTM model with increased dropout rate\n",
        "model = Sequential()\n",
        "model.add(LSTM(256, activation='relu', return_sequences=True, input_shape=(1, 1)))\n",
        "model.add(Dropout(0.5))  # Increase dropout rate\n",
        "model.add(LSTM(128, activation='relu', return_sequences=True))\n",
        "model.add(Dropout(0.5))  # Increase dropout rate\n",
        "model.add(LSTM(64, activation='relu'))\n",
        "model.add(Dropout(0.5))  # Increase dropout rate\n",
        "model.add(Dense(32, activation='relu'))\n",
        "model.add(Dense(1, activation='relu'))\n",
        "model.compile(optimizer='adam', loss='mean_squared_error')\n",
        "model.fit(X_train, y_train, epochs=200, batch_size=8)\n",
        "\n",
        "# Generate future indices for prediction\n",
        "X_future = np.arange(df['Months_since_start'].iloc[-1] + 1, df['Months_since_start'].iloc[-1] + 1 + num_months)\n",
        "X_future = X_future.reshape(-1, 1, 1)  # Reshape for LSTM input\n",
        "\n",
        "# Generate predictions\n",
        "y_pred_normalized = model.predict(X_future)\n",
        "\n",
        "# Inverse transform predictions to get actual prices\n",
        "y_pred = scaler.inverse_transform(y_pred_normalized)\n",
        "\n",
        "# Ensure predictions are non-negative\n",
        "y_pred = np.maximum(y_pred, 0)\n",
        "\n",
        "# Compute confidence interval bounds\n",
        "confidence_level = 0.80  # Set confidence level\n",
        "z_score = 1.645  # Z-score for 80% confidence level (corresponds to wider interval)\n",
        "std_dev = np.std(y_pred_normalized)  # Compute standard deviation\n",
        "margin_of_error = z_score * std_dev  # Margin of error\n",
        "lower_bound = y_pred - margin_of_error\n",
        "upper_bound = y_pred + margin_of_error\n",
        "\n",
        "# Generate date range for the predictions\n",
        "dates = pd.date_range(start=start_date, periods=num_months, freq='MS')\n",
        "\n",
        "# Print predicted prices with corresponding dates and confidence intervals\n",
        "print(\"Predicted prices from 2024-04-01 to 2028-12-01:\")\n",
        "for date, pred, lower, upper in zip(dates, y_pred.flatten(), lower_bound.flatten(), upper_bound.flatten()):\n",
        "    print(f\"{date.strftime('%Y-%m-%d')}: {pred:.3f} (Lower Bound: {lower:.3f}, Upper Bound: {upper:.3f})\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OERjJDfoFEQY",
        "outputId": "6c542220-2f95-4967-a9b0-64dff0a1cb98"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/200\n",
            "19/19 [==============================] - 8s 23ms/step - loss: 0.0755\n",
            "Epoch 2/200\n",
            "19/19 [==============================] - 0s 22ms/step - loss: 0.0540\n",
            "Epoch 3/200\n",
            "19/19 [==============================] - 0s 22ms/step - loss: 0.0454\n",
            "Epoch 4/200\n",
            "19/19 [==============================] - 0s 22ms/step - loss: 0.0441\n",
            "Epoch 5/200\n",
            "19/19 [==============================] - 0s 22ms/step - loss: 0.0399\n",
            "Epoch 6/200\n",
            "19/19 [==============================] - 0s 22ms/step - loss: 0.0376\n",
            "Epoch 7/200\n",
            "19/19 [==============================] - 0s 21ms/step - loss: 0.0349\n",
            "Epoch 8/200\n",
            "19/19 [==============================] - 0s 22ms/step - loss: 0.0350\n",
            "Epoch 9/200\n",
            "19/19 [==============================] - 0s 21ms/step - loss: 0.0293\n",
            "Epoch 10/200\n",
            "19/19 [==============================] - 0s 20ms/step - loss: 0.0306\n",
            "Epoch 11/200\n",
            "19/19 [==============================] - 0s 14ms/step - loss: 0.0319\n",
            "Epoch 12/200\n",
            "19/19 [==============================] - 0s 11ms/step - loss: 0.0275\n",
            "Epoch 13/200\n",
            "19/19 [==============================] - 0s 11ms/step - loss: 0.0330\n",
            "Epoch 14/200\n",
            "19/19 [==============================] - 0s 12ms/step - loss: 0.0281\n",
            "Epoch 15/200\n",
            "19/19 [==============================] - 0s 18ms/step - loss: 0.0342\n",
            "Epoch 16/200\n",
            "19/19 [==============================] - 0s 25ms/step - loss: 0.0297\n",
            "Epoch 17/200\n",
            "19/19 [==============================] - 0s 21ms/step - loss: 0.0312\n",
            "Epoch 18/200\n",
            "19/19 [==============================] - 0s 20ms/step - loss: 0.0263\n",
            "Epoch 19/200\n",
            "19/19 [==============================] - 0s 20ms/step - loss: 0.0296\n",
            "Epoch 20/200\n",
            "19/19 [==============================] - 0s 21ms/step - loss: 0.0302\n",
            "Epoch 21/200\n",
            "19/19 [==============================] - 0s 21ms/step - loss: 0.0249\n",
            "Epoch 22/200\n",
            "19/19 [==============================] - 0s 21ms/step - loss: 0.0267\n",
            "Epoch 23/200\n",
            "19/19 [==============================] - 0s 20ms/step - loss: 0.0270\n",
            "Epoch 24/200\n",
            "19/19 [==============================] - 0s 20ms/step - loss: 0.0277\n",
            "Epoch 25/200\n",
            "19/19 [==============================] - 0s 17ms/step - loss: 0.0192\n",
            "Epoch 26/200\n",
            "19/19 [==============================] - 0s 12ms/step - loss: 0.0291\n",
            "Epoch 27/200\n",
            "19/19 [==============================] - 0s 11ms/step - loss: 0.0246\n",
            "Epoch 28/200\n",
            "19/19 [==============================] - 0s 11ms/step - loss: 0.0252\n",
            "Epoch 29/200\n",
            "19/19 [==============================] - 0s 12ms/step - loss: 0.0240\n",
            "Epoch 30/200\n",
            "19/19 [==============================] - 0s 11ms/step - loss: 0.0337\n",
            "Epoch 31/200\n",
            "19/19 [==============================] - 0s 12ms/step - loss: 0.0275\n",
            "Epoch 32/200\n",
            "19/19 [==============================] - 0s 11ms/step - loss: 0.0243\n",
            "Epoch 33/200\n",
            "19/19 [==============================] - 0s 11ms/step - loss: 0.0247\n",
            "Epoch 34/200\n",
            "19/19 [==============================] - 0s 11ms/step - loss: 0.0329\n",
            "Epoch 35/200\n",
            "19/19 [==============================] - 0s 11ms/step - loss: 0.0303\n",
            "Epoch 36/200\n",
            "19/19 [==============================] - 0s 12ms/step - loss: 0.0260\n",
            "Epoch 37/200\n",
            "19/19 [==============================] - 0s 11ms/step - loss: 0.0273\n",
            "Epoch 38/200\n",
            "19/19 [==============================] - 0s 12ms/step - loss: 0.0278\n",
            "Epoch 39/200\n",
            "19/19 [==============================] - 0s 12ms/step - loss: 0.0241\n",
            "Epoch 40/200\n",
            "19/19 [==============================] - 0s 12ms/step - loss: 0.0290\n",
            "Epoch 41/200\n",
            "19/19 [==============================] - 0s 12ms/step - loss: 0.0282\n",
            "Epoch 42/200\n",
            "19/19 [==============================] - 0s 12ms/step - loss: 0.0265\n",
            "Epoch 43/200\n",
            "19/19 [==============================] - 0s 11ms/step - loss: 0.0246\n",
            "Epoch 44/200\n",
            "19/19 [==============================] - 0s 11ms/step - loss: 0.0287\n",
            "Epoch 45/200\n",
            "19/19 [==============================] - 0s 12ms/step - loss: 0.0232\n",
            "Epoch 46/200\n",
            "19/19 [==============================] - 0s 11ms/step - loss: 0.0257\n",
            "Epoch 47/200\n",
            "19/19 [==============================] - 0s 11ms/step - loss: 0.0254\n",
            "Epoch 48/200\n",
            "19/19 [==============================] - 0s 11ms/step - loss: 0.0257\n",
            "Epoch 49/200\n",
            "19/19 [==============================] - 0s 12ms/step - loss: 0.0292\n",
            "Epoch 50/200\n",
            "19/19 [==============================] - 0s 12ms/step - loss: 0.0255\n",
            "Epoch 51/200\n",
            "19/19 [==============================] - 0s 11ms/step - loss: 0.0217\n",
            "Epoch 52/200\n",
            "19/19 [==============================] - 0s 11ms/step - loss: 0.0276\n",
            "Epoch 53/200\n",
            "19/19 [==============================] - 0s 11ms/step - loss: 0.0273\n",
            "Epoch 54/200\n",
            "19/19 [==============================] - 0s 13ms/step - loss: 0.0256\n",
            "Epoch 55/200\n",
            "19/19 [==============================] - 0s 12ms/step - loss: 0.0314\n",
            "Epoch 56/200\n",
            "19/19 [==============================] - 0s 12ms/step - loss: 0.0239\n",
            "Epoch 57/200\n",
            "19/19 [==============================] - 0s 11ms/step - loss: 0.0214\n",
            "Epoch 58/200\n",
            "19/19 [==============================] - 0s 12ms/step - loss: 0.0183\n",
            "Epoch 59/200\n",
            "19/19 [==============================] - 0s 12ms/step - loss: 0.0292\n",
            "Epoch 60/200\n",
            "19/19 [==============================] - 0s 11ms/step - loss: 0.0177\n",
            "Epoch 61/200\n",
            "19/19 [==============================] - 0s 12ms/step - loss: 0.0266\n",
            "Epoch 62/200\n",
            "19/19 [==============================] - 0s 11ms/step - loss: 0.0244\n",
            "Epoch 63/200\n",
            "19/19 [==============================] - 0s 12ms/step - loss: 0.0206\n",
            "Epoch 64/200\n",
            "19/19 [==============================] - 0s 11ms/step - loss: 0.0204\n",
            "Epoch 65/200\n",
            "19/19 [==============================] - 0s 11ms/step - loss: 0.0299\n",
            "Epoch 66/200\n",
            "19/19 [==============================] - 0s 11ms/step - loss: 0.0270\n",
            "Epoch 67/200\n",
            "19/19 [==============================] - 0s 12ms/step - loss: 0.0228\n",
            "Epoch 68/200\n",
            "19/19 [==============================] - 0s 11ms/step - loss: 0.0211\n",
            "Epoch 69/200\n",
            "19/19 [==============================] - 0s 15ms/step - loss: 0.0245\n",
            "Epoch 70/200\n",
            "19/19 [==============================] - 0s 18ms/step - loss: 0.0201\n",
            "Epoch 71/200\n",
            "19/19 [==============================] - 0s 20ms/step - loss: 0.0269\n",
            "Epoch 72/200\n",
            "19/19 [==============================] - 0s 20ms/step - loss: 0.0202\n",
            "Epoch 73/200\n",
            "19/19 [==============================] - 0s 20ms/step - loss: 0.0200\n",
            "Epoch 74/200\n",
            "19/19 [==============================] - 0s 21ms/step - loss: 0.0234\n",
            "Epoch 75/200\n",
            "19/19 [==============================] - 0s 20ms/step - loss: 0.0263\n",
            "Epoch 76/200\n",
            "19/19 [==============================] - 0s 21ms/step - loss: 0.0258\n",
            "Epoch 77/200\n",
            "19/19 [==============================] - 0s 21ms/step - loss: 0.0229\n",
            "Epoch 78/200\n",
            "19/19 [==============================] - 0s 21ms/step - loss: 0.0256\n",
            "Epoch 79/200\n",
            "19/19 [==============================] - 0s 21ms/step - loss: 0.0254\n",
            "Epoch 80/200\n",
            "19/19 [==============================] - 0s 11ms/step - loss: 0.0181\n",
            "Epoch 81/200\n",
            "19/19 [==============================] - 0s 11ms/step - loss: 0.0239\n",
            "Epoch 82/200\n",
            "19/19 [==============================] - 0s 11ms/step - loss: 0.0219\n",
            "Epoch 83/200\n",
            "19/19 [==============================] - 0s 13ms/step - loss: 0.0251\n",
            "Epoch 84/200\n",
            "19/19 [==============================] - 0s 11ms/step - loss: 0.0216\n",
            "Epoch 85/200\n",
            "19/19 [==============================] - 0s 11ms/step - loss: 0.0274\n",
            "Epoch 86/200\n",
            "19/19 [==============================] - 0s 11ms/step - loss: 0.0190\n",
            "Epoch 87/200\n",
            "19/19 [==============================] - 0s 12ms/step - loss: 0.0266\n",
            "Epoch 88/200\n",
            "19/19 [==============================] - 0s 11ms/step - loss: 0.0265\n",
            "Epoch 89/200\n",
            "19/19 [==============================] - 0s 11ms/step - loss: 0.0181\n",
            "Epoch 90/200\n",
            "19/19 [==============================] - 0s 11ms/step - loss: 0.0217\n",
            "Epoch 91/200\n",
            "19/19 [==============================] - 0s 12ms/step - loss: 0.0179\n",
            "Epoch 92/200\n",
            "19/19 [==============================] - 0s 12ms/step - loss: 0.0226\n",
            "Epoch 93/200\n",
            "19/19 [==============================] - 0s 12ms/step - loss: 0.0242\n",
            "Epoch 94/200\n",
            "19/19 [==============================] - 0s 11ms/step - loss: 0.0184\n",
            "Epoch 95/200\n",
            "19/19 [==============================] - 0s 11ms/step - loss: 0.0254\n",
            "Epoch 96/200\n",
            "19/19 [==============================] - 0s 12ms/step - loss: 0.0163\n",
            "Epoch 97/200\n",
            "19/19 [==============================] - 0s 11ms/step - loss: 0.0176\n",
            "Epoch 98/200\n",
            "19/19 [==============================] - 0s 11ms/step - loss: 0.0160\n",
            "Epoch 99/200\n",
            "19/19 [==============================] - 0s 11ms/step - loss: 0.0197\n",
            "Epoch 100/200\n",
            "19/19 [==============================] - 0s 12ms/step - loss: 0.0195\n",
            "Epoch 101/200\n",
            "19/19 [==============================] - 0s 12ms/step - loss: 0.0204\n",
            "Epoch 102/200\n",
            "19/19 [==============================] - 0s 11ms/step - loss: 0.0175\n",
            "Epoch 103/200\n",
            "19/19 [==============================] - 0s 11ms/step - loss: 0.0208\n",
            "Epoch 104/200\n",
            "19/19 [==============================] - 0s 12ms/step - loss: 0.0197\n",
            "Epoch 105/200\n",
            "19/19 [==============================] - 0s 11ms/step - loss: 0.0225\n",
            "Epoch 106/200\n",
            "19/19 [==============================] - 0s 12ms/step - loss: 0.0180\n",
            "Epoch 107/200\n",
            "19/19 [==============================] - 0s 12ms/step - loss: 0.0178\n",
            "Epoch 108/200\n",
            "19/19 [==============================] - 0s 11ms/step - loss: 0.0211\n",
            "Epoch 109/200\n",
            "19/19 [==============================] - 0s 12ms/step - loss: 0.0213\n",
            "Epoch 110/200\n",
            "19/19 [==============================] - 0s 12ms/step - loss: 0.0180\n",
            "Epoch 111/200\n",
            "19/19 [==============================] - 0s 12ms/step - loss: 0.0191\n",
            "Epoch 112/200\n",
            "19/19 [==============================] - 0s 12ms/step - loss: 0.0175\n",
            "Epoch 113/200\n",
            "19/19 [==============================] - 0s 12ms/step - loss: 0.0176\n",
            "Epoch 114/200\n",
            "19/19 [==============================] - 0s 11ms/step - loss: 0.0236\n",
            "Epoch 115/200\n",
            "19/19 [==============================] - 0s 12ms/step - loss: 0.0197\n",
            "Epoch 116/200\n",
            "19/19 [==============================] - 0s 11ms/step - loss: 0.0173\n",
            "Epoch 117/200\n",
            "19/19 [==============================] - 0s 12ms/step - loss: 0.0162\n",
            "Epoch 118/200\n",
            "19/19 [==============================] - 0s 12ms/step - loss: 0.0169\n",
            "Epoch 119/200\n",
            "19/19 [==============================] - 0s 13ms/step - loss: 0.0175\n",
            "Epoch 120/200\n",
            "19/19 [==============================] - 0s 11ms/step - loss: 0.0151\n",
            "Epoch 121/200\n",
            "19/19 [==============================] - 0s 12ms/step - loss: 0.0170\n",
            "Epoch 122/200\n",
            "19/19 [==============================] - 0s 11ms/step - loss: 0.0146\n",
            "Epoch 123/200\n",
            "19/19 [==============================] - 0s 14ms/step - loss: 0.0199\n",
            "Epoch 124/200\n",
            "19/19 [==============================] - 0s 20ms/step - loss: 0.0164\n",
            "Epoch 125/200\n",
            "19/19 [==============================] - 0s 20ms/step - loss: 0.0205\n",
            "Epoch 126/200\n",
            "19/19 [==============================] - 0s 20ms/step - loss: 0.0228\n",
            "Epoch 127/200\n",
            "19/19 [==============================] - 0s 19ms/step - loss: 0.0188\n",
            "Epoch 128/200\n",
            "19/19 [==============================] - 0s 20ms/step - loss: 0.0181\n",
            "Epoch 129/200\n",
            "19/19 [==============================] - 0s 20ms/step - loss: 0.0181\n",
            "Epoch 130/200\n",
            "19/19 [==============================] - 0s 20ms/step - loss: 0.0176\n",
            "Epoch 131/200\n",
            "19/19 [==============================] - 0s 21ms/step - loss: 0.0133\n",
            "Epoch 132/200\n",
            "19/19 [==============================] - 0s 21ms/step - loss: 0.0156\n",
            "Epoch 133/200\n",
            "19/19 [==============================] - 0s 20ms/step - loss: 0.0165\n",
            "Epoch 134/200\n",
            "19/19 [==============================] - 0s 16ms/step - loss: 0.0205\n",
            "Epoch 135/200\n",
            "19/19 [==============================] - 0s 12ms/step - loss: 0.0181\n",
            "Epoch 136/200\n",
            "19/19 [==============================] - 0s 12ms/step - loss: 0.0154\n",
            "Epoch 137/200\n",
            "19/19 [==============================] - 0s 12ms/step - loss: 0.0177\n",
            "Epoch 138/200\n",
            "19/19 [==============================] - 0s 13ms/step - loss: 0.0175\n",
            "Epoch 139/200\n",
            "19/19 [==============================] - 0s 12ms/step - loss: 0.0179\n",
            "Epoch 140/200\n",
            "19/19 [==============================] - 0s 11ms/step - loss: 0.0167\n",
            "Epoch 141/200\n",
            "19/19 [==============================] - 0s 12ms/step - loss: 0.0190\n",
            "Epoch 142/200\n",
            "19/19 [==============================] - 0s 12ms/step - loss: 0.0165\n",
            "Epoch 143/200\n",
            "19/19 [==============================] - 0s 11ms/step - loss: 0.0157\n",
            "Epoch 144/200\n",
            "19/19 [==============================] - 0s 12ms/step - loss: 0.0167\n",
            "Epoch 145/200\n",
            "19/19 [==============================] - 0s 12ms/step - loss: 0.0163\n",
            "Epoch 146/200\n",
            "19/19 [==============================] - 0s 11ms/step - loss: 0.0148\n",
            "Epoch 147/200\n",
            "19/19 [==============================] - 0s 12ms/step - loss: 0.0163\n",
            "Epoch 148/200\n",
            "19/19 [==============================] - 0s 12ms/step - loss: 0.0172\n",
            "Epoch 149/200\n",
            "19/19 [==============================] - 0s 11ms/step - loss: 0.0201\n",
            "Epoch 150/200\n",
            "19/19 [==============================] - 0s 12ms/step - loss: 0.0174\n",
            "Epoch 151/200\n",
            "19/19 [==============================] - 0s 12ms/step - loss: 0.0141\n",
            "Epoch 152/200\n",
            "19/19 [==============================] - 0s 11ms/step - loss: 0.0190\n",
            "Epoch 153/200\n",
            "19/19 [==============================] - 0s 12ms/step - loss: 0.0205\n",
            "Epoch 154/200\n",
            "19/19 [==============================] - 0s 12ms/step - loss: 0.0150\n",
            "Epoch 155/200\n",
            "19/19 [==============================] - 0s 11ms/step - loss: 0.0162\n",
            "Epoch 156/200\n",
            "19/19 [==============================] - 0s 11ms/step - loss: 0.0174\n",
            "Epoch 157/200\n",
            "19/19 [==============================] - 0s 12ms/step - loss: 0.0150\n",
            "Epoch 158/200\n",
            "19/19 [==============================] - 0s 12ms/step - loss: 0.0185\n",
            "Epoch 159/200\n",
            "19/19 [==============================] - 0s 12ms/step - loss: 0.0163\n",
            "Epoch 160/200\n",
            "19/19 [==============================] - 0s 11ms/step - loss: 0.0127\n",
            "Epoch 161/200\n",
            "19/19 [==============================] - 0s 11ms/step - loss: 0.0159\n",
            "Epoch 162/200\n",
            "19/19 [==============================] - 0s 12ms/step - loss: 0.0187\n",
            "Epoch 163/200\n",
            "19/19 [==============================] - 0s 12ms/step - loss: 0.0175\n",
            "Epoch 164/200\n",
            "19/19 [==============================] - 0s 12ms/step - loss: 0.0140\n",
            "Epoch 165/200\n",
            "19/19 [==============================] - 0s 11ms/step - loss: 0.0173\n",
            "Epoch 166/200\n",
            "19/19 [==============================] - 0s 13ms/step - loss: 0.0167\n",
            "Epoch 167/200\n",
            "19/19 [==============================] - 0s 12ms/step - loss: 0.0194\n",
            "Epoch 168/200\n",
            "19/19 [==============================] - 0s 12ms/step - loss: 0.0198\n",
            "Epoch 169/200\n",
            "19/19 [==============================] - 0s 12ms/step - loss: 0.0170\n",
            "Epoch 170/200\n",
            "19/19 [==============================] - 0s 11ms/step - loss: 0.0155\n",
            "Epoch 171/200\n",
            "19/19 [==============================] - 0s 13ms/step - loss: 0.0139\n",
            "Epoch 172/200\n",
            "19/19 [==============================] - 0s 12ms/step - loss: 0.0171\n",
            "Epoch 173/200\n",
            "19/19 [==============================] - 0s 11ms/step - loss: 0.0119\n",
            "Epoch 174/200\n",
            "19/19 [==============================] - 0s 11ms/step - loss: 0.0114\n",
            "Epoch 175/200\n",
            "19/19 [==============================] - 0s 13ms/step - loss: 0.0181\n",
            "Epoch 176/200\n",
            "19/19 [==============================] - 0s 12ms/step - loss: 0.0123\n",
            "Epoch 177/200\n",
            "19/19 [==============================] - 0s 13ms/step - loss: 0.0151\n",
            "Epoch 178/200\n",
            "19/19 [==============================] - 0s 20ms/step - loss: 0.0173\n",
            "Epoch 179/200\n",
            "19/19 [==============================] - 0s 20ms/step - loss: 0.0169\n",
            "Epoch 180/200\n",
            "19/19 [==============================] - 0s 19ms/step - loss: 0.0196\n",
            "Epoch 181/200\n",
            "19/19 [==============================] - 0s 20ms/step - loss: 0.0159\n",
            "Epoch 182/200\n",
            "19/19 [==============================] - 0s 21ms/step - loss: 0.0150\n",
            "Epoch 183/200\n",
            "19/19 [==============================] - 0s 20ms/step - loss: 0.0146\n",
            "Epoch 184/200\n",
            "19/19 [==============================] - 0s 21ms/step - loss: 0.0146\n",
            "Epoch 185/200\n",
            "19/19 [==============================] - 0s 22ms/step - loss: 0.0163\n",
            "Epoch 186/200\n",
            "19/19 [==============================] - 0s 20ms/step - loss: 0.0154\n",
            "Epoch 187/200\n",
            "19/19 [==============================] - 0s 12ms/step - loss: 0.0150\n",
            "Epoch 188/200\n",
            "19/19 [==============================] - 0s 11ms/step - loss: 0.0153\n",
            "Epoch 189/200\n",
            "19/19 [==============================] - 0s 11ms/step - loss: 0.0154\n",
            "Epoch 190/200\n",
            "19/19 [==============================] - 0s 11ms/step - loss: 0.0147\n",
            "Epoch 191/200\n",
            "19/19 [==============================] - 0s 13ms/step - loss: 0.0122\n",
            "Epoch 192/200\n",
            "19/19 [==============================] - 0s 12ms/step - loss: 0.0160\n",
            "Epoch 193/200\n",
            "19/19 [==============================] - 0s 12ms/step - loss: 0.0184\n",
            "Epoch 194/200\n",
            "19/19 [==============================] - 0s 11ms/step - loss: 0.0128\n",
            "Epoch 195/200\n",
            "19/19 [==============================] - 0s 12ms/step - loss: 0.0135\n",
            "Epoch 196/200\n",
            "19/19 [==============================] - 0s 13ms/step - loss: 0.0166\n",
            "Epoch 197/200\n",
            "19/19 [==============================] - 0s 11ms/step - loss: 0.0166\n",
            "Epoch 198/200\n",
            "19/19 [==============================] - 0s 11ms/step - loss: 0.0146\n",
            "Epoch 199/200\n",
            "19/19 [==============================] - 0s 12ms/step - loss: 0.0145\n",
            "Epoch 200/200\n",
            "19/19 [==============================] - 0s 12ms/step - loss: 0.0140\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Predicted prices from 2024-04-01 to 2028-12-01:\n",
            "2024-04-01: 2.662 (Lower Bound: 2.626, Upper Bound: 2.698)\n",
            "2024-05-01: 2.660 (Lower Bound: 2.624, Upper Bound: 2.696)\n",
            "2024-06-01: 2.658 (Lower Bound: 2.622, Upper Bound: 2.694)\n",
            "2024-07-01: 2.655 (Lower Bound: 2.619, Upper Bound: 2.691)\n",
            "2024-08-01: 2.653 (Lower Bound: 2.617, Upper Bound: 2.689)\n",
            "2024-09-01: 2.652 (Lower Bound: 2.616, Upper Bound: 2.688)\n",
            "2024-10-01: 2.650 (Lower Bound: 2.614, Upper Bound: 2.686)\n",
            "2024-11-01: 2.648 (Lower Bound: 2.612, Upper Bound: 2.684)\n",
            "2024-12-01: 2.647 (Lower Bound: 2.611, Upper Bound: 2.683)\n",
            "2025-01-01: 2.647 (Lower Bound: 2.611, Upper Bound: 2.683)\n",
            "2025-02-01: 2.647 (Lower Bound: 2.611, Upper Bound: 2.683)\n",
            "2025-03-01: 2.647 (Lower Bound: 2.611, Upper Bound: 2.683)\n",
            "2025-04-01: 2.646 (Lower Bound: 2.610, Upper Bound: 2.682)\n",
            "2025-05-01: 2.646 (Lower Bound: 2.610, Upper Bound: 2.682)\n",
            "2025-06-01: 2.646 (Lower Bound: 2.610, Upper Bound: 2.682)\n",
            "2025-07-01: 2.645 (Lower Bound: 2.609, Upper Bound: 2.681)\n",
            "2025-08-01: 2.645 (Lower Bound: 2.609, Upper Bound: 2.681)\n",
            "2025-09-01: 2.644 (Lower Bound: 2.608, Upper Bound: 2.680)\n",
            "2025-10-01: 2.643 (Lower Bound: 2.607, Upper Bound: 2.679)\n",
            "2025-11-01: 2.643 (Lower Bound: 2.607, Upper Bound: 2.679)\n",
            "2025-12-01: 2.642 (Lower Bound: 2.606, Upper Bound: 2.678)\n",
            "2026-01-01: 2.641 (Lower Bound: 2.605, Upper Bound: 2.677)\n",
            "2026-02-01: 2.640 (Lower Bound: 2.604, Upper Bound: 2.676)\n",
            "2026-03-01: 2.635 (Lower Bound: 2.599, Upper Bound: 2.671)\n",
            "2026-04-01: 2.628 (Lower Bound: 2.592, Upper Bound: 2.664)\n",
            "2026-05-01: 2.621 (Lower Bound: 2.585, Upper Bound: 2.657)\n",
            "2026-06-01: 2.613 (Lower Bound: 2.577, Upper Bound: 2.649)\n",
            "2026-07-01: 2.605 (Lower Bound: 2.569, Upper Bound: 2.641)\n",
            "2026-08-01: 2.596 (Lower Bound: 2.560, Upper Bound: 2.632)\n",
            "2026-09-01: 2.588 (Lower Bound: 2.552, Upper Bound: 2.624)\n",
            "2026-10-01: 2.581 (Lower Bound: 2.545, Upper Bound: 2.617)\n",
            "2026-11-01: 2.574 (Lower Bound: 2.538, Upper Bound: 2.610)\n",
            "2026-12-01: 2.568 (Lower Bound: 2.532, Upper Bound: 2.604)\n",
            "2027-01-01: 2.565 (Lower Bound: 2.529, Upper Bound: 2.601)\n",
            "2027-02-01: 2.563 (Lower Bound: 2.527, Upper Bound: 2.599)\n",
            "2027-03-01: 2.562 (Lower Bound: 2.526, Upper Bound: 2.598)\n",
            "2027-04-01: 2.560 (Lower Bound: 2.524, Upper Bound: 2.596)\n",
            "2027-05-01: 2.558 (Lower Bound: 2.522, Upper Bound: 2.594)\n",
            "2027-06-01: 2.556 (Lower Bound: 2.520, Upper Bound: 2.592)\n",
            "2027-07-01: 2.554 (Lower Bound: 2.518, Upper Bound: 2.590)\n",
            "2027-08-01: 2.552 (Lower Bound: 2.516, Upper Bound: 2.588)\n",
            "2027-09-01: 2.550 (Lower Bound: 2.514, Upper Bound: 2.586)\n",
            "2027-10-01: 2.546 (Lower Bound: 2.510, Upper Bound: 2.582)\n",
            "2027-11-01: 2.537 (Lower Bound: 2.501, Upper Bound: 2.573)\n",
            "2027-12-01: 2.529 (Lower Bound: 2.493, Upper Bound: 2.565)\n",
            "2028-01-01: 2.520 (Lower Bound: 2.484, Upper Bound: 2.556)\n",
            "2028-02-01: 2.512 (Lower Bound: 2.476, Upper Bound: 2.548)\n",
            "2028-03-01: 2.504 (Lower Bound: 2.468, Upper Bound: 2.540)\n",
            "2028-04-01: 2.496 (Lower Bound: 2.460, Upper Bound: 2.532)\n",
            "2028-05-01: 2.487 (Lower Bound: 2.451, Upper Bound: 2.523)\n",
            "2028-06-01: 2.479 (Lower Bound: 2.443, Upper Bound: 2.515)\n",
            "2028-07-01: 2.470 (Lower Bound: 2.434, Upper Bound: 2.506)\n",
            "2028-08-01: 2.461 (Lower Bound: 2.425, Upper Bound: 2.497)\n",
            "2028-09-01: 2.453 (Lower Bound: 2.417, Upper Bound: 2.488)\n",
            "2028-10-01: 2.444 (Lower Bound: 2.408, Upper Bound: 2.480)\n",
            "2028-11-01: 2.435 (Lower Bound: 2.399, Upper Bound: 2.470)\n",
            "2028-12-01: 2.425 (Lower Bound: 2.389, Upper Bound: 2.461)\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from datetime import datetime\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import LSTM, Dense, Dropout\n",
        "\n",
        "# Read the dataset\n",
        "df = pd.read_excel('LNG (High).xlsx')\n",
        "\n",
        "# Function to calculate the number of months between two dates\n",
        "def months_between(start_date, end_date):\n",
        "    start_date = datetime.strptime(start_date, \"%Y-%m-%d\")\n",
        "    end_date = datetime.strptime(end_date, \"%Y-%m-%d\")\n",
        "    return (end_date.year - start_date.year) * 12 + end_date.month - start_date.month + 1\n",
        "\n",
        "# Define the date range\n",
        "start_date = '2024-04-01'\n",
        "end_date = '2028-12-01'\n",
        "\n",
        "# Calculate the number of months to predict\n",
        "num_months = months_between(start_date, end_date)\n",
        "\n",
        "# Ensure data is sorted by date\n",
        "df['Date'] = pd.to_datetime(df['Date'], format='%b-%y')\n",
        "df = df.sort_values(by=\"Date\", ascending=True)\n",
        "\n",
        "# Normalize the data\n",
        "scaler = MinMaxScaler(feature_range=(0, 1))\n",
        "df['Price_normalized'] = scaler.fit_transform(df['Price'].values.reshape(-1,1))\n",
        "\n",
        "# Create a new feature representing the number of months since start date\n",
        "df['Months_since_start'] = (df['Date'] - pd.to_datetime(start_date)).dt.days / 30\n",
        "\n",
        "# Prepare data for training\n",
        "X_train = df['Months_since_start'].values.reshape(-1, 1, 1)\n",
        "y_train = df['Price_normalized'].values\n",
        "\n",
        "# Define and train the LSTM model with increased dropout rate\n",
        "model = Sequential()\n",
        "model.add(LSTM(256, activation='relu', return_sequences=True, input_shape=(1, 1)))\n",
        "model.add(Dropout(0.5))  # Increase dropout rate\n",
        "model.add(LSTM(128, activation='relu', return_sequences=True))\n",
        "model.add(Dropout(0.5))  # Increase dropout rate\n",
        "model.add(LSTM(64, activation='relu'))\n",
        "model.add(Dropout(0.5))  # Increase dropout rate\n",
        "model.add(Dense(32, activation='relu'))\n",
        "model.add(Dense(1, activation='relu'))\n",
        "model.compile(optimizer='adam', loss='mean_squared_error')\n",
        "model.fit(X_train, y_train, epochs=200, batch_size=8)\n",
        "\n",
        "# Generate future indices for prediction\n",
        "X_future = np.arange(df['Months_since_start'].iloc[-1] + 1, df['Months_since_start'].iloc[-1] + 1 + num_months)\n",
        "X_future = X_future.reshape(-1, 1, 1)  # Reshape for LSTM input\n",
        "\n",
        "# Generate predictions\n",
        "y_pred_normalized = model.predict(X_future)\n",
        "\n",
        "# Inverse transform predictions to get actual prices\n",
        "y_pred = scaler.inverse_transform(y_pred_normalized)\n",
        "\n",
        "# Ensure predictions are non-negative\n",
        "y_pred = np.maximum(y_pred, 0)\n",
        "\n",
        "# Compute confidence interval bounds\n",
        "confidence_level = 0.80  # Set confidence level\n",
        "z_score = 4.25  # Adjusted z-score for wider interval\n",
        "std_dev = np.std(y_pred_normalized)  # Compute standard deviation\n",
        "margin_of_error = z_score * std_dev  # Margin of error\n",
        "lower_bound = y_pred - margin_of_error\n",
        "upper_bound = y_pred + margin_of_error\n",
        "\n",
        "# Generate date range for the predictions\n",
        "dates = pd.date_range(start=start_date, periods=num_months, freq='MS')\n",
        "\n",
        "# Print predicted prices with corresponding dates and confidence intervals\n",
        "print(\"Predicted prices from 2024-04-01 to 2028-12-01:\")\n",
        "for date, pred, lower, upper in zip(dates, y_pred.flatten(), lower_bound.flatten(), upper_bound.flatten()):\n",
        "    print(f\"{date.strftime('%Y-%m-%d')}: {pred:.3f} (Lower Bound: {lower:.3f}, Upper Bound: {upper:.3f})\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iA5zIoWtGR12",
        "outputId": "87dcd0e1-2526-435f-f283-ad5a061e4365"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/200\n",
            "19/19 [==============================] - 9s 22ms/step - loss: 0.0703\n",
            "Epoch 2/200\n",
            "19/19 [==============================] - 0s 23ms/step - loss: 0.0537\n",
            "Epoch 3/200\n",
            "19/19 [==============================] - 0s 25ms/step - loss: 0.0451\n",
            "Epoch 4/200\n",
            "19/19 [==============================] - 0s 21ms/step - loss: 0.0404\n",
            "Epoch 5/200\n",
            "19/19 [==============================] - 0s 22ms/step - loss: 0.0395\n",
            "Epoch 6/200\n",
            "19/19 [==============================] - 0s 24ms/step - loss: 0.0361\n",
            "Epoch 7/200\n",
            "19/19 [==============================] - 0s 22ms/step - loss: 0.0350\n",
            "Epoch 8/200\n",
            "19/19 [==============================] - 0s 22ms/step - loss: 0.0324\n",
            "Epoch 9/200\n",
            "19/19 [==============================] - 1s 30ms/step - loss: 0.0310\n",
            "Epoch 10/200\n",
            "19/19 [==============================] - 1s 29ms/step - loss: 0.0305\n",
            "Epoch 11/200\n",
            "19/19 [==============================] - 0s 25ms/step - loss: 0.0286\n",
            "Epoch 12/200\n",
            "19/19 [==============================] - 0s 25ms/step - loss: 0.0293\n",
            "Epoch 13/200\n",
            "19/19 [==============================] - 1s 30ms/step - loss: 0.0298\n",
            "Epoch 14/200\n",
            "19/19 [==============================] - 1s 31ms/step - loss: 0.0338\n",
            "Epoch 15/200\n",
            "19/19 [==============================] - 1s 27ms/step - loss: 0.0292\n",
            "Epoch 16/200\n",
            "19/19 [==============================] - 1s 28ms/step - loss: 0.0310\n",
            "Epoch 17/200\n",
            "19/19 [==============================] - 0s 19ms/step - loss: 0.0235\n",
            "Epoch 18/200\n",
            "19/19 [==============================] - 0s 12ms/step - loss: 0.0293\n",
            "Epoch 19/200\n",
            "19/19 [==============================] - 0s 12ms/step - loss: 0.0372\n",
            "Epoch 20/200\n",
            "19/19 [==============================] - 0s 12ms/step - loss: 0.0331\n",
            "Epoch 21/200\n",
            "19/19 [==============================] - 0s 14ms/step - loss: 0.0308\n",
            "Epoch 22/200\n",
            "19/19 [==============================] - 0s 12ms/step - loss: 0.0260\n",
            "Epoch 23/200\n",
            "19/19 [==============================] - 0s 12ms/step - loss: 0.0245\n",
            "Epoch 24/200\n",
            "19/19 [==============================] - 0s 14ms/step - loss: 0.0259\n",
            "Epoch 25/200\n",
            "19/19 [==============================] - 0s 13ms/step - loss: 0.0289\n",
            "Epoch 26/200\n",
            "19/19 [==============================] - 0s 12ms/step - loss: 0.0284\n",
            "Epoch 27/200\n",
            "19/19 [==============================] - 0s 11ms/step - loss: 0.0268\n",
            "Epoch 28/200\n",
            "19/19 [==============================] - 0s 12ms/step - loss: 0.0263\n",
            "Epoch 29/200\n",
            "19/19 [==============================] - 0s 13ms/step - loss: 0.0262\n",
            "Epoch 30/200\n",
            "19/19 [==============================] - 0s 12ms/step - loss: 0.0282\n",
            "Epoch 31/200\n",
            "19/19 [==============================] - 0s 12ms/step - loss: 0.0234\n",
            "Epoch 32/200\n",
            "19/19 [==============================] - 0s 12ms/step - loss: 0.0276\n",
            "Epoch 33/200\n",
            "19/19 [==============================] - 0s 12ms/step - loss: 0.0241\n",
            "Epoch 34/200\n",
            "19/19 [==============================] - 0s 13ms/step - loss: 0.0277\n",
            "Epoch 35/200\n",
            "19/19 [==============================] - 0s 12ms/step - loss: 0.0301\n",
            "Epoch 36/200\n",
            "19/19 [==============================] - 0s 12ms/step - loss: 0.0246\n",
            "Epoch 37/200\n",
            "19/19 [==============================] - 0s 13ms/step - loss: 0.0208\n",
            "Epoch 38/200\n",
            "19/19 [==============================] - 0s 13ms/step - loss: 0.0275\n",
            "Epoch 39/200\n",
            "19/19 [==============================] - 0s 12ms/step - loss: 0.0243\n",
            "Epoch 40/200\n",
            "19/19 [==============================] - 0s 12ms/step - loss: 0.0235\n",
            "Epoch 41/200\n",
            "19/19 [==============================] - 0s 12ms/step - loss: 0.0257\n",
            "Epoch 42/200\n",
            "19/19 [==============================] - 0s 13ms/step - loss: 0.0240\n",
            "Epoch 43/200\n",
            "19/19 [==============================] - 0s 12ms/step - loss: 0.0239\n",
            "Epoch 44/200\n",
            "19/19 [==============================] - 0s 12ms/step - loss: 0.0255\n",
            "Epoch 45/200\n",
            "19/19 [==============================] - 0s 12ms/step - loss: 0.0234\n",
            "Epoch 46/200\n",
            "19/19 [==============================] - 0s 12ms/step - loss: 0.0258\n",
            "Epoch 47/200\n",
            "19/19 [==============================] - 0s 13ms/step - loss: 0.0214\n",
            "Epoch 48/200\n",
            "19/19 [==============================] - 0s 12ms/step - loss: 0.0235\n",
            "Epoch 49/200\n",
            "19/19 [==============================] - 0s 12ms/step - loss: 0.0217\n",
            "Epoch 50/200\n",
            "19/19 [==============================] - 0s 12ms/step - loss: 0.0273\n",
            "Epoch 51/200\n",
            "19/19 [==============================] - 0s 13ms/step - loss: 0.0234\n",
            "Epoch 52/200\n",
            "19/19 [==============================] - 0s 12ms/step - loss: 0.0221\n",
            "Epoch 53/200\n",
            "19/19 [==============================] - 0s 12ms/step - loss: 0.0208\n",
            "Epoch 54/200\n",
            "19/19 [==============================] - 0s 13ms/step - loss: 0.0240\n",
            "Epoch 55/200\n",
            "19/19 [==============================] - 0s 13ms/step - loss: 0.0218\n",
            "Epoch 56/200\n",
            "19/19 [==============================] - 0s 12ms/step - loss: 0.0198\n",
            "Epoch 57/200\n",
            "19/19 [==============================] - 0s 12ms/step - loss: 0.0210\n",
            "Epoch 58/200\n",
            "19/19 [==============================] - 0s 13ms/step - loss: 0.0239\n",
            "Epoch 59/200\n",
            "19/19 [==============================] - 0s 21ms/step - loss: 0.0266\n",
            "Epoch 60/200\n",
            "19/19 [==============================] - 0s 21ms/step - loss: 0.0158\n",
            "Epoch 61/200\n",
            "19/19 [==============================] - 0s 21ms/step - loss: 0.0200\n",
            "Epoch 62/200\n",
            "19/19 [==============================] - 0s 21ms/step - loss: 0.0188\n",
            "Epoch 63/200\n",
            "19/19 [==============================] - 0s 21ms/step - loss: 0.0271\n",
            "Epoch 64/200\n",
            "19/19 [==============================] - 0s 22ms/step - loss: 0.0213\n",
            "Epoch 65/200\n",
            "19/19 [==============================] - 0s 21ms/step - loss: 0.0248\n",
            "Epoch 66/200\n",
            "19/19 [==============================] - 0s 22ms/step - loss: 0.0241\n",
            "Epoch 67/200\n",
            "19/19 [==============================] - 0s 23ms/step - loss: 0.0212\n",
            "Epoch 68/200\n",
            "19/19 [==============================] - 0s 21ms/step - loss: 0.0224\n",
            "Epoch 69/200\n",
            "19/19 [==============================] - 0s 13ms/step - loss: 0.0222\n",
            "Epoch 70/200\n",
            "19/19 [==============================] - 0s 14ms/step - loss: 0.0239\n",
            "Epoch 71/200\n",
            "19/19 [==============================] - 0s 12ms/step - loss: 0.0192\n",
            "Epoch 72/200\n",
            "19/19 [==============================] - 0s 13ms/step - loss: 0.0267\n",
            "Epoch 73/200\n",
            "19/19 [==============================] - 0s 12ms/step - loss: 0.0298\n",
            "Epoch 74/200\n",
            "19/19 [==============================] - 0s 13ms/step - loss: 0.0189\n",
            "Epoch 75/200\n",
            "19/19 [==============================] - 0s 13ms/step - loss: 0.0270\n",
            "Epoch 76/200\n",
            "19/19 [==============================] - 0s 13ms/step - loss: 0.0219\n",
            "Epoch 77/200\n",
            "19/19 [==============================] - 0s 13ms/step - loss: 0.0213\n",
            "Epoch 78/200\n",
            "19/19 [==============================] - 0s 14ms/step - loss: 0.0159\n",
            "Epoch 79/200\n",
            "19/19 [==============================] - 0s 12ms/step - loss: 0.0186\n",
            "Epoch 80/200\n",
            "19/19 [==============================] - 0s 12ms/step - loss: 0.0209\n",
            "Epoch 81/200\n",
            "19/19 [==============================] - 0s 12ms/step - loss: 0.0165\n",
            "Epoch 82/200\n",
            "19/19 [==============================] - 0s 14ms/step - loss: 0.0219\n",
            "Epoch 83/200\n",
            "19/19 [==============================] - 0s 13ms/step - loss: 0.0181\n",
            "Epoch 84/200\n",
            "19/19 [==============================] - 0s 12ms/step - loss: 0.0132\n",
            "Epoch 85/200\n",
            "19/19 [==============================] - 0s 12ms/step - loss: 0.0226\n",
            "Epoch 86/200\n",
            "19/19 [==============================] - 0s 12ms/step - loss: 0.0192\n",
            "Epoch 87/200\n",
            "19/19 [==============================] - 0s 14ms/step - loss: 0.0199\n",
            "Epoch 88/200\n",
            "19/19 [==============================] - 0s 13ms/step - loss: 0.0228\n",
            "Epoch 89/200\n",
            "19/19 [==============================] - 0s 13ms/step - loss: 0.0241\n",
            "Epoch 90/200\n",
            "19/19 [==============================] - 0s 13ms/step - loss: 0.0215\n",
            "Epoch 91/200\n",
            "19/19 [==============================] - 0s 14ms/step - loss: 0.0203\n",
            "Epoch 92/200\n",
            "19/19 [==============================] - 0s 13ms/step - loss: 0.0154\n",
            "Epoch 93/200\n",
            "19/19 [==============================] - 0s 12ms/step - loss: 0.0166\n",
            "Epoch 94/200\n",
            "19/19 [==============================] - 0s 12ms/step - loss: 0.0202\n",
            "Epoch 95/200\n",
            "19/19 [==============================] - 0s 14ms/step - loss: 0.0147\n",
            "Epoch 96/200\n",
            "19/19 [==============================] - 0s 12ms/step - loss: 0.0152\n",
            "Epoch 97/200\n",
            "19/19 [==============================] - 0s 13ms/step - loss: 0.0152\n",
            "Epoch 98/200\n",
            "19/19 [==============================] - 0s 15ms/step - loss: 0.0214\n",
            "Epoch 99/200\n",
            "19/19 [==============================] - 0s 14ms/step - loss: 0.0213\n",
            "Epoch 100/200\n",
            "19/19 [==============================] - 0s 13ms/step - loss: 0.0203\n",
            "Epoch 101/200\n",
            "19/19 [==============================] - 0s 13ms/step - loss: 0.0186\n",
            "Epoch 102/200\n",
            "19/19 [==============================] - 0s 13ms/step - loss: 0.0159\n",
            "Epoch 103/200\n",
            "19/19 [==============================] - 0s 14ms/step - loss: 0.0170\n",
            "Epoch 104/200\n",
            "19/19 [==============================] - 0s 12ms/step - loss: 0.0180\n",
            "Epoch 105/200\n",
            "19/19 [==============================] - 0s 14ms/step - loss: 0.0189\n",
            "Epoch 106/200\n",
            "19/19 [==============================] - 0s 13ms/step - loss: 0.0174\n",
            "Epoch 107/200\n",
            "19/19 [==============================] - 0s 14ms/step - loss: 0.0167\n",
            "Epoch 108/200\n",
            "19/19 [==============================] - 0s 21ms/step - loss: 0.0171\n",
            "Epoch 109/200\n",
            "19/19 [==============================] - 0s 21ms/step - loss: 0.0158\n",
            "Epoch 110/200\n",
            "19/19 [==============================] - 0s 21ms/step - loss: 0.0186\n",
            "Epoch 111/200\n",
            "19/19 [==============================] - 0s 21ms/step - loss: 0.0157\n",
            "Epoch 112/200\n",
            "19/19 [==============================] - 0s 23ms/step - loss: 0.0139\n",
            "Epoch 113/200\n",
            "19/19 [==============================] - 0s 22ms/step - loss: 0.0132\n",
            "Epoch 114/200\n",
            "19/19 [==============================] - 0s 23ms/step - loss: 0.0173\n",
            "Epoch 115/200\n",
            "19/19 [==============================] - 0s 23ms/step - loss: 0.0134\n",
            "Epoch 116/200\n",
            "19/19 [==============================] - 0s 22ms/step - loss: 0.0157\n",
            "Epoch 117/200\n",
            "19/19 [==============================] - 0s 23ms/step - loss: 0.0184\n",
            "Epoch 118/200\n",
            "19/19 [==============================] - 0s 14ms/step - loss: 0.0141\n",
            "Epoch 119/200\n",
            "19/19 [==============================] - 0s 13ms/step - loss: 0.0191\n",
            "Epoch 120/200\n",
            "19/19 [==============================] - 0s 14ms/step - loss: 0.0152\n",
            "Epoch 121/200\n",
            "19/19 [==============================] - 0s 14ms/step - loss: 0.0177\n",
            "Epoch 122/200\n",
            "19/19 [==============================] - 0s 13ms/step - loss: 0.0151\n",
            "Epoch 123/200\n",
            "19/19 [==============================] - 0s 13ms/step - loss: 0.0188\n",
            "Epoch 124/200\n",
            "19/19 [==============================] - 0s 13ms/step - loss: 0.0188\n",
            "Epoch 125/200\n",
            "19/19 [==============================] - 0s 13ms/step - loss: 0.0179\n",
            "Epoch 126/200\n",
            "19/19 [==============================] - 0s 13ms/step - loss: 0.0173\n",
            "Epoch 127/200\n",
            "19/19 [==============================] - 0s 13ms/step - loss: 0.0168\n",
            "Epoch 128/200\n",
            "19/19 [==============================] - 0s 12ms/step - loss: 0.0170\n",
            "Epoch 129/200\n",
            "19/19 [==============================] - 0s 14ms/step - loss: 0.0175\n",
            "Epoch 130/200\n",
            "19/19 [==============================] - 0s 13ms/step - loss: 0.0166\n",
            "Epoch 131/200\n",
            "19/19 [==============================] - 0s 13ms/step - loss: 0.0159\n",
            "Epoch 132/200\n",
            "19/19 [==============================] - 0s 12ms/step - loss: 0.0168\n",
            "Epoch 133/200\n",
            "19/19 [==============================] - 0s 13ms/step - loss: 0.0164\n",
            "Epoch 134/200\n",
            "19/19 [==============================] - 0s 13ms/step - loss: 0.0170\n",
            "Epoch 135/200\n",
            "19/19 [==============================] - 0s 13ms/step - loss: 0.0138\n",
            "Epoch 136/200\n",
            "19/19 [==============================] - 0s 13ms/step - loss: 0.0144\n",
            "Epoch 137/200\n",
            "19/19 [==============================] - 0s 14ms/step - loss: 0.0131\n",
            "Epoch 138/200\n",
            "19/19 [==============================] - 0s 13ms/step - loss: 0.0203\n",
            "Epoch 139/200\n",
            "19/19 [==============================] - 0s 13ms/step - loss: 0.0174\n",
            "Epoch 140/200\n",
            "19/19 [==============================] - 0s 13ms/step - loss: 0.0156\n",
            "Epoch 141/200\n",
            "19/19 [==============================] - 0s 13ms/step - loss: 0.0191\n",
            "Epoch 142/200\n",
            "19/19 [==============================] - 0s 12ms/step - loss: 0.0154\n",
            "Epoch 143/200\n",
            "19/19 [==============================] - 0s 12ms/step - loss: 0.0135\n",
            "Epoch 144/200\n",
            "19/19 [==============================] - 0s 13ms/step - loss: 0.0227\n",
            "Epoch 145/200\n",
            "19/19 [==============================] - 0s 14ms/step - loss: 0.0179\n",
            "Epoch 146/200\n",
            "19/19 [==============================] - 0s 13ms/step - loss: 0.0162\n",
            "Epoch 147/200\n",
            "19/19 [==============================] - 0s 13ms/step - loss: 0.0160\n",
            "Epoch 148/200\n",
            "19/19 [==============================] - 0s 13ms/step - loss: 0.0184\n",
            "Epoch 149/200\n",
            "19/19 [==============================] - 0s 13ms/step - loss: 0.0136\n",
            "Epoch 150/200\n",
            "19/19 [==============================] - 0s 13ms/step - loss: 0.0136\n",
            "Epoch 151/200\n",
            "19/19 [==============================] - 0s 12ms/step - loss: 0.0124\n",
            "Epoch 152/200\n",
            "19/19 [==============================] - 0s 13ms/step - loss: 0.0163\n",
            "Epoch 153/200\n",
            "19/19 [==============================] - 0s 14ms/step - loss: 0.0177\n",
            "Epoch 154/200\n",
            "19/19 [==============================] - 0s 13ms/step - loss: 0.0163\n",
            "Epoch 155/200\n",
            "19/19 [==============================] - 0s 12ms/step - loss: 0.0144\n",
            "Epoch 156/200\n",
            "19/19 [==============================] - 0s 13ms/step - loss: 0.0129\n",
            "Epoch 157/200\n",
            "19/19 [==============================] - 0s 17ms/step - loss: 0.0133\n",
            "Epoch 158/200\n",
            "19/19 [==============================] - 0s 21ms/step - loss: 0.0134\n",
            "Epoch 159/200\n",
            "19/19 [==============================] - 0s 23ms/step - loss: 0.0133\n",
            "Epoch 160/200\n",
            "19/19 [==============================] - 0s 21ms/step - loss: 0.0147\n",
            "Epoch 161/200\n",
            "19/19 [==============================] - 0s 21ms/step - loss: 0.0190\n",
            "Epoch 162/200\n",
            "19/19 [==============================] - 0s 21ms/step - loss: 0.0142\n",
            "Epoch 163/200\n",
            "19/19 [==============================] - 0s 22ms/step - loss: 0.0167\n",
            "Epoch 164/200\n",
            "19/19 [==============================] - 0s 22ms/step - loss: 0.0186\n",
            "Epoch 165/200\n",
            "19/19 [==============================] - 0s 22ms/step - loss: 0.0120\n",
            "Epoch 166/200\n",
            "19/19 [==============================] - 0s 22ms/step - loss: 0.0155\n",
            "Epoch 167/200\n",
            "19/19 [==============================] - 0s 16ms/step - loss: 0.0126\n",
            "Epoch 168/200\n",
            "19/19 [==============================] - 0s 13ms/step - loss: 0.0122\n",
            "Epoch 169/200\n",
            "19/19 [==============================] - 0s 13ms/step - loss: 0.0182\n",
            "Epoch 170/200\n",
            "19/19 [==============================] - 0s 13ms/step - loss: 0.0154\n",
            "Epoch 171/200\n",
            "19/19 [==============================] - 0s 12ms/step - loss: 0.0160\n",
            "Epoch 172/200\n",
            "19/19 [==============================] - 0s 13ms/step - loss: 0.0136\n",
            "Epoch 173/200\n",
            "19/19 [==============================] - 0s 12ms/step - loss: 0.0188\n",
            "Epoch 174/200\n",
            "19/19 [==============================] - 0s 13ms/step - loss: 0.0160\n",
            "Epoch 175/200\n",
            "19/19 [==============================] - 0s 12ms/step - loss: 0.0161\n",
            "Epoch 176/200\n",
            "19/19 [==============================] - 0s 13ms/step - loss: 0.0139\n",
            "Epoch 177/200\n",
            "19/19 [==============================] - 0s 12ms/step - loss: 0.0165\n",
            "Epoch 178/200\n",
            "19/19 [==============================] - 0s 13ms/step - loss: 0.0177\n",
            "Epoch 179/200\n",
            "19/19 [==============================] - 0s 12ms/step - loss: 0.0158\n",
            "Epoch 180/200\n",
            "19/19 [==============================] - 0s 13ms/step - loss: 0.0146\n",
            "Epoch 181/200\n",
            "19/19 [==============================] - 0s 12ms/step - loss: 0.0118\n",
            "Epoch 182/200\n",
            "19/19 [==============================] - 0s 13ms/step - loss: 0.0183\n",
            "Epoch 183/200\n",
            "19/19 [==============================] - 0s 12ms/step - loss: 0.0159\n",
            "Epoch 184/200\n",
            "19/19 [==============================] - 0s 14ms/step - loss: 0.0150\n",
            "Epoch 185/200\n",
            "19/19 [==============================] - 0s 12ms/step - loss: 0.0145\n",
            "Epoch 186/200\n",
            "19/19 [==============================] - 0s 13ms/step - loss: 0.0158\n",
            "Epoch 187/200\n",
            "19/19 [==============================] - 0s 12ms/step - loss: 0.0162\n",
            "Epoch 188/200\n",
            "19/19 [==============================] - 0s 13ms/step - loss: 0.0143\n",
            "Epoch 189/200\n",
            "19/19 [==============================] - 0s 12ms/step - loss: 0.0119\n",
            "Epoch 190/200\n",
            "19/19 [==============================] - 0s 13ms/step - loss: 0.0104\n",
            "Epoch 191/200\n",
            "19/19 [==============================] - 0s 13ms/step - loss: 0.0139\n",
            "Epoch 192/200\n",
            "19/19 [==============================] - 0s 13ms/step - loss: 0.0124\n",
            "Epoch 193/200\n",
            "19/19 [==============================] - 0s 13ms/step - loss: 0.0121\n",
            "Epoch 194/200\n",
            "19/19 [==============================] - 0s 13ms/step - loss: 0.0137\n",
            "Epoch 195/200\n",
            "19/19 [==============================] - 0s 12ms/step - loss: 0.0151\n",
            "Epoch 196/200\n",
            "19/19 [==============================] - 0s 12ms/step - loss: 0.0150\n",
            "Epoch 197/200\n",
            "19/19 [==============================] - 0s 13ms/step - loss: 0.0112\n",
            "Epoch 198/200\n",
            "19/19 [==============================] - 0s 12ms/step - loss: 0.0157\n",
            "Epoch 199/200\n",
            "19/19 [==============================] - 0s 13ms/step - loss: 0.0141\n",
            "Epoch 200/200\n",
            "19/19 [==============================] - 0s 12ms/step - loss: 0.0158\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "\n",
            "For z-score = 1.96:\n",
            "2024-04-01: 2.585 (Lower Bound: 2.569, Upper Bound: 2.600)\n",
            "2024-05-01: 2.581 (Lower Bound: 2.566, Upper Bound: 2.597)\n",
            "2024-06-01: 2.583 (Lower Bound: 2.567, Upper Bound: 2.598)\n",
            "2024-07-01: 2.585 (Lower Bound: 2.569, Upper Bound: 2.601)\n",
            "2024-08-01: 2.587 (Lower Bound: 2.571, Upper Bound: 2.603)\n",
            "2024-09-01: 2.589 (Lower Bound: 2.573, Upper Bound: 2.605)\n",
            "2024-10-01: 2.591 (Lower Bound: 2.575, Upper Bound: 2.607)\n",
            "2024-11-01: 2.593 (Lower Bound: 2.577, Upper Bound: 2.609)\n",
            "2024-12-01: 2.595 (Lower Bound: 2.579, Upper Bound: 2.611)\n",
            "2025-01-01: 2.597 (Lower Bound: 2.581, Upper Bound: 2.612)\n",
            "2025-02-01: 2.599 (Lower Bound: 2.583, Upper Bound: 2.614)\n",
            "2025-03-01: 2.604 (Lower Bound: 2.588, Upper Bound: 2.620)\n",
            "2025-04-01: 2.609 (Lower Bound: 2.594, Upper Bound: 2.625)\n",
            "2025-05-01: 2.615 (Lower Bound: 2.599, Upper Bound: 2.630)\n",
            "2025-06-01: 2.620 (Lower Bound: 2.604, Upper Bound: 2.636)\n",
            "2025-07-01: 2.625 (Lower Bound: 2.609, Upper Bound: 2.641)\n",
            "2025-08-01: 2.630 (Lower Bound: 2.614, Upper Bound: 2.645)\n",
            "2025-09-01: 2.635 (Lower Bound: 2.619, Upper Bound: 2.650)\n",
            "2025-10-01: 2.640 (Lower Bound: 2.625, Upper Bound: 2.656)\n",
            "2025-11-01: 2.646 (Lower Bound: 2.630, Upper Bound: 2.661)\n",
            "2025-12-01: 2.651 (Lower Bound: 2.635, Upper Bound: 2.666)\n",
            "2026-01-01: 2.656 (Lower Bound: 2.640, Upper Bound: 2.671)\n",
            "2026-02-01: 2.661 (Lower Bound: 2.645, Upper Bound: 2.676)\n",
            "2026-03-01: 2.666 (Lower Bound: 2.650, Upper Bound: 2.681)\n",
            "2026-04-01: 2.670 (Lower Bound: 2.654, Upper Bound: 2.685)\n",
            "2026-05-01: 2.674 (Lower Bound: 2.658, Upper Bound: 2.689)\n",
            "2026-06-01: 2.678 (Lower Bound: 2.662, Upper Bound: 2.694)\n",
            "2026-07-01: 2.682 (Lower Bound: 2.666, Upper Bound: 2.698)\n",
            "2026-08-01: 2.686 (Lower Bound: 2.670, Upper Bound: 2.702)\n",
            "2026-09-01: 2.690 (Lower Bound: 2.674, Upper Bound: 2.706)\n",
            "2026-10-01: 2.694 (Lower Bound: 2.678, Upper Bound: 2.710)\n",
            "2026-11-01: 2.698 (Lower Bound: 2.682, Upper Bound: 2.714)\n",
            "2026-12-01: 2.702 (Lower Bound: 2.686, Upper Bound: 2.718)\n",
            "2027-01-01: 2.706 (Lower Bound: 2.690, Upper Bound: 2.722)\n",
            "2027-02-01: 2.710 (Lower Bound: 2.694, Upper Bound: 2.725)\n",
            "2027-03-01: 2.713 (Lower Bound: 2.698, Upper Bound: 2.729)\n",
            "2027-04-01: 2.717 (Lower Bound: 2.701, Upper Bound: 2.732)\n",
            "2027-05-01: 2.720 (Lower Bound: 2.704, Upper Bound: 2.736)\n",
            "2027-06-01: 2.724 (Lower Bound: 2.708, Upper Bound: 2.740)\n",
            "2027-07-01: 2.728 (Lower Bound: 2.713, Upper Bound: 2.744)\n",
            "2027-08-01: 2.732 (Lower Bound: 2.717, Upper Bound: 2.748)\n",
            "2027-09-01: 2.736 (Lower Bound: 2.721, Upper Bound: 2.752)\n",
            "2027-10-01: 2.740 (Lower Bound: 2.725, Upper Bound: 2.756)\n",
            "2027-11-01: 2.744 (Lower Bound: 2.728, Upper Bound: 2.759)\n",
            "2027-12-01: 2.747 (Lower Bound: 2.731, Upper Bound: 2.763)\n",
            "2028-01-01: 2.750 (Lower Bound: 2.735, Upper Bound: 2.766)\n",
            "2028-02-01: 2.753 (Lower Bound: 2.738, Upper Bound: 2.769)\n",
            "2028-03-01: 2.757 (Lower Bound: 2.741, Upper Bound: 2.772)\n",
            "2028-04-01: 2.760 (Lower Bound: 2.744, Upper Bound: 2.775)\n",
            "2028-05-01: 2.763 (Lower Bound: 2.747, Upper Bound: 2.778)\n",
            "2028-06-01: 2.766 (Lower Bound: 2.750, Upper Bound: 2.781)\n",
            "2028-07-01: 2.768 (Lower Bound: 2.753, Upper Bound: 2.784)\n",
            "2028-08-01: 2.771 (Lower Bound: 2.756, Upper Bound: 2.787)\n",
            "2028-09-01: 2.774 (Lower Bound: 2.758, Upper Bound: 2.790)\n",
            "2028-10-01: 2.777 (Lower Bound: 2.761, Upper Bound: 2.792)\n",
            "2028-11-01: 2.780 (Lower Bound: 2.764, Upper Bound: 2.795)\n",
            "2028-12-01: 2.782 (Lower Bound: 2.767, Upper Bound: 2.798)\n",
            "\n",
            "For z-score = 2.25:\n",
            "2024-04-01: 2.585 (Lower Bound: 2.567, Upper Bound: 2.603)\n",
            "2024-05-01: 2.581 (Lower Bound: 2.563, Upper Bound: 2.599)\n",
            "2024-06-01: 2.583 (Lower Bound: 2.565, Upper Bound: 2.601)\n",
            "2024-07-01: 2.585 (Lower Bound: 2.567, Upper Bound: 2.603)\n",
            "2024-08-01: 2.587 (Lower Bound: 2.569, Upper Bound: 2.605)\n",
            "2024-09-01: 2.589 (Lower Bound: 2.571, Upper Bound: 2.607)\n",
            "2024-10-01: 2.591 (Lower Bound: 2.573, Upper Bound: 2.609)\n",
            "2024-11-01: 2.593 (Lower Bound: 2.575, Upper Bound: 2.611)\n",
            "2024-12-01: 2.595 (Lower Bound: 2.577, Upper Bound: 2.613)\n",
            "2025-01-01: 2.597 (Lower Bound: 2.579, Upper Bound: 2.615)\n",
            "2025-02-01: 2.599 (Lower Bound: 2.581, Upper Bound: 2.617)\n",
            "2025-03-01: 2.604 (Lower Bound: 2.586, Upper Bound: 2.622)\n",
            "2025-04-01: 2.609 (Lower Bound: 2.591, Upper Bound: 2.627)\n",
            "2025-05-01: 2.615 (Lower Bound: 2.597, Upper Bound: 2.633)\n",
            "2025-06-01: 2.620 (Lower Bound: 2.602, Upper Bound: 2.638)\n",
            "2025-07-01: 2.625 (Lower Bound: 2.607, Upper Bound: 2.643)\n",
            "2025-08-01: 2.630 (Lower Bound: 2.612, Upper Bound: 2.648)\n",
            "2025-09-01: 2.635 (Lower Bound: 2.617, Upper Bound: 2.653)\n",
            "2025-10-01: 2.640 (Lower Bound: 2.622, Upper Bound: 2.658)\n",
            "2025-11-01: 2.646 (Lower Bound: 2.628, Upper Bound: 2.664)\n",
            "2025-12-01: 2.651 (Lower Bound: 2.633, Upper Bound: 2.669)\n",
            "2026-01-01: 2.656 (Lower Bound: 2.638, Upper Bound: 2.674)\n",
            "2026-02-01: 2.661 (Lower Bound: 2.643, Upper Bound: 2.679)\n",
            "2026-03-01: 2.666 (Lower Bound: 2.648, Upper Bound: 2.683)\n",
            "2026-04-01: 2.670 (Lower Bound: 2.652, Upper Bound: 2.688)\n",
            "2026-05-01: 2.674 (Lower Bound: 2.656, Upper Bound: 2.692)\n",
            "2026-06-01: 2.678 (Lower Bound: 2.660, Upper Bound: 2.696)\n",
            "2026-07-01: 2.682 (Lower Bound: 2.664, Upper Bound: 2.700)\n",
            "2026-08-01: 2.686 (Lower Bound: 2.668, Upper Bound: 2.704)\n",
            "2026-09-01: 2.690 (Lower Bound: 2.672, Upper Bound: 2.708)\n",
            "2026-10-01: 2.694 (Lower Bound: 2.676, Upper Bound: 2.712)\n",
            "2026-11-01: 2.698 (Lower Bound: 2.680, Upper Bound: 2.716)\n",
            "2026-12-01: 2.702 (Lower Bound: 2.684, Upper Bound: 2.720)\n",
            "2027-01-01: 2.706 (Lower Bound: 2.688, Upper Bound: 2.724)\n",
            "2027-02-01: 2.710 (Lower Bound: 2.692, Upper Bound: 2.728)\n",
            "2027-03-01: 2.713 (Lower Bound: 2.695, Upper Bound: 2.731)\n",
            "2027-04-01: 2.717 (Lower Bound: 2.699, Upper Bound: 2.735)\n",
            "2027-05-01: 2.720 (Lower Bound: 2.702, Upper Bound: 2.738)\n",
            "2027-06-01: 2.724 (Lower Bound: 2.706, Upper Bound: 2.742)\n",
            "2027-07-01: 2.728 (Lower Bound: 2.710, Upper Bound: 2.746)\n",
            "2027-08-01: 2.732 (Lower Bound: 2.714, Upper Bound: 2.750)\n",
            "2027-09-01: 2.736 (Lower Bound: 2.718, Upper Bound: 2.754)\n",
            "2027-10-01: 2.740 (Lower Bound: 2.722, Upper Bound: 2.758)\n",
            "2027-11-01: 2.744 (Lower Bound: 2.726, Upper Bound: 2.762)\n",
            "2027-12-01: 2.747 (Lower Bound: 2.729, Upper Bound: 2.765)\n",
            "2028-01-01: 2.750 (Lower Bound: 2.732, Upper Bound: 2.768)\n",
            "2028-02-01: 2.753 (Lower Bound: 2.736, Upper Bound: 2.771)\n",
            "2028-03-01: 2.757 (Lower Bound: 2.739, Upper Bound: 2.775)\n",
            "2028-04-01: 2.760 (Lower Bound: 2.742, Upper Bound: 2.778)\n",
            "2028-05-01: 2.763 (Lower Bound: 2.745, Upper Bound: 2.781)\n",
            "2028-06-01: 2.766 (Lower Bound: 2.748, Upper Bound: 2.783)\n",
            "2028-07-01: 2.768 (Lower Bound: 2.750, Upper Bound: 2.786)\n",
            "2028-08-01: 2.771 (Lower Bound: 2.753, Upper Bound: 2.789)\n",
            "2028-09-01: 2.774 (Lower Bound: 2.756, Upper Bound: 2.792)\n",
            "2028-10-01: 2.777 (Lower Bound: 2.759, Upper Bound: 2.795)\n",
            "2028-11-01: 2.780 (Lower Bound: 2.762, Upper Bound: 2.798)\n",
            "2028-12-01: 2.782 (Lower Bound: 2.764, Upper Bound: 2.800)\n",
            "\n",
            "For z-score = 2.5:\n",
            "2024-04-01: 2.585 (Lower Bound: 2.565, Upper Bound: 2.605)\n",
            "2024-05-01: 2.581 (Lower Bound: 2.561, Upper Bound: 2.601)\n",
            "2024-06-01: 2.583 (Lower Bound: 2.563, Upper Bound: 2.603)\n",
            "2024-07-01: 2.585 (Lower Bound: 2.565, Upper Bound: 2.605)\n",
            "2024-08-01: 2.587 (Lower Bound: 2.567, Upper Bound: 2.607)\n",
            "2024-09-01: 2.589 (Lower Bound: 2.569, Upper Bound: 2.609)\n",
            "2024-10-01: 2.591 (Lower Bound: 2.571, Upper Bound: 2.611)\n",
            "2024-11-01: 2.593 (Lower Bound: 2.573, Upper Bound: 2.613)\n",
            "2024-12-01: 2.595 (Lower Bound: 2.575, Upper Bound: 2.615)\n",
            "2025-01-01: 2.597 (Lower Bound: 2.577, Upper Bound: 2.617)\n",
            "2025-02-01: 2.599 (Lower Bound: 2.579, Upper Bound: 2.619)\n",
            "2025-03-01: 2.604 (Lower Bound: 2.584, Upper Bound: 2.624)\n",
            "2025-04-01: 2.609 (Lower Bound: 2.589, Upper Bound: 2.629)\n",
            "2025-05-01: 2.615 (Lower Bound: 2.595, Upper Bound: 2.635)\n",
            "2025-06-01: 2.620 (Lower Bound: 2.600, Upper Bound: 2.640)\n",
            "2025-07-01: 2.625 (Lower Bound: 2.605, Upper Bound: 2.645)\n",
            "2025-08-01: 2.630 (Lower Bound: 2.610, Upper Bound: 2.650)\n",
            "2025-09-01: 2.635 (Lower Bound: 2.615, Upper Bound: 2.655)\n",
            "2025-10-01: 2.640 (Lower Bound: 2.620, Upper Bound: 2.660)\n",
            "2025-11-01: 2.646 (Lower Bound: 2.626, Upper Bound: 2.666)\n",
            "2025-12-01: 2.651 (Lower Bound: 2.631, Upper Bound: 2.671)\n",
            "2026-01-01: 2.656 (Lower Bound: 2.636, Upper Bound: 2.676)\n",
            "2026-02-01: 2.661 (Lower Bound: 2.641, Upper Bound: 2.681)\n",
            "2026-03-01: 2.666 (Lower Bound: 2.646, Upper Bound: 2.685)\n",
            "2026-04-01: 2.670 (Lower Bound: 2.650, Upper Bound: 2.690)\n",
            "2026-05-01: 2.674 (Lower Bound: 2.654, Upper Bound: 2.694)\n",
            "2026-06-01: 2.678 (Lower Bound: 2.658, Upper Bound: 2.698)\n",
            "2026-07-01: 2.682 (Lower Bound: 2.662, Upper Bound: 2.702)\n",
            "2026-08-01: 2.686 (Lower Bound: 2.666, Upper Bound: 2.706)\n",
            "2026-09-01: 2.690 (Lower Bound: 2.670, Upper Bound: 2.710)\n",
            "2026-10-01: 2.694 (Lower Bound: 2.674, Upper Bound: 2.714)\n",
            "2026-11-01: 2.698 (Lower Bound: 2.678, Upper Bound: 2.718)\n",
            "2026-12-01: 2.702 (Lower Bound: 2.682, Upper Bound: 2.722)\n",
            "2027-01-01: 2.706 (Lower Bound: 2.686, Upper Bound: 2.726)\n",
            "2027-02-01: 2.710 (Lower Bound: 2.690, Upper Bound: 2.730)\n",
            "2027-03-01: 2.713 (Lower Bound: 2.693, Upper Bound: 2.733)\n",
            "2027-04-01: 2.717 (Lower Bound: 2.697, Upper Bound: 2.737)\n",
            "2027-05-01: 2.720 (Lower Bound: 2.700, Upper Bound: 2.740)\n",
            "2027-06-01: 2.724 (Lower Bound: 2.704, Upper Bound: 2.744)\n",
            "2027-07-01: 2.728 (Lower Bound: 2.708, Upper Bound: 2.748)\n",
            "2027-08-01: 2.732 (Lower Bound: 2.712, Upper Bound: 2.752)\n",
            "2027-09-01: 2.736 (Lower Bound: 2.716, Upper Bound: 2.756)\n",
            "2027-10-01: 2.740 (Lower Bound: 2.720, Upper Bound: 2.760)\n",
            "2027-11-01: 2.744 (Lower Bound: 2.724, Upper Bound: 2.764)\n",
            "2027-12-01: 2.747 (Lower Bound: 2.727, Upper Bound: 2.767)\n",
            "2028-01-01: 2.750 (Lower Bound: 2.730, Upper Bound: 2.770)\n",
            "2028-02-01: 2.753 (Lower Bound: 2.734, Upper Bound: 2.773)\n",
            "2028-03-01: 2.757 (Lower Bound: 2.737, Upper Bound: 2.777)\n",
            "2028-04-01: 2.760 (Lower Bound: 2.740, Upper Bound: 2.780)\n",
            "2028-05-01: 2.763 (Lower Bound: 2.743, Upper Bound: 2.783)\n",
            "2028-06-01: 2.766 (Lower Bound: 2.746, Upper Bound: 2.785)\n",
            "2028-07-01: 2.768 (Lower Bound: 2.748, Upper Bound: 2.788)\n",
            "2028-08-01: 2.771 (Lower Bound: 2.751, Upper Bound: 2.791)\n",
            "2028-09-01: 2.774 (Lower Bound: 2.754, Upper Bound: 2.794)\n",
            "2028-10-01: 2.777 (Lower Bound: 2.757, Upper Bound: 2.797)\n",
            "2028-11-01: 2.780 (Lower Bound: 2.760, Upper Bound: 2.800)\n",
            "2028-12-01: 2.782 (Lower Bound: 2.762, Upper Bound: 2.802)\n",
            "\n",
            "For z-score = 3.0:\n",
            "2024-04-01: 2.585 (Lower Bound: 2.561, Upper Bound: 2.609)\n",
            "2024-05-01: 2.581 (Lower Bound: 2.557, Upper Bound: 2.605)\n",
            "2024-06-01: 2.583 (Lower Bound: 2.559, Upper Bound: 2.607)\n",
            "2024-07-01: 2.585 (Lower Bound: 2.561, Upper Bound: 2.609)\n",
            "2024-08-01: 2.587 (Lower Bound: 2.563, Upper Bound: 2.611)\n",
            "2024-09-01: 2.589 (Lower Bound: 2.565, Upper Bound: 2.613)\n",
            "2024-10-01: 2.591 (Lower Bound: 2.567, Upper Bound: 2.615)\n",
            "2024-11-01: 2.593 (Lower Bound: 2.569, Upper Bound: 2.617)\n",
            "2024-12-01: 2.595 (Lower Bound: 2.571, Upper Bound: 2.619)\n",
            "2025-01-01: 2.597 (Lower Bound: 2.573, Upper Bound: 2.621)\n",
            "2025-02-01: 2.599 (Lower Bound: 2.575, Upper Bound: 2.623)\n",
            "2025-03-01: 2.604 (Lower Bound: 2.580, Upper Bound: 2.628)\n",
            "2025-04-01: 2.609 (Lower Bound: 2.585, Upper Bound: 2.633)\n",
            "2025-05-01: 2.615 (Lower Bound: 2.591, Upper Bound: 2.639)\n",
            "2025-06-01: 2.620 (Lower Bound: 2.596, Upper Bound: 2.644)\n",
            "2025-07-01: 2.625 (Lower Bound: 2.601, Upper Bound: 2.649)\n",
            "2025-08-01: 2.630 (Lower Bound: 2.606, Upper Bound: 2.654)\n",
            "2025-09-01: 2.635 (Lower Bound: 2.611, Upper Bound: 2.659)\n",
            "2025-10-01: 2.640 (Lower Bound: 2.616, Upper Bound: 2.664)\n",
            "2025-11-01: 2.646 (Lower Bound: 2.622, Upper Bound: 2.670)\n",
            "2025-12-01: 2.651 (Lower Bound: 2.627, Upper Bound: 2.675)\n",
            "2026-01-01: 2.656 (Lower Bound: 2.632, Upper Bound: 2.680)\n",
            "2026-02-01: 2.661 (Lower Bound: 2.637, Upper Bound: 2.685)\n",
            "2026-03-01: 2.666 (Lower Bound: 2.642, Upper Bound: 2.689)\n",
            "2026-04-01: 2.670 (Lower Bound: 2.646, Upper Bound: 2.694)\n",
            "2026-05-01: 2.674 (Lower Bound: 2.650, Upper Bound: 2.698)\n",
            "2026-06-01: 2.678 (Lower Bound: 2.654, Upper Bound: 2.702)\n",
            "2026-07-01: 2.682 (Lower Bound: 2.658, Upper Bound: 2.706)\n",
            "2026-08-01: 2.686 (Lower Bound: 2.662, Upper Bound: 2.710)\n",
            "2026-09-01: 2.690 (Lower Bound: 2.666, Upper Bound: 2.714)\n",
            "2026-10-01: 2.694 (Lower Bound: 2.670, Upper Bound: 2.718)\n",
            "2026-11-01: 2.698 (Lower Bound: 2.674, Upper Bound: 2.722)\n",
            "2026-12-01: 2.702 (Lower Bound: 2.678, Upper Bound: 2.726)\n",
            "2027-01-01: 2.706 (Lower Bound: 2.682, Upper Bound: 2.730)\n",
            "2027-02-01: 2.710 (Lower Bound: 2.686, Upper Bound: 2.734)\n",
            "2027-03-01: 2.713 (Lower Bound: 2.689, Upper Bound: 2.737)\n",
            "2027-04-01: 2.717 (Lower Bound: 2.693, Upper Bound: 2.741)\n",
            "2027-05-01: 2.720 (Lower Bound: 2.696, Upper Bound: 2.744)\n",
            "2027-06-01: 2.724 (Lower Bound: 2.700, Upper Bound: 2.748)\n",
            "2027-07-01: 2.728 (Lower Bound: 2.704, Upper Bound: 2.752)\n",
            "2027-08-01: 2.732 (Lower Bound: 2.708, Upper Bound: 2.756)\n",
            "2027-09-01: 2.736 (Lower Bound: 2.712, Upper Bound: 2.760)\n",
            "2027-10-01: 2.740 (Lower Bound: 2.716, Upper Bound: 2.764)\n",
            "2027-11-01: 2.744 (Lower Bound: 2.720, Upper Bound: 2.768)\n",
            "2027-12-01: 2.747 (Lower Bound: 2.723, Upper Bound: 2.771)\n",
            "2028-01-01: 2.750 (Lower Bound: 2.726, Upper Bound: 2.774)\n",
            "2028-02-01: 2.753 (Lower Bound: 2.730, Upper Bound: 2.777)\n",
            "2028-03-01: 2.757 (Lower Bound: 2.733, Upper Bound: 2.781)\n",
            "2028-04-01: 2.760 (Lower Bound: 2.736, Upper Bound: 2.784)\n",
            "2028-05-01: 2.763 (Lower Bound: 2.739, Upper Bound: 2.787)\n",
            "2028-06-01: 2.766 (Lower Bound: 2.742, Upper Bound: 2.789)\n",
            "2028-07-01: 2.768 (Lower Bound: 2.744, Upper Bound: 2.792)\n",
            "2028-08-01: 2.771 (Lower Bound: 2.747, Upper Bound: 2.795)\n",
            "2028-09-01: 2.774 (Lower Bound: 2.750, Upper Bound: 2.798)\n",
            "2028-10-01: 2.777 (Lower Bound: 2.753, Upper Bound: 2.801)\n",
            "2028-11-01: 2.780 (Lower Bound: 2.756, Upper Bound: 2.804)\n",
            "2028-12-01: 2.782 (Lower Bound: 2.758, Upper Bound: 2.806)\n",
            "\n",
            "For z-score = 3.5:\n",
            "2024-04-01: 2.585 (Lower Bound: 2.557, Upper Bound: 2.613)\n",
            "2024-05-01: 2.581 (Lower Bound: 2.553, Upper Bound: 2.609)\n",
            "2024-06-01: 2.583 (Lower Bound: 2.555, Upper Bound: 2.611)\n",
            "2024-07-01: 2.585 (Lower Bound: 2.557, Upper Bound: 2.613)\n",
            "2024-08-01: 2.587 (Lower Bound: 2.559, Upper Bound: 2.615)\n",
            "2024-09-01: 2.589 (Lower Bound: 2.561, Upper Bound: 2.617)\n",
            "2024-10-01: 2.591 (Lower Bound: 2.563, Upper Bound: 2.619)\n",
            "2024-11-01: 2.593 (Lower Bound: 2.565, Upper Bound: 2.621)\n",
            "2024-12-01: 2.595 (Lower Bound: 2.567, Upper Bound: 2.623)\n",
            "2025-01-01: 2.597 (Lower Bound: 2.569, Upper Bound: 2.625)\n",
            "2025-02-01: 2.599 (Lower Bound: 2.571, Upper Bound: 2.627)\n",
            "2025-03-01: 2.604 (Lower Bound: 2.576, Upper Bound: 2.632)\n",
            "2025-04-01: 2.609 (Lower Bound: 2.581, Upper Bound: 2.637)\n",
            "2025-05-01: 2.615 (Lower Bound: 2.587, Upper Bound: 2.643)\n",
            "2025-06-01: 2.620 (Lower Bound: 2.592, Upper Bound: 2.648)\n",
            "2025-07-01: 2.625 (Lower Bound: 2.597, Upper Bound: 2.653)\n",
            "2025-08-01: 2.630 (Lower Bound: 2.602, Upper Bound: 2.658)\n",
            "2025-09-01: 2.635 (Lower Bound: 2.607, Upper Bound: 2.663)\n",
            "2025-10-01: 2.640 (Lower Bound: 2.612, Upper Bound: 2.668)\n",
            "2025-11-01: 2.646 (Lower Bound: 2.618, Upper Bound: 2.674)\n",
            "2025-12-01: 2.651 (Lower Bound: 2.623, Upper Bound: 2.679)\n",
            "2026-01-01: 2.656 (Lower Bound: 2.628, Upper Bound: 2.684)\n",
            "2026-02-01: 2.661 (Lower Bound: 2.633, Upper Bound: 2.689)\n",
            "2026-03-01: 2.666 (Lower Bound: 2.638, Upper Bound: 2.693)\n",
            "2026-04-01: 2.670 (Lower Bound: 2.642, Upper Bound: 2.698)\n",
            "2026-05-01: 2.674 (Lower Bound: 2.646, Upper Bound: 2.702)\n",
            "2026-06-01: 2.678 (Lower Bound: 2.650, Upper Bound: 2.706)\n",
            "2026-07-01: 2.682 (Lower Bound: 2.654, Upper Bound: 2.710)\n",
            "2026-08-01: 2.686 (Lower Bound: 2.658, Upper Bound: 2.714)\n",
            "2026-09-01: 2.690 (Lower Bound: 2.662, Upper Bound: 2.718)\n",
            "2026-10-01: 2.694 (Lower Bound: 2.666, Upper Bound: 2.722)\n",
            "2026-11-01: 2.698 (Lower Bound: 2.670, Upper Bound: 2.726)\n",
            "2026-12-01: 2.702 (Lower Bound: 2.674, Upper Bound: 2.730)\n",
            "2027-01-01: 2.706 (Lower Bound: 2.678, Upper Bound: 2.734)\n",
            "2027-02-01: 2.710 (Lower Bound: 2.682, Upper Bound: 2.738)\n",
            "2027-03-01: 2.713 (Lower Bound: 2.685, Upper Bound: 2.741)\n",
            "2027-04-01: 2.717 (Lower Bound: 2.689, Upper Bound: 2.745)\n",
            "2027-05-01: 2.720 (Lower Bound: 2.692, Upper Bound: 2.748)\n",
            "2027-06-01: 2.724 (Lower Bound: 2.696, Upper Bound: 2.752)\n",
            "2027-07-01: 2.728 (Lower Bound: 2.700, Upper Bound: 2.756)\n",
            "2027-08-01: 2.732 (Lower Bound: 2.704, Upper Bound: 2.760)\n",
            "2027-09-01: 2.736 (Lower Bound: 2.708, Upper Bound: 2.764)\n",
            "2027-10-01: 2.740 (Lower Bound: 2.712, Upper Bound: 2.768)\n",
            "2027-11-01: 2.744 (Lower Bound: 2.716, Upper Bound: 2.772)\n",
            "2027-12-01: 2.747 (Lower Bound: 2.719, Upper Bound: 2.775)\n",
            "2028-01-01: 2.750 (Lower Bound: 2.722, Upper Bound: 2.778)\n",
            "2028-02-01: 2.753 (Lower Bound: 2.726, Upper Bound: 2.781)\n",
            "2028-03-01: 2.757 (Lower Bound: 2.729, Upper Bound: 2.785)\n",
            "2028-04-01: 2.760 (Lower Bound: 2.732, Upper Bound: 2.788)\n",
            "2028-05-01: 2.763 (Lower Bound: 2.735, Upper Bound: 2.791)\n",
            "2028-06-01: 2.766 (Lower Bound: 2.738, Upper Bound: 2.793)\n",
            "2028-07-01: 2.768 (Lower Bound: 2.740, Upper Bound: 2.796)\n",
            "2028-08-01: 2.771 (Lower Bound: 2.743, Upper Bound: 2.799)\n",
            "2028-09-01: 2.774 (Lower Bound: 2.746, Upper Bound: 2.802)\n",
            "2028-10-01: 2.777 (Lower Bound: 2.749, Upper Bound: 2.805)\n",
            "2028-11-01: 2.780 (Lower Bound: 2.752, Upper Bound: 2.808)\n",
            "2028-12-01: 2.782 (Lower Bound: 2.754, Upper Bound: 2.810)\n",
            "\n",
            "For z-score = 4.0:\n",
            "2024-04-01: 2.585 (Lower Bound: 2.553, Upper Bound: 2.617)\n",
            "2024-05-01: 2.581 (Lower Bound: 2.549, Upper Bound: 2.613)\n",
            "2024-06-01: 2.583 (Lower Bound: 2.551, Upper Bound: 2.615)\n",
            "2024-07-01: 2.585 (Lower Bound: 2.553, Upper Bound: 2.617)\n",
            "2024-08-01: 2.587 (Lower Bound: 2.555, Upper Bound: 2.619)\n",
            "2024-09-01: 2.589 (Lower Bound: 2.557, Upper Bound: 2.621)\n",
            "2024-10-01: 2.591 (Lower Bound: 2.559, Upper Bound: 2.623)\n",
            "2024-11-01: 2.593 (Lower Bound: 2.561, Upper Bound: 2.625)\n",
            "2024-12-01: 2.595 (Lower Bound: 2.563, Upper Bound: 2.627)\n",
            "2025-01-01: 2.597 (Lower Bound: 2.565, Upper Bound: 2.629)\n",
            "2025-02-01: 2.599 (Lower Bound: 2.567, Upper Bound: 2.631)\n",
            "2025-03-01: 2.604 (Lower Bound: 2.572, Upper Bound: 2.636)\n",
            "2025-04-01: 2.609 (Lower Bound: 2.577, Upper Bound: 2.641)\n",
            "2025-05-01: 2.615 (Lower Bound: 2.583, Upper Bound: 2.647)\n",
            "2025-06-01: 2.620 (Lower Bound: 2.588, Upper Bound: 2.652)\n",
            "2025-07-01: 2.625 (Lower Bound: 2.593, Upper Bound: 2.657)\n",
            "2025-08-01: 2.630 (Lower Bound: 2.598, Upper Bound: 2.662)\n",
            "2025-09-01: 2.635 (Lower Bound: 2.603, Upper Bound: 2.667)\n",
            "2025-10-01: 2.640 (Lower Bound: 2.608, Upper Bound: 2.672)\n",
            "2025-11-01: 2.646 (Lower Bound: 2.614, Upper Bound: 2.678)\n",
            "2025-12-01: 2.651 (Lower Bound: 2.619, Upper Bound: 2.683)\n",
            "2026-01-01: 2.656 (Lower Bound: 2.624, Upper Bound: 2.688)\n",
            "2026-02-01: 2.661 (Lower Bound: 2.629, Upper Bound: 2.693)\n",
            "2026-03-01: 2.666 (Lower Bound: 2.634, Upper Bound: 2.697)\n",
            "2026-04-01: 2.670 (Lower Bound: 2.638, Upper Bound: 2.702)\n",
            "2026-05-01: 2.674 (Lower Bound: 2.642, Upper Bound: 2.706)\n",
            "2026-06-01: 2.678 (Lower Bound: 2.646, Upper Bound: 2.710)\n",
            "2026-07-01: 2.682 (Lower Bound: 2.650, Upper Bound: 2.714)\n",
            "2026-08-01: 2.686 (Lower Bound: 2.654, Upper Bound: 2.718)\n",
            "2026-09-01: 2.690 (Lower Bound: 2.658, Upper Bound: 2.722)\n",
            "2026-10-01: 2.694 (Lower Bound: 2.662, Upper Bound: 2.726)\n",
            "2026-11-01: 2.698 (Lower Bound: 2.666, Upper Bound: 2.730)\n",
            "2026-12-01: 2.702 (Lower Bound: 2.670, Upper Bound: 2.734)\n",
            "2027-01-01: 2.706 (Lower Bound: 2.674, Upper Bound: 2.738)\n",
            "2027-02-01: 2.710 (Lower Bound: 2.678, Upper Bound: 2.742)\n",
            "2027-03-01: 2.713 (Lower Bound: 2.681, Upper Bound: 2.745)\n",
            "2027-04-01: 2.717 (Lower Bound: 2.685, Upper Bound: 2.749)\n",
            "2027-05-01: 2.720 (Lower Bound: 2.688, Upper Bound: 2.752)\n",
            "2027-06-01: 2.724 (Lower Bound: 2.692, Upper Bound: 2.756)\n",
            "2027-07-01: 2.728 (Lower Bound: 2.696, Upper Bound: 2.760)\n",
            "2027-08-01: 2.732 (Lower Bound: 2.700, Upper Bound: 2.764)\n",
            "2027-09-01: 2.736 (Lower Bound: 2.704, Upper Bound: 2.768)\n",
            "2027-10-01: 2.740 (Lower Bound: 2.708, Upper Bound: 2.772)\n",
            "2027-11-01: 2.744 (Lower Bound: 2.712, Upper Bound: 2.776)\n",
            "2027-12-01: 2.747 (Lower Bound: 2.715, Upper Bound: 2.779)\n",
            "2028-01-01: 2.750 (Lower Bound: 2.718, Upper Bound: 2.782)\n",
            "2028-02-01: 2.753 (Lower Bound: 2.722, Upper Bound: 2.785)\n",
            "2028-03-01: 2.757 (Lower Bound: 2.725, Upper Bound: 2.789)\n",
            "2028-04-01: 2.760 (Lower Bound: 2.728, Upper Bound: 2.792)\n",
            "2028-05-01: 2.763 (Lower Bound: 2.731, Upper Bound: 2.795)\n",
            "2028-06-01: 2.766 (Lower Bound: 2.734, Upper Bound: 2.797)\n",
            "2028-07-01: 2.768 (Lower Bound: 2.736, Upper Bound: 2.800)\n",
            "2028-08-01: 2.771 (Lower Bound: 2.739, Upper Bound: 2.803)\n",
            "2028-09-01: 2.774 (Lower Bound: 2.742, Upper Bound: 2.806)\n",
            "2028-10-01: 2.777 (Lower Bound: 2.745, Upper Bound: 2.809)\n",
            "2028-11-01: 2.780 (Lower Bound: 2.748, Upper Bound: 2.811)\n",
            "2028-12-01: 2.782 (Lower Bound: 2.750, Upper Bound: 2.814)\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from datetime import datetime\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import LSTM, Dense, Dropout\n",
        "\n",
        "# Read the dataset\n",
        "df = pd.read_excel('LNG (High).xlsx')\n",
        "\n",
        "# Function to calculate the number of months between two dates\n",
        "def months_between(start_date, end_date):\n",
        "    start_date = datetime.strptime(start_date, \"%Y-%m-%d\")\n",
        "    end_date = datetime.strptime(end_date, \"%Y-%m-%d\")\n",
        "    return (end_date.year - start_date.year) * 12 + end_date.month - start_date.month + 1\n",
        "\n",
        "# Define the date range\n",
        "start_date = '2024-04-01'\n",
        "end_date = '2028-12-01'\n",
        "\n",
        "# Calculate the number of months to predict\n",
        "num_months = months_between(start_date, end_date)\n",
        "\n",
        "# Ensure data is sorted by date\n",
        "df['Date'] = pd.to_datetime(df['Date'], format='%b-%y')\n",
        "df = df.sort_values(by=\"Date\", ascending=True)\n",
        "\n",
        "# Normalize the data\n",
        "scaler = MinMaxScaler(feature_range=(0, 1))\n",
        "df['Price_normalized'] = scaler.fit_transform(df['Price'].values.reshape(-1,1))\n",
        "\n",
        "# Create a new feature representing the number of months since start date\n",
        "df['Months_since_start'] = (df['Date'] - pd.to_datetime(start_date)).dt.days / 30\n",
        "\n",
        "# Prepare data for training\n",
        "X_train = df['Months_since_start'].values.reshape(-1, 1, 1)\n",
        "y_train = df['Price_normalized'].values\n",
        "\n",
        "# Define and train the LSTM model with increased dropout rate\n",
        "model = Sequential()\n",
        "model.add(LSTM(256, activation='relu', return_sequences=True, input_shape=(1, 1)))\n",
        "model.add(Dropout(0.5))  # Increase dropout rate\n",
        "model.add(LSTM(128, activation='relu', return_sequences=True))\n",
        "model.add(Dropout(0.5))  # Increase dropout rate\n",
        "model.add(LSTM(64, activation='relu'))\n",
        "model.add(Dropout(0.5))  # Increase dropout rate\n",
        "model.add(Dense(32, activation='relu'))\n",
        "model.add(Dense(1, activation='relu'))\n",
        "model.compile(optimizer='adam', loss='mean_squared_error')\n",
        "model.fit(X_train, y_train, epochs=200, batch_size=8)\n",
        "\n",
        "# Generate future indices for prediction\n",
        "X_future = np.arange(df['Months_since_start'].iloc[-1] + 1, df['Months_since_start'].iloc[-1] + 1 + num_months)\n",
        "X_future = X_future.reshape(-1, 1, 1)  # Reshape for LSTM input\n",
        "\n",
        "# Generate predictions\n",
        "y_pred_normalized = model.predict(X_future)\n",
        "\n",
        "# Inverse transform predictions to get actual prices\n",
        "y_pred = scaler.inverse_transform(y_pred_normalized)\n",
        "\n",
        "# Ensure predictions are non-negative\n",
        "y_pred = np.maximum(y_pred, 0)\n",
        "\n",
        "# Define a range of z-scores to try\n",
        "z_scores = [1.96, 2.25, 2.5, 3.0, 3.5, 4.0]\n",
        "\n",
        "# Print predicted prices with corresponding dates and confidence intervals for each z-score\n",
        "for z_score in z_scores:\n",
        "    std_dev = np.std(y_pred_normalized)  # Compute standard deviation\n",
        "    margin_of_error = z_score * std_dev  # Margin of error\n",
        "    lower_bound = y_pred - margin_of_error\n",
        "    upper_bound = y_pred + margin_of_error\n",
        "\n",
        "    # Generate date range for the predictions\n",
        "    dates = pd.date_range(start=start_date, periods=num_months, freq='MS')\n",
        "\n",
        "    # Print results\n",
        "    print(f\"\\nFor z-score = {z_score}:\")\n",
        "    for date, pred, lower, upper in zip(dates, y_pred.flatten(), lower_bound.flatten(), upper_bound.flatten()):\n",
        "        print(f\"{date.strftime('%Y-%m-%d')}: {pred:.3f} (Lower Bound: {lower:.3f}, Upper Bound: {upper:.3f})\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zBwqwfTaMqCY",
        "outputId": "b63000c3-99f7-42e8-e799-30d0c754c5ae"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/200\n",
            "19/19 [==============================] - 7s 21ms/step - loss: 0.0639\n",
            "Epoch 2/200\n",
            "19/19 [==============================] - 0s 21ms/step - loss: 0.0536\n",
            "Epoch 3/200\n",
            "19/19 [==============================] - 0s 20ms/step - loss: 0.0426\n",
            "Epoch 4/200\n",
            "19/19 [==============================] - 0s 19ms/step - loss: 0.0399\n",
            "Epoch 5/200\n",
            "19/19 [==============================] - 0s 22ms/step - loss: 0.0385\n",
            "Epoch 6/200\n",
            "19/19 [==============================] - 0s 23ms/step - loss: 0.0367\n",
            "Epoch 7/200\n",
            "19/19 [==============================] - 0s 22ms/step - loss: 0.0311\n",
            "Epoch 8/200\n",
            "19/19 [==============================] - 0s 22ms/step - loss: 0.0341\n",
            "Epoch 9/200\n",
            "19/19 [==============================] - 0s 21ms/step - loss: 0.0267\n",
            "Epoch 10/200\n",
            "19/19 [==============================] - 0s 21ms/step - loss: 0.0336\n",
            "Epoch 11/200\n",
            "19/19 [==============================] - 0s 19ms/step - loss: 0.0306\n",
            "Epoch 12/200\n",
            "19/19 [==============================] - 0s 24ms/step - loss: 0.0303\n",
            "Epoch 13/200\n",
            "19/19 [==============================] - 1s 26ms/step - loss: 0.0304\n",
            "Epoch 14/200\n",
            "19/19 [==============================] - 0s 26ms/step - loss: 0.0290\n",
            "Epoch 15/200\n",
            "19/19 [==============================] - 0s 25ms/step - loss: 0.0232\n",
            "Epoch 16/200\n",
            "19/19 [==============================] - 0s 24ms/step - loss: 0.0320\n",
            "Epoch 17/200\n",
            "19/19 [==============================] - 1s 30ms/step - loss: 0.0291\n",
            "Epoch 18/200\n",
            "19/19 [==============================] - 0s 24ms/step - loss: 0.0304\n",
            "Epoch 19/200\n",
            "19/19 [==============================] - 0s 25ms/step - loss: 0.0281\n",
            "Epoch 20/200\n",
            "19/19 [==============================] - 0s 24ms/step - loss: 0.0286\n",
            "Epoch 21/200\n",
            "19/19 [==============================] - 0s 26ms/step - loss: 0.0252\n",
            "Epoch 22/200\n",
            "19/19 [==============================] - 0s 21ms/step - loss: 0.0267\n",
            "Epoch 23/200\n",
            "19/19 [==============================] - 0s 20ms/step - loss: 0.0307\n",
            "Epoch 24/200\n",
            "19/19 [==============================] - 0s 22ms/step - loss: 0.0280\n",
            "Epoch 25/200\n",
            "19/19 [==============================] - 0s 21ms/step - loss: 0.0252\n",
            "Epoch 26/200\n",
            "19/19 [==============================] - 0s 22ms/step - loss: 0.0252\n",
            "Epoch 27/200\n",
            "19/19 [==============================] - 0s 23ms/step - loss: 0.0298\n",
            "Epoch 28/200\n",
            "19/19 [==============================] - 0s 22ms/step - loss: 0.0244\n",
            "Epoch 29/200\n",
            "19/19 [==============================] - 0s 21ms/step - loss: 0.0242\n",
            "Epoch 30/200\n",
            "19/19 [==============================] - 0s 19ms/step - loss: 0.0259\n",
            "Epoch 31/200\n",
            "19/19 [==============================] - 0s 22ms/step - loss: 0.0272\n",
            "Epoch 32/200\n",
            "19/19 [==============================] - 0s 19ms/step - loss: 0.0225\n",
            "Epoch 33/200\n",
            "19/19 [==============================] - 0s 12ms/step - loss: 0.0258\n",
            "Epoch 34/200\n",
            "19/19 [==============================] - 0s 12ms/step - loss: 0.0225\n",
            "Epoch 35/200\n",
            "19/19 [==============================] - 0s 12ms/step - loss: 0.0254\n",
            "Epoch 36/200\n",
            "19/19 [==============================] - 0s 11ms/step - loss: 0.0306\n",
            "Epoch 37/200\n",
            "19/19 [==============================] - 0s 11ms/step - loss: 0.0219\n",
            "Epoch 38/200\n",
            "19/19 [==============================] - 0s 12ms/step - loss: 0.0248\n",
            "Epoch 39/200\n",
            "19/19 [==============================] - 0s 12ms/step - loss: 0.0219\n",
            "Epoch 40/200\n",
            "19/19 [==============================] - 0s 11ms/step - loss: 0.0210\n",
            "Epoch 41/200\n",
            "19/19 [==============================] - 0s 12ms/step - loss: 0.0283\n",
            "Epoch 42/200\n",
            "19/19 [==============================] - 0s 12ms/step - loss: 0.0260\n",
            "Epoch 43/200\n",
            "19/19 [==============================] - 0s 14ms/step - loss: 0.0221\n",
            "Epoch 44/200\n",
            "19/19 [==============================] - 0s 12ms/step - loss: 0.0256\n",
            "Epoch 45/200\n",
            "19/19 [==============================] - 0s 12ms/step - loss: 0.0255\n",
            "Epoch 46/200\n",
            "19/19 [==============================] - 0s 12ms/step - loss: 0.0235\n",
            "Epoch 47/200\n",
            "19/19 [==============================] - 0s 12ms/step - loss: 0.0229\n",
            "Epoch 48/200\n",
            "19/19 [==============================] - 0s 11ms/step - loss: 0.0279\n",
            "Epoch 49/200\n",
            "19/19 [==============================] - 0s 13ms/step - loss: 0.0256\n",
            "Epoch 50/200\n",
            "19/19 [==============================] - 0s 11ms/step - loss: 0.0238\n",
            "Epoch 51/200\n",
            "19/19 [==============================] - 0s 12ms/step - loss: 0.0276\n",
            "Epoch 52/200\n",
            "19/19 [==============================] - 0s 12ms/step - loss: 0.0226\n",
            "Epoch 53/200\n",
            "19/19 [==============================] - 0s 11ms/step - loss: 0.0237\n",
            "Epoch 54/200\n",
            "19/19 [==============================] - 0s 12ms/step - loss: 0.0219\n",
            "Epoch 55/200\n",
            "19/19 [==============================] - 0s 11ms/step - loss: 0.0187\n",
            "Epoch 56/200\n",
            "19/19 [==============================] - 0s 18ms/step - loss: 0.0297\n",
            "Epoch 57/200\n",
            "19/19 [==============================] - 0s 21ms/step - loss: 0.0275\n",
            "Epoch 58/200\n",
            "19/19 [==============================] - 0s 21ms/step - loss: 0.0310\n",
            "Epoch 59/200\n",
            "19/19 [==============================] - 0s 20ms/step - loss: 0.0286\n",
            "Epoch 60/200\n",
            "19/19 [==============================] - 0s 20ms/step - loss: 0.0264\n",
            "Epoch 61/200\n",
            "19/19 [==============================] - 0s 21ms/step - loss: 0.0243\n",
            "Epoch 62/200\n",
            "19/19 [==============================] - 0s 21ms/step - loss: 0.0249\n",
            "Epoch 63/200\n",
            "19/19 [==============================] - 0s 22ms/step - loss: 0.0221\n",
            "Epoch 64/200\n",
            "19/19 [==============================] - 0s 20ms/step - loss: 0.0251\n",
            "Epoch 65/200\n",
            "19/19 [==============================] - 0s 12ms/step - loss: 0.0231\n",
            "Epoch 66/200\n",
            "19/19 [==============================] - 0s 11ms/step - loss: 0.0268\n",
            "Epoch 67/200\n",
            "19/19 [==============================] - 0s 11ms/step - loss: 0.0229\n",
            "Epoch 68/200\n",
            "19/19 [==============================] - 0s 12ms/step - loss: 0.0230\n",
            "Epoch 69/200\n",
            "19/19 [==============================] - 0s 11ms/step - loss: 0.0219\n",
            "Epoch 70/200\n",
            "19/19 [==============================] - 0s 11ms/step - loss: 0.0196\n",
            "Epoch 71/200\n",
            "19/19 [==============================] - 0s 11ms/step - loss: 0.0234\n",
            "Epoch 72/200\n",
            "19/19 [==============================] - 0s 12ms/step - loss: 0.0216\n",
            "Epoch 73/200\n",
            "19/19 [==============================] - 0s 12ms/step - loss: 0.0263\n",
            "Epoch 74/200\n",
            "19/19 [==============================] - 0s 11ms/step - loss: 0.0239\n",
            "Epoch 75/200\n",
            "19/19 [==============================] - 0s 11ms/step - loss: 0.0238\n",
            "Epoch 76/200\n",
            "19/19 [==============================] - 0s 11ms/step - loss: 0.0244\n",
            "Epoch 77/200\n",
            "19/19 [==============================] - 0s 12ms/step - loss: 0.0269\n",
            "Epoch 78/200\n",
            "19/19 [==============================] - 0s 11ms/step - loss: 0.0270\n",
            "Epoch 79/200\n",
            "19/19 [==============================] - 0s 11ms/step - loss: 0.0248\n",
            "Epoch 80/200\n",
            "19/19 [==============================] - 0s 11ms/step - loss: 0.0220\n",
            "Epoch 81/200\n",
            "19/19 [==============================] - 0s 11ms/step - loss: 0.0230\n",
            "Epoch 82/200\n",
            "19/19 [==============================] - 0s 12ms/step - loss: 0.0264\n",
            "Epoch 83/200\n",
            "19/19 [==============================] - 0s 11ms/step - loss: 0.0245\n",
            "Epoch 84/200\n",
            "19/19 [==============================] - 0s 11ms/step - loss: 0.0184\n",
            "Epoch 85/200\n",
            "19/19 [==============================] - 0s 11ms/step - loss: 0.0250\n",
            "Epoch 86/200\n",
            "19/19 [==============================] - 0s 12ms/step - loss: 0.0221\n",
            "Epoch 87/200\n",
            "19/19 [==============================] - 0s 12ms/step - loss: 0.0209\n",
            "Epoch 88/200\n",
            "19/19 [==============================] - 0s 12ms/step - loss: 0.0291\n",
            "Epoch 89/200\n",
            "19/19 [==============================] - 0s 11ms/step - loss: 0.0199\n",
            "Epoch 90/200\n",
            "19/19 [==============================] - 0s 11ms/step - loss: 0.0242\n",
            "Epoch 91/200\n",
            "19/19 [==============================] - 0s 12ms/step - loss: 0.0204\n",
            "Epoch 92/200\n",
            "19/19 [==============================] - 0s 11ms/step - loss: 0.0222\n",
            "Epoch 93/200\n",
            "19/19 [==============================] - 0s 11ms/step - loss: 0.0210\n",
            "Epoch 94/200\n",
            "19/19 [==============================] - 0s 11ms/step - loss: 0.0255\n",
            "Epoch 95/200\n",
            "19/19 [==============================] - 0s 12ms/step - loss: 0.0250\n",
            "Epoch 96/200\n",
            "19/19 [==============================] - 0s 13ms/step - loss: 0.0294\n",
            "Epoch 97/200\n",
            "19/19 [==============================] - 0s 12ms/step - loss: 0.0167\n",
            "Epoch 98/200\n",
            "19/19 [==============================] - 0s 12ms/step - loss: 0.0242\n",
            "Epoch 99/200\n",
            "19/19 [==============================] - 0s 11ms/step - loss: 0.0172\n",
            "Epoch 100/200\n",
            "19/19 [==============================] - 0s 12ms/step - loss: 0.0203\n",
            "Epoch 101/200\n",
            "19/19 [==============================] - 0s 12ms/step - loss: 0.0226\n",
            "Epoch 102/200\n",
            "19/19 [==============================] - 0s 11ms/step - loss: 0.0219\n",
            "Epoch 103/200\n",
            "19/19 [==============================] - 0s 12ms/step - loss: 0.0201\n",
            "Epoch 104/200\n",
            "19/19 [==============================] - 0s 12ms/step - loss: 0.0185\n",
            "Epoch 105/200\n",
            "19/19 [==============================] - 0s 12ms/step - loss: 0.0274\n",
            "Epoch 106/200\n",
            "19/19 [==============================] - 0s 12ms/step - loss: 0.0167\n",
            "Epoch 107/200\n",
            "19/19 [==============================] - 0s 12ms/step - loss: 0.0245\n",
            "Epoch 108/200\n",
            "19/19 [==============================] - 0s 12ms/step - loss: 0.0160\n",
            "Epoch 109/200\n",
            "19/19 [==============================] - 0s 20ms/step - loss: 0.0185\n",
            "Epoch 110/200\n",
            "19/19 [==============================] - 0s 20ms/step - loss: 0.0132\n",
            "Epoch 111/200\n",
            "19/19 [==============================] - 0s 20ms/step - loss: 0.0164\n",
            "Epoch 112/200\n",
            "19/19 [==============================] - 0s 20ms/step - loss: 0.0181\n",
            "Epoch 113/200\n",
            "19/19 [==============================] - 0s 21ms/step - loss: 0.0176\n",
            "Epoch 114/200\n",
            "19/19 [==============================] - 0s 21ms/step - loss: 0.0186\n",
            "Epoch 115/200\n",
            "19/19 [==============================] - 0s 20ms/step - loss: 0.0196\n",
            "Epoch 116/200\n",
            "19/19 [==============================] - 0s 20ms/step - loss: 0.0190\n",
            "Epoch 117/200\n",
            "19/19 [==============================] - 0s 21ms/step - loss: 0.0247\n",
            "Epoch 118/200\n",
            "19/19 [==============================] - 0s 20ms/step - loss: 0.0187\n",
            "Epoch 119/200\n",
            "19/19 [==============================] - 0s 17ms/step - loss: 0.0228\n",
            "Epoch 120/200\n",
            "19/19 [==============================] - 0s 12ms/step - loss: 0.0199\n",
            "Epoch 121/200\n",
            "19/19 [==============================] - 0s 12ms/step - loss: 0.0222\n",
            "Epoch 122/200\n",
            "19/19 [==============================] - 0s 12ms/step - loss: 0.0185\n",
            "Epoch 123/200\n",
            "19/19 [==============================] - 0s 11ms/step - loss: 0.0191\n",
            "Epoch 124/200\n",
            "19/19 [==============================] - 0s 13ms/step - loss: 0.0202\n",
            "Epoch 125/200\n",
            "19/19 [==============================] - 0s 12ms/step - loss: 0.0219\n",
            "Epoch 126/200\n",
            "19/19 [==============================] - 0s 12ms/step - loss: 0.0171\n",
            "Epoch 127/200\n",
            "19/19 [==============================] - 0s 12ms/step - loss: 0.0165\n",
            "Epoch 128/200\n",
            "19/19 [==============================] - 0s 11ms/step - loss: 0.0211\n",
            "Epoch 129/200\n",
            "19/19 [==============================] - 0s 12ms/step - loss: 0.0164\n",
            "Epoch 130/200\n",
            "19/19 [==============================] - 0s 12ms/step - loss: 0.0271\n",
            "Epoch 131/200\n",
            "19/19 [==============================] - 0s 12ms/step - loss: 0.0194\n",
            "Epoch 132/200\n",
            "19/19 [==============================] - 0s 11ms/step - loss: 0.0202\n",
            "Epoch 133/200\n",
            "19/19 [==============================] - 0s 12ms/step - loss: 0.0157\n",
            "Epoch 134/200\n",
            "19/19 [==============================] - 0s 11ms/step - loss: 0.0138\n",
            "Epoch 135/200\n",
            "19/19 [==============================] - 0s 12ms/step - loss: 0.0233\n",
            "Epoch 136/200\n",
            "19/19 [==============================] - 0s 12ms/step - loss: 0.0170\n",
            "Epoch 137/200\n",
            "19/19 [==============================] - 0s 13ms/step - loss: 0.0172\n",
            "Epoch 138/200\n",
            "19/19 [==============================] - 0s 12ms/step - loss: 0.0224\n",
            "Epoch 139/200\n",
            "19/19 [==============================] - 0s 12ms/step - loss: 0.0139\n",
            "Epoch 140/200\n",
            "19/19 [==============================] - 0s 12ms/step - loss: 0.0164\n",
            "Epoch 141/200\n",
            "19/19 [==============================] - 0s 12ms/step - loss: 0.0197\n",
            "Epoch 142/200\n",
            "19/19 [==============================] - 0s 13ms/step - loss: 0.0224\n",
            "Epoch 143/200\n",
            "19/19 [==============================] - 0s 12ms/step - loss: 0.0147\n",
            "Epoch 144/200\n",
            "19/19 [==============================] - 0s 12ms/step - loss: 0.0155\n",
            "Epoch 145/200\n",
            "19/19 [==============================] - 0s 12ms/step - loss: 0.0167\n",
            "Epoch 146/200\n",
            "19/19 [==============================] - 0s 13ms/step - loss: 0.0191\n",
            "Epoch 147/200\n",
            "19/19 [==============================] - 0s 12ms/step - loss: 0.0179\n",
            "Epoch 148/200\n",
            "19/19 [==============================] - 0s 12ms/step - loss: 0.0201\n",
            "Epoch 149/200\n",
            "19/19 [==============================] - 0s 12ms/step - loss: 0.0180\n",
            "Epoch 150/200\n",
            "19/19 [==============================] - 0s 12ms/step - loss: 0.0211\n",
            "Epoch 151/200\n",
            "19/19 [==============================] - 0s 12ms/step - loss: 0.0144\n",
            "Epoch 152/200\n",
            "19/19 [==============================] - 0s 11ms/step - loss: 0.0112\n",
            "Epoch 153/200\n",
            "19/19 [==============================] - 0s 12ms/step - loss: 0.0159\n",
            "Epoch 154/200\n",
            "19/19 [==============================] - 0s 12ms/step - loss: 0.0169\n",
            "Epoch 155/200\n",
            "19/19 [==============================] - 0s 13ms/step - loss: 0.0185\n",
            "Epoch 156/200\n",
            "19/19 [==============================] - 0s 12ms/step - loss: 0.0160\n",
            "Epoch 157/200\n",
            "19/19 [==============================] - 0s 12ms/step - loss: 0.0152\n",
            "Epoch 158/200\n",
            "19/19 [==============================] - 0s 12ms/step - loss: 0.0170\n",
            "Epoch 159/200\n",
            "19/19 [==============================] - 0s 13ms/step - loss: 0.0162\n",
            "Epoch 160/200\n",
            "19/19 [==============================] - 0s 12ms/step - loss: 0.0165\n",
            "Epoch 161/200\n",
            "19/19 [==============================] - 0s 12ms/step - loss: 0.0199\n",
            "Epoch 162/200\n",
            "19/19 [==============================] - 0s 20ms/step - loss: 0.0212\n",
            "Epoch 163/200\n",
            "19/19 [==============================] - 0s 22ms/step - loss: 0.0194\n",
            "Epoch 164/200\n",
            "19/19 [==============================] - 0s 20ms/step - loss: 0.0143\n",
            "Epoch 165/200\n",
            "19/19 [==============================] - 0s 20ms/step - loss: 0.0175\n",
            "Epoch 166/200\n",
            "19/19 [==============================] - 0s 20ms/step - loss: 0.0192\n",
            "Epoch 167/200\n",
            "19/19 [==============================] - 0s 20ms/step - loss: 0.0123\n",
            "Epoch 168/200\n",
            "19/19 [==============================] - 0s 21ms/step - loss: 0.0196\n",
            "Epoch 169/200\n",
            "19/19 [==============================] - 0s 20ms/step - loss: 0.0175\n",
            "Epoch 170/200\n",
            "19/19 [==============================] - 0s 20ms/step - loss: 0.0185\n",
            "Epoch 171/200\n",
            "19/19 [==============================] - 0s 20ms/step - loss: 0.0171\n",
            "Epoch 172/200\n",
            "19/19 [==============================] - 0s 21ms/step - loss: 0.0174\n",
            "Epoch 173/200\n",
            "19/19 [==============================] - 0s 12ms/step - loss: 0.0174\n",
            "Epoch 174/200\n",
            "19/19 [==============================] - 0s 13ms/step - loss: 0.0131\n",
            "Epoch 175/200\n",
            "19/19 [==============================] - 0s 12ms/step - loss: 0.0156\n",
            "Epoch 176/200\n",
            "19/19 [==============================] - 0s 12ms/step - loss: 0.0199\n",
            "Epoch 177/200\n",
            "19/19 [==============================] - 0s 13ms/step - loss: 0.0169\n",
            "Epoch 178/200\n",
            "19/19 [==============================] - 0s 12ms/step - loss: 0.0129\n",
            "Epoch 179/200\n",
            "19/19 [==============================] - 0s 13ms/step - loss: 0.0155\n",
            "Epoch 180/200\n",
            "19/19 [==============================] - 0s 12ms/step - loss: 0.0159\n",
            "Epoch 181/200\n",
            "19/19 [==============================] - 0s 12ms/step - loss: 0.0167\n",
            "Epoch 182/200\n",
            "19/19 [==============================] - 0s 12ms/step - loss: 0.0150\n",
            "Epoch 183/200\n",
            "19/19 [==============================] - 0s 12ms/step - loss: 0.0142\n",
            "Epoch 184/200\n",
            "19/19 [==============================] - 0s 12ms/step - loss: 0.0157\n",
            "Epoch 185/200\n",
            "19/19 [==============================] - 0s 12ms/step - loss: 0.0193\n",
            "Epoch 186/200\n",
            "19/19 [==============================] - 0s 11ms/step - loss: 0.0159\n",
            "Epoch 187/200\n",
            "19/19 [==============================] - 0s 13ms/step - loss: 0.0168\n",
            "Epoch 188/200\n",
            "19/19 [==============================] - 0s 11ms/step - loss: 0.0152\n",
            "Epoch 189/200\n",
            "19/19 [==============================] - 0s 12ms/step - loss: 0.0175\n",
            "Epoch 190/200\n",
            "19/19 [==============================] - 0s 11ms/step - loss: 0.0148\n",
            "Epoch 191/200\n",
            "19/19 [==============================] - 0s 12ms/step - loss: 0.0149\n",
            "Epoch 192/200\n",
            "19/19 [==============================] - 0s 12ms/step - loss: 0.0153\n",
            "Epoch 193/200\n",
            "19/19 [==============================] - 0s 11ms/step - loss: 0.0170\n",
            "Epoch 194/200\n",
            "19/19 [==============================] - 0s 12ms/step - loss: 0.0181\n",
            "Epoch 195/200\n",
            "19/19 [==============================] - 0s 12ms/step - loss: 0.0170\n",
            "Epoch 196/200\n",
            "19/19 [==============================] - 0s 13ms/step - loss: 0.0183\n",
            "Epoch 197/200\n",
            "19/19 [==============================] - 0s 11ms/step - loss: 0.0165\n",
            "Epoch 198/200\n",
            "19/19 [==============================] - 0s 12ms/step - loss: 0.0122\n",
            "Epoch 199/200\n",
            "19/19 [==============================] - 0s 12ms/step - loss: 0.0155\n",
            "Epoch 200/200\n",
            "19/19 [==============================] - 0s 12ms/step - loss: 0.0188\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Predicted prices from 2024-04-01 to 2028-12-01:\n",
            "2024-04-01: 2.796 (Lower Bound: 2.726, Upper Bound: 2.866)\n",
            "2024-05-01: 2.833 (Lower Bound: 2.763, Upper Bound: 2.903)\n",
            "2024-06-01: 2.846 (Lower Bound: 2.776, Upper Bound: 2.916)\n",
            "2024-07-01: 2.849 (Lower Bound: 2.779, Upper Bound: 2.919)\n",
            "2024-08-01: 2.849 (Lower Bound: 2.779, Upper Bound: 2.919)\n",
            "2024-09-01: 2.855 (Lower Bound: 2.785, Upper Bound: 2.925)\n",
            "2024-10-01: 2.861 (Lower Bound: 2.791, Upper Bound: 2.931)\n",
            "2024-11-01: 2.868 (Lower Bound: 2.798, Upper Bound: 2.937)\n",
            "2024-12-01: 2.876 (Lower Bound: 2.806, Upper Bound: 2.945)\n",
            "2025-01-01: 2.884 (Lower Bound: 2.814, Upper Bound: 2.954)\n",
            "2025-02-01: 2.893 (Lower Bound: 2.823, Upper Bound: 2.962)\n",
            "2025-03-01: 2.901 (Lower Bound: 2.832, Upper Bound: 2.971)\n",
            "2025-04-01: 2.911 (Lower Bound: 2.841, Upper Bound: 2.980)\n",
            "2025-05-01: 2.925 (Lower Bound: 2.855, Upper Bound: 2.995)\n",
            "2025-06-01: 2.942 (Lower Bound: 2.873, Upper Bound: 3.012)\n",
            "2025-07-01: 2.960 (Lower Bound: 2.890, Upper Bound: 3.030)\n",
            "2025-08-01: 2.979 (Lower Bound: 2.909, Upper Bound: 3.049)\n",
            "2025-09-01: 3.005 (Lower Bound: 2.935, Upper Bound: 3.075)\n",
            "2025-10-01: 3.031 (Lower Bound: 2.961, Upper Bound: 3.101)\n",
            "2025-11-01: 3.057 (Lower Bound: 2.987, Upper Bound: 3.127)\n",
            "2025-12-01: 3.082 (Lower Bound: 3.012, Upper Bound: 3.152)\n",
            "2026-01-01: 3.107 (Lower Bound: 3.037, Upper Bound: 3.177)\n",
            "2026-02-01: 3.133 (Lower Bound: 3.063, Upper Bound: 3.203)\n",
            "2026-03-01: 3.159 (Lower Bound: 3.089, Upper Bound: 3.229)\n",
            "2026-04-01: 3.185 (Lower Bound: 3.115, Upper Bound: 3.255)\n",
            "2026-05-01: 3.211 (Lower Bound: 3.142, Upper Bound: 3.281)\n",
            "2026-06-01: 3.238 (Lower Bound: 3.168, Upper Bound: 3.308)\n",
            "2026-07-01: 3.264 (Lower Bound: 3.194, Upper Bound: 3.334)\n",
            "2026-08-01: 3.290 (Lower Bound: 3.220, Upper Bound: 3.360)\n",
            "2026-09-01: 3.316 (Lower Bound: 3.247, Upper Bound: 3.386)\n",
            "2026-10-01: 3.342 (Lower Bound: 3.272, Upper Bound: 3.412)\n",
            "2026-11-01: 3.368 (Lower Bound: 3.298, Upper Bound: 3.438)\n",
            "2026-12-01: 3.393 (Lower Bound: 3.323, Upper Bound: 3.463)\n",
            "2027-01-01: 3.418 (Lower Bound: 3.348, Upper Bound: 3.488)\n",
            "2027-02-01: 3.442 (Lower Bound: 3.372, Upper Bound: 3.512)\n",
            "2027-03-01: 3.466 (Lower Bound: 3.396, Upper Bound: 3.536)\n",
            "2027-04-01: 3.490 (Lower Bound: 3.420, Upper Bound: 3.560)\n",
            "2027-05-01: 3.513 (Lower Bound: 3.443, Upper Bound: 3.583)\n",
            "2027-06-01: 3.535 (Lower Bound: 3.465, Upper Bound: 3.605)\n",
            "2027-07-01: 3.557 (Lower Bound: 3.488, Upper Bound: 3.627)\n",
            "2027-08-01: 3.579 (Lower Bound: 3.509, Upper Bound: 3.649)\n",
            "2027-09-01: 3.600 (Lower Bound: 3.530, Upper Bound: 3.670)\n",
            "2027-10-01: 3.620 (Lower Bound: 3.550, Upper Bound: 3.690)\n",
            "2027-11-01: 3.640 (Lower Bound: 3.570, Upper Bound: 3.710)\n",
            "2027-12-01: 3.659 (Lower Bound: 3.590, Upper Bound: 3.729)\n",
            "2028-01-01: 3.678 (Lower Bound: 3.608, Upper Bound: 3.748)\n",
            "2028-02-01: 3.697 (Lower Bound: 3.627, Upper Bound: 3.766)\n",
            "2028-03-01: 3.714 (Lower Bound: 3.645, Upper Bound: 3.784)\n",
            "2028-04-01: 3.732 (Lower Bound: 3.662, Upper Bound: 3.802)\n",
            "2028-05-01: 3.749 (Lower Bound: 3.679, Upper Bound: 3.819)\n",
            "2028-06-01: 3.765 (Lower Bound: 3.695, Upper Bound: 3.835)\n",
            "2028-07-01: 3.781 (Lower Bound: 3.711, Upper Bound: 3.851)\n",
            "2028-08-01: 3.797 (Lower Bound: 3.727, Upper Bound: 3.867)\n",
            "2028-09-01: 3.812 (Lower Bound: 3.742, Upper Bound: 3.882)\n",
            "2028-10-01: 3.827 (Lower Bound: 3.757, Upper Bound: 3.897)\n",
            "2028-11-01: 3.841 (Lower Bound: 3.771, Upper Bound: 3.911)\n",
            "2028-12-01: 3.855 (Lower Bound: 3.785, Upper Bound: 3.925)\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from datetime import datetime\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import LSTM, Dense, Dropout\n",
        "\n",
        "# Read the dataset\n",
        "df = pd.read_excel('LNG (High).xlsx')\n",
        "\n",
        "# Function to calculate the number of months between two dates\n",
        "def months_between(start_date, end_date):\n",
        "    start_date = datetime.strptime(start_date, \"%Y-%m-%d\")\n",
        "    end_date = datetime.strptime(end_date, \"%Y-%m-%d\")\n",
        "    return (end_date.year - start_date.year) * 12 + end_date.month - start_date.month + 1\n",
        "\n",
        "# Define the date range\n",
        "start_date = '2024-04-01'\n",
        "end_date = '2028-12-01'\n",
        "\n",
        "# Calculate the number of months to predict\n",
        "num_months = months_between(start_date, end_date)\n",
        "\n",
        "# Ensure data is sorted by date\n",
        "df['Date'] = pd.to_datetime(df['Date'], format='%b-%y')\n",
        "df = df.sort_values(by=\"Date\", ascending=True)\n",
        "\n",
        "# Normalize the data\n",
        "scaler = MinMaxScaler(feature_range=(0, 1))\n",
        "df['Price_normalized'] = scaler.fit_transform(df['Price'].values.reshape(-1,1))\n",
        "\n",
        "# Create a new feature representing the number of months since start date\n",
        "df['Months_since_start'] = (df['Date'] - pd.to_datetime(start_date)).dt.days / 30\n",
        "\n",
        "# Prepare data for training\n",
        "X_train = df['Months_since_start'].values.reshape(-1, 1, 1)\n",
        "y_train = df['Price_normalized'].values\n",
        "\n",
        "# Define and train the LSTM model with increased dropout rate\n",
        "model = Sequential()\n",
        "model.add(LSTM(256, activation='relu', return_sequences=True, input_shape=(1, 1)))\n",
        "model.add(Dropout(0.5))  # Increase dropout rate\n",
        "model.add(LSTM(128, activation='relu', return_sequences=True))\n",
        "model.add(Dropout(0.5))  # Increase dropout rate\n",
        "model.add(LSTM(64, activation='relu'))\n",
        "model.add(Dropout(0.5))  # Increase dropout rate\n",
        "model.add(Dense(32, activation='relu'))\n",
        "model.add(Dense(1, activation='relu'))\n",
        "model.compile(optimizer='adam', loss='mean_squared_error')\n",
        "model.fit(X_train, y_train, epochs=200, batch_size=8)\n",
        "\n",
        "# Generate future indices for prediction\n",
        "X_future = np.arange(df['Months_since_start'].iloc[-1] + 1, df['Months_since_start'].iloc[-1] + 1 + num_months)\n",
        "X_future = X_future.reshape(-1, 1, 1)  # Reshape for LSTM input\n",
        "\n",
        "# Generate predictions\n",
        "y_pred_normalized = model.predict(X_future)\n",
        "\n",
        "# Inverse transform predictions to get actual prices\n",
        "y_pred = scaler.inverse_transform(y_pred_normalized)\n",
        "\n",
        "# Ensure predictions are non-negative\n",
        "y_pred = np.maximum(y_pred, 0)\n",
        "\n",
        "# Compute confidence interval bounds\n",
        "confidence_level = 0.80  # Set confidence level\n",
        "z_score = 1.645  # Z-score for 80% confidence level (corresponds to wider interval)\n",
        "std_dev = np.std(y_pred_normalized)  # Compute standard deviation\n",
        "margin_of_error = z_score * std_dev  # Margin of error\n",
        "lower_bound = y_pred - margin_of_error\n",
        "upper_bound = y_pred + margin_of_error\n",
        "\n",
        "# Generate date range for the predictions\n",
        "dates = pd.date_range(start=start_date, periods=num_months, freq='MS')\n",
        "\n",
        "# Print predicted prices with corresponding dates and confidence intervals\n",
        "print(\"Predicted prices from 2024-04-01 to 2028-12-01:\")\n",
        "for date, pred, lower, upper in zip(dates, y_pred.flatten(), lower_bound.flatten(), upper_bound.flatten()):\n",
        "    print(f\"{date.strftime('%Y-%m-%d')}: {pred:.3f} (Lower Bound: {lower:.3f}, Upper Bound: {upper:.3f})\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3qJ3_pRJN-PG",
        "outputId": "38648ad8-6c94-44dd-9bb6-a9c4724bc4a0"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/200\n",
            "19/19 [==============================] - 8s 19ms/step - loss: 0.0794\n",
            "Epoch 2/200\n",
            "19/19 [==============================] - 0s 21ms/step - loss: 0.0536\n",
            "Epoch 3/200\n",
            "19/19 [==============================] - 0s 21ms/step - loss: 0.0458\n",
            "Epoch 4/200\n",
            "19/19 [==============================] - 0s 21ms/step - loss: 0.0411\n",
            "Epoch 5/200\n",
            "19/19 [==============================] - 0s 21ms/step - loss: 0.0401\n",
            "Epoch 6/200\n",
            "19/19 [==============================] - 0s 20ms/step - loss: 0.0348\n",
            "Epoch 7/200\n",
            "19/19 [==============================] - 0s 21ms/step - loss: 0.0360\n",
            "Epoch 8/200\n",
            "19/19 [==============================] - 0s 22ms/step - loss: 0.0325\n",
            "Epoch 9/200\n",
            "19/19 [==============================] - 0s 21ms/step - loss: 0.0288\n",
            "Epoch 10/200\n",
            "19/19 [==============================] - 0s 22ms/step - loss: 0.0335\n",
            "Epoch 11/200\n",
            "19/19 [==============================] - 0s 21ms/step - loss: 0.0337\n",
            "Epoch 12/200\n",
            "19/19 [==============================] - 0s 23ms/step - loss: 0.0290\n",
            "Epoch 13/200\n",
            "19/19 [==============================] - 1s 28ms/step - loss: 0.0346\n",
            "Epoch 14/200\n",
            "19/19 [==============================] - 1s 27ms/step - loss: 0.0314\n",
            "Epoch 15/200\n",
            "19/19 [==============================] - 1s 29ms/step - loss: 0.0225\n",
            "Epoch 16/200\n",
            "19/19 [==============================] - 0s 24ms/step - loss: 0.0301\n",
            "Epoch 17/200\n",
            "19/19 [==============================] - 0s 23ms/step - loss: 0.0230\n",
            "Epoch 18/200\n",
            "19/19 [==============================] - 0s 23ms/step - loss: 0.0296\n",
            "Epoch 19/200\n",
            "19/19 [==============================] - 0s 23ms/step - loss: 0.0277\n",
            "Epoch 20/200\n",
            "19/19 [==============================] - 0s 24ms/step - loss: 0.0299\n",
            "Epoch 21/200\n",
            "19/19 [==============================] - 0s 24ms/step - loss: 0.0233\n",
            "Epoch 22/200\n",
            "19/19 [==============================] - 0s 23ms/step - loss: 0.0322\n",
            "Epoch 23/200\n",
            "19/19 [==============================] - 0s 20ms/step - loss: 0.0297\n",
            "Epoch 24/200\n",
            "19/19 [==============================] - 0s 21ms/step - loss: 0.0271\n",
            "Epoch 25/200\n",
            "19/19 [==============================] - 0s 21ms/step - loss: 0.0268\n",
            "Epoch 26/200\n",
            "19/19 [==============================] - 0s 22ms/step - loss: 0.0233\n",
            "Epoch 27/200\n",
            "19/19 [==============================] - 0s 21ms/step - loss: 0.0296\n",
            "Epoch 28/200\n",
            "19/19 [==============================] - 0s 21ms/step - loss: 0.0317\n",
            "Epoch 29/200\n",
            "19/19 [==============================] - 0s 21ms/step - loss: 0.0238\n",
            "Epoch 30/200\n",
            "19/19 [==============================] - 0s 21ms/step - loss: 0.0248\n",
            "Epoch 31/200\n",
            "19/19 [==============================] - 0s 22ms/step - loss: 0.0320\n",
            "Epoch 32/200\n",
            "19/19 [==============================] - 0s 22ms/step - loss: 0.0236\n",
            "Epoch 33/200\n",
            "19/19 [==============================] - 0s 22ms/step - loss: 0.0357\n",
            "Epoch 34/200\n",
            "19/19 [==============================] - 0s 22ms/step - loss: 0.0266\n",
            "Epoch 35/200\n",
            "19/19 [==============================] - 0s 23ms/step - loss: 0.0270\n",
            "Epoch 36/200\n",
            "19/19 [==============================] - 0s 11ms/step - loss: 0.0279\n",
            "Epoch 37/200\n",
            "19/19 [==============================] - 0s 13ms/step - loss: 0.0306\n",
            "Epoch 38/200\n",
            "19/19 [==============================] - 0s 11ms/step - loss: 0.0298\n",
            "Epoch 39/200\n",
            "19/19 [==============================] - 0s 11ms/step - loss: 0.0282\n",
            "Epoch 40/200\n",
            "19/19 [==============================] - 0s 11ms/step - loss: 0.0296\n",
            "Epoch 41/200\n",
            "19/19 [==============================] - 0s 12ms/step - loss: 0.0265\n",
            "Epoch 42/200\n",
            "19/19 [==============================] - 0s 12ms/step - loss: 0.0272\n",
            "Epoch 43/200\n",
            "19/19 [==============================] - 0s 11ms/step - loss: 0.0262\n",
            "Epoch 44/200\n",
            "19/19 [==============================] - 0s 11ms/step - loss: 0.0198\n",
            "Epoch 45/200\n",
            "19/19 [==============================] - 0s 11ms/step - loss: 0.0324\n",
            "Epoch 46/200\n",
            "19/19 [==============================] - 0s 12ms/step - loss: 0.0251\n",
            "Epoch 47/200\n",
            "19/19 [==============================] - 0s 14ms/step - loss: 0.0224\n",
            "Epoch 48/200\n",
            "19/19 [==============================] - 0s 11ms/step - loss: 0.0232\n",
            "Epoch 49/200\n",
            "19/19 [==============================] - 0s 11ms/step - loss: 0.0240\n",
            "Epoch 50/200\n",
            "19/19 [==============================] - 0s 12ms/step - loss: 0.0251\n",
            "Epoch 51/200\n",
            "19/19 [==============================] - 0s 11ms/step - loss: 0.0247\n",
            "Epoch 52/200\n",
            "19/19 [==============================] - 0s 12ms/step - loss: 0.0258\n",
            "Epoch 53/200\n",
            "19/19 [==============================] - 0s 11ms/step - loss: 0.0238\n",
            "Epoch 54/200\n",
            "19/19 [==============================] - 0s 12ms/step - loss: 0.0254\n",
            "Epoch 55/200\n",
            "19/19 [==============================] - 0s 20ms/step - loss: 0.0256\n",
            "Epoch 56/200\n",
            "19/19 [==============================] - 0s 20ms/step - loss: 0.0285\n",
            "Epoch 57/200\n",
            "19/19 [==============================] - 0s 20ms/step - loss: 0.0255\n",
            "Epoch 58/200\n",
            "19/19 [==============================] - 0s 20ms/step - loss: 0.0238\n",
            "Epoch 59/200\n",
            "19/19 [==============================] - 0s 19ms/step - loss: 0.0206\n",
            "Epoch 60/200\n",
            "19/19 [==============================] - 0s 21ms/step - loss: 0.0216\n",
            "Epoch 61/200\n",
            "19/19 [==============================] - 0s 21ms/step - loss: 0.0260\n",
            "Epoch 62/200\n",
            "19/19 [==============================] - 0s 21ms/step - loss: 0.0338\n",
            "Epoch 63/200\n",
            "19/19 [==============================] - 0s 21ms/step - loss: 0.0277\n",
            "Epoch 64/200\n",
            "19/19 [==============================] - 0s 20ms/step - loss: 0.0246\n",
            "Epoch 65/200\n",
            "19/19 [==============================] - 0s 13ms/step - loss: 0.0231\n",
            "Epoch 66/200\n",
            "19/19 [==============================] - 0s 12ms/step - loss: 0.0214\n",
            "Epoch 67/200\n",
            "19/19 [==============================] - 0s 11ms/step - loss: 0.0250\n",
            "Epoch 68/200\n",
            "19/19 [==============================] - 0s 11ms/step - loss: 0.0224\n",
            "Epoch 69/200\n",
            "19/19 [==============================] - 0s 12ms/step - loss: 0.0220\n",
            "Epoch 70/200\n",
            "19/19 [==============================] - 0s 12ms/step - loss: 0.0198\n",
            "Epoch 71/200\n",
            "19/19 [==============================] - 0s 12ms/step - loss: 0.0221\n",
            "Epoch 72/200\n",
            "19/19 [==============================] - 0s 11ms/step - loss: 0.0198\n",
            "Epoch 73/200\n",
            "19/19 [==============================] - 0s 11ms/step - loss: 0.0221\n",
            "Epoch 74/200\n",
            "19/19 [==============================] - 0s 12ms/step - loss: 0.0226\n",
            "Epoch 75/200\n",
            "19/19 [==============================] - 0s 12ms/step - loss: 0.0194\n",
            "Epoch 76/200\n",
            "19/19 [==============================] - 0s 11ms/step - loss: 0.0247\n",
            "Epoch 77/200\n",
            "19/19 [==============================] - 0s 11ms/step - loss: 0.0209\n",
            "Epoch 78/200\n",
            "19/19 [==============================] - 0s 12ms/step - loss: 0.0225\n",
            "Epoch 79/200\n",
            "19/19 [==============================] - 0s 12ms/step - loss: 0.0248\n",
            "Epoch 80/200\n",
            "19/19 [==============================] - 0s 12ms/step - loss: 0.0187\n",
            "Epoch 81/200\n",
            "19/19 [==============================] - 0s 11ms/step - loss: 0.0212\n",
            "Epoch 82/200\n",
            "19/19 [==============================] - 0s 11ms/step - loss: 0.0230\n",
            "Epoch 83/200\n",
            "19/19 [==============================] - 0s 12ms/step - loss: 0.0182\n",
            "Epoch 84/200\n",
            "19/19 [==============================] - 0s 11ms/step - loss: 0.0215\n",
            "Epoch 85/200\n",
            "19/19 [==============================] - 0s 12ms/step - loss: 0.0172\n",
            "Epoch 86/200\n",
            "19/19 [==============================] - 0s 11ms/step - loss: 0.0214\n",
            "Epoch 87/200\n",
            "19/19 [==============================] - 0s 12ms/step - loss: 0.0188\n",
            "Epoch 88/200\n",
            "19/19 [==============================] - 0s 11ms/step - loss: 0.0187\n",
            "Epoch 89/200\n",
            "19/19 [==============================] - 0s 12ms/step - loss: 0.0149\n",
            "Epoch 90/200\n",
            "19/19 [==============================] - 0s 11ms/step - loss: 0.0193\n",
            "Epoch 91/200\n",
            "19/19 [==============================] - 0s 11ms/step - loss: 0.0201\n",
            "Epoch 92/200\n",
            "19/19 [==============================] - 0s 12ms/step - loss: 0.0163\n",
            "Epoch 93/200\n",
            "19/19 [==============================] - 0s 11ms/step - loss: 0.0190\n",
            "Epoch 94/200\n",
            "19/19 [==============================] - 0s 13ms/step - loss: 0.0203\n",
            "Epoch 95/200\n",
            "19/19 [==============================] - 0s 11ms/step - loss: 0.0172\n",
            "Epoch 96/200\n",
            "19/19 [==============================] - 0s 12ms/step - loss: 0.0165\n",
            "Epoch 97/200\n",
            "19/19 [==============================] - 0s 11ms/step - loss: 0.0227\n",
            "Epoch 98/200\n",
            "19/19 [==============================] - 0s 12ms/step - loss: 0.0242\n",
            "Epoch 99/200\n",
            "19/19 [==============================] - 0s 11ms/step - loss: 0.0233\n",
            "Epoch 100/200\n",
            "19/19 [==============================] - 0s 11ms/step - loss: 0.0244\n",
            "Epoch 101/200\n",
            "19/19 [==============================] - 0s 12ms/step - loss: 0.0192\n",
            "Epoch 102/200\n",
            "19/19 [==============================] - 0s 11ms/step - loss: 0.0212\n",
            "Epoch 103/200\n",
            "19/19 [==============================] - 0s 12ms/step - loss: 0.0207\n",
            "Epoch 104/200\n",
            "19/19 [==============================] - 0s 12ms/step - loss: 0.0200\n",
            "Epoch 105/200\n",
            "19/19 [==============================] - 0s 12ms/step - loss: 0.0182\n",
            "Epoch 106/200\n",
            "19/19 [==============================] - 0s 12ms/step - loss: 0.0148\n",
            "Epoch 107/200\n",
            "19/19 [==============================] - 0s 12ms/step - loss: 0.0226\n",
            "Epoch 108/200\n",
            "19/19 [==============================] - 0s 11ms/step - loss: 0.0180\n",
            "Epoch 109/200\n",
            "19/19 [==============================] - 0s 18ms/step - loss: 0.0173\n",
            "Epoch 110/200\n",
            "19/19 [==============================] - 0s 20ms/step - loss: 0.0188\n",
            "Epoch 111/200\n",
            "19/19 [==============================] - 0s 19ms/step - loss: 0.0234\n",
            "Epoch 112/200\n",
            "19/19 [==============================] - 0s 20ms/step - loss: 0.0236\n",
            "Epoch 113/200\n",
            "19/19 [==============================] - 0s 20ms/step - loss: 0.0166\n",
            "Epoch 114/200\n",
            "19/19 [==============================] - 0s 20ms/step - loss: 0.0159\n",
            "Epoch 115/200\n",
            "19/19 [==============================] - 0s 20ms/step - loss: 0.0165\n",
            "Epoch 116/200\n",
            "19/19 [==============================] - 0s 21ms/step - loss: 0.0169\n",
            "Epoch 117/200\n",
            "19/19 [==============================] - 0s 20ms/step - loss: 0.0162\n",
            "Epoch 118/200\n",
            "19/19 [==============================] - 0s 20ms/step - loss: 0.0146\n",
            "Epoch 119/200\n",
            "19/19 [==============================] - 0s 12ms/step - loss: 0.0174\n",
            "Epoch 120/200\n",
            "19/19 [==============================] - 0s 11ms/step - loss: 0.0196\n",
            "Epoch 121/200\n",
            "19/19 [==============================] - 0s 11ms/step - loss: 0.0187\n",
            "Epoch 122/200\n",
            "19/19 [==============================] - 0s 11ms/step - loss: 0.0202\n",
            "Epoch 123/200\n",
            "19/19 [==============================] - 0s 12ms/step - loss: 0.0188\n",
            "Epoch 124/200\n",
            "19/19 [==============================] - 0s 12ms/step - loss: 0.0189\n",
            "Epoch 125/200\n",
            "19/19 [==============================] - 0s 12ms/step - loss: 0.0147\n",
            "Epoch 126/200\n",
            "19/19 [==============================] - 0s 13ms/step - loss: 0.0159\n",
            "Epoch 127/200\n",
            "19/19 [==============================] - 0s 12ms/step - loss: 0.0191\n",
            "Epoch 128/200\n",
            "19/19 [==============================] - 0s 12ms/step - loss: 0.0144\n",
            "Epoch 129/200\n",
            "19/19 [==============================] - 0s 12ms/step - loss: 0.0198\n",
            "Epoch 130/200\n",
            "19/19 [==============================] - 0s 11ms/step - loss: 0.0170\n",
            "Epoch 131/200\n",
            "19/19 [==============================] - 0s 12ms/step - loss: 0.0157\n",
            "Epoch 132/200\n",
            "19/19 [==============================] - 0s 12ms/step - loss: 0.0181\n",
            "Epoch 133/200\n",
            "19/19 [==============================] - 0s 12ms/step - loss: 0.0166\n",
            "Epoch 134/200\n",
            "19/19 [==============================] - 0s 12ms/step - loss: 0.0188\n",
            "Epoch 135/200\n",
            "19/19 [==============================] - 0s 11ms/step - loss: 0.0165\n",
            "Epoch 136/200\n",
            "19/19 [==============================] - 0s 11ms/step - loss: 0.0135\n",
            "Epoch 137/200\n",
            "19/19 [==============================] - 0s 13ms/step - loss: 0.0202\n",
            "Epoch 138/200\n",
            "19/19 [==============================] - 0s 11ms/step - loss: 0.0209\n",
            "Epoch 139/200\n",
            "19/19 [==============================] - 0s 11ms/step - loss: 0.0184\n",
            "Epoch 140/200\n",
            "19/19 [==============================] - 0s 11ms/step - loss: 0.0156\n",
            "Epoch 141/200\n",
            "19/19 [==============================] - 0s 12ms/step - loss: 0.0163\n",
            "Epoch 142/200\n",
            "19/19 [==============================] - 0s 12ms/step - loss: 0.0202\n",
            "Epoch 143/200\n",
            "19/19 [==============================] - 0s 11ms/step - loss: 0.0140\n",
            "Epoch 144/200\n",
            "19/19 [==============================] - 0s 12ms/step - loss: 0.0158\n",
            "Epoch 145/200\n",
            "19/19 [==============================] - 0s 12ms/step - loss: 0.0150\n",
            "Epoch 146/200\n",
            "19/19 [==============================] - 0s 13ms/step - loss: 0.0216\n",
            "Epoch 147/200\n",
            "19/19 [==============================] - 0s 11ms/step - loss: 0.0183\n",
            "Epoch 148/200\n",
            "19/19 [==============================] - 0s 12ms/step - loss: 0.0175\n",
            "Epoch 149/200\n",
            "19/19 [==============================] - 0s 12ms/step - loss: 0.0133\n",
            "Epoch 150/200\n",
            "19/19 [==============================] - 0s 12ms/step - loss: 0.0145\n",
            "Epoch 151/200\n",
            "19/19 [==============================] - 0s 12ms/step - loss: 0.0125\n",
            "Epoch 152/200\n",
            "19/19 [==============================] - 0s 11ms/step - loss: 0.0139\n",
            "Epoch 153/200\n",
            "19/19 [==============================] - 0s 11ms/step - loss: 0.0168\n",
            "Epoch 154/200\n",
            "19/19 [==============================] - 0s 12ms/step - loss: 0.0141\n",
            "Epoch 155/200\n",
            "19/19 [==============================] - 0s 13ms/step - loss: 0.0187\n",
            "Epoch 156/200\n",
            "19/19 [==============================] - 0s 12ms/step - loss: 0.0141\n",
            "Epoch 157/200\n",
            "19/19 [==============================] - 0s 11ms/step - loss: 0.0173\n",
            "Epoch 158/200\n",
            "19/19 [==============================] - 0s 12ms/step - loss: 0.0175\n",
            "Epoch 159/200\n",
            "19/19 [==============================] - 0s 12ms/step - loss: 0.0158\n",
            "Epoch 160/200\n",
            "19/19 [==============================] - 0s 12ms/step - loss: 0.0156\n",
            "Epoch 161/200\n",
            "19/19 [==============================] - 0s 12ms/step - loss: 0.0160\n",
            "Epoch 162/200\n",
            "19/19 [==============================] - 0s 19ms/step - loss: 0.0175\n",
            "Epoch 163/200\n",
            "19/19 [==============================] - 0s 20ms/step - loss: 0.0141\n",
            "Epoch 164/200\n",
            "19/19 [==============================] - 0s 20ms/step - loss: 0.0193\n",
            "Epoch 165/200\n",
            "19/19 [==============================] - 0s 20ms/step - loss: 0.0153\n",
            "Epoch 166/200\n",
            "19/19 [==============================] - 0s 20ms/step - loss: 0.0172\n",
            "Epoch 167/200\n",
            "19/19 [==============================] - 0s 20ms/step - loss: 0.0147\n",
            "Epoch 168/200\n",
            "19/19 [==============================] - 0s 21ms/step - loss: 0.0155\n",
            "Epoch 169/200\n",
            "19/19 [==============================] - 0s 21ms/step - loss: 0.0136\n",
            "Epoch 170/200\n",
            "19/19 [==============================] - 0s 20ms/step - loss: 0.0113\n",
            "Epoch 171/200\n",
            "19/19 [==============================] - 0s 21ms/step - loss: 0.0177\n",
            "Epoch 172/200\n",
            "19/19 [==============================] - 0s 16ms/step - loss: 0.0140\n",
            "Epoch 173/200\n",
            "19/19 [==============================] - 0s 11ms/step - loss: 0.0170\n",
            "Epoch 174/200\n",
            "19/19 [==============================] - 0s 13ms/step - loss: 0.0174\n",
            "Epoch 175/200\n",
            "19/19 [==============================] - 0s 13ms/step - loss: 0.0197\n",
            "Epoch 176/200\n",
            "19/19 [==============================] - 0s 12ms/step - loss: 0.0158\n",
            "Epoch 177/200\n",
            "19/19 [==============================] - 0s 12ms/step - loss: 0.0159\n",
            "Epoch 178/200\n",
            "19/19 [==============================] - 0s 13ms/step - loss: 0.0151\n",
            "Epoch 179/200\n",
            "19/19 [==============================] - 0s 13ms/step - loss: 0.0158\n",
            "Epoch 180/200\n",
            "19/19 [==============================] - 0s 12ms/step - loss: 0.0204\n",
            "Epoch 181/200\n",
            "19/19 [==============================] - 0s 12ms/step - loss: 0.0131\n",
            "Epoch 182/200\n",
            "19/19 [==============================] - 0s 12ms/step - loss: 0.0171\n",
            "Epoch 183/200\n",
            "19/19 [==============================] - 0s 12ms/step - loss: 0.0155\n",
            "Epoch 184/200\n",
            "19/19 [==============================] - 0s 12ms/step - loss: 0.0133\n",
            "Epoch 185/200\n",
            "19/19 [==============================] - 0s 12ms/step - loss: 0.0150\n",
            "Epoch 186/200\n",
            "19/19 [==============================] - 0s 12ms/step - loss: 0.0161\n",
            "Epoch 187/200\n",
            "19/19 [==============================] - 0s 12ms/step - loss: 0.0177\n",
            "Epoch 188/200\n",
            "19/19 [==============================] - 0s 13ms/step - loss: 0.0128\n",
            "Epoch 189/200\n",
            "19/19 [==============================] - 0s 12ms/step - loss: 0.0164\n",
            "Epoch 190/200\n",
            "19/19 [==============================] - 0s 13ms/step - loss: 0.0105\n",
            "Epoch 191/200\n",
            "19/19 [==============================] - 0s 12ms/step - loss: 0.0137\n",
            "Epoch 192/200\n",
            "19/19 [==============================] - 0s 13ms/step - loss: 0.0169\n",
            "Epoch 193/200\n",
            "19/19 [==============================] - 0s 12ms/step - loss: 0.0146\n",
            "Epoch 194/200\n",
            "19/19 [==============================] - 0s 12ms/step - loss: 0.0157\n",
            "Epoch 195/200\n",
            "19/19 [==============================] - 0s 12ms/step - loss: 0.0137\n",
            "Epoch 196/200\n",
            "19/19 [==============================] - 0s 13ms/step - loss: 0.0141\n",
            "Epoch 197/200\n",
            "19/19 [==============================] - 0s 12ms/step - loss: 0.0152\n",
            "Epoch 198/200\n",
            "19/19 [==============================] - 0s 12ms/step - loss: 0.0148\n",
            "Epoch 199/200\n",
            "19/19 [==============================] - 0s 12ms/step - loss: 0.0132\n",
            "Epoch 200/200\n",
            "19/19 [==============================] - 0s 12ms/step - loss: 0.0117\n",
            "2/2 [==============================] - 0s 9ms/step\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from datetime import datetime\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import LSTM, Dense, Dropout\n",
        "\n",
        "# Read the dataset\n",
        "df = pd.read_excel('LNG (High).xlsx')\n",
        "\n",
        "# Function to calculate the number of months between two dates\n",
        "def months_between(start_date, end_date):\n",
        "    start_date = datetime.strptime(start_date, \"%Y-%m-%d\")\n",
        "    end_date = datetime.strptime(end_date, \"%Y-%m-%d\")\n",
        "    return (end_date.year - start_date.year) * 12 + end_date.month - start_date.month + 1\n",
        "\n",
        "# Define the date range\n",
        "start_date = '2024-04-01'\n",
        "end_date = '2028-12-01'\n",
        "\n",
        "# Calculate the number of months to predict\n",
        "num_months = months_between(start_date, end_date)\n",
        "\n",
        "# Ensure data is sorted by date\n",
        "df['Date'] = pd.to_datetime(df['Date'], format='%b-%y')\n",
        "df = df.sort_values(by=\"Date\", ascending=True)\n",
        "\n",
        "# Normalize the data\n",
        "scaler = MinMaxScaler(feature_range=(0, 1))\n",
        "df['Price_normalized'] = scaler.fit_transform(df['Price'].values.reshape(-1,1))\n",
        "\n",
        "# Create a new feature representing the number of months since start date\n",
        "df['Months_since_start'] = (df['Date'] - pd.to_datetime(start_date)).dt.days / 30\n",
        "\n",
        "# Prepare data for training\n",
        "X_train = df['Months_since_start'].values.reshape(-1, 1, 1)\n",
        "y_train = df['Price_normalized'].values\n",
        "\n",
        "# Define and train the LSTM model with increased dropout rate\n",
        "model = Sequential()\n",
        "model.add(LSTM(256, activation='relu', return_sequences=True, input_shape=(1, 1)))\n",
        "model.add(Dropout(0.5))  # Increase dropout rate\n",
        "model.add(LSTM(128, activation='relu', return_sequences=True))\n",
        "model.add(Dropout(0.5))  # Increase dropout rate\n",
        "model.add(LSTM(64, activation='relu'))\n",
        "model.add(Dropout(0.5))  # Increase dropout rate\n",
        "model.add(Dense(32, activation='relu'))\n",
        "model.add(Dense(1, activation='relu'))\n",
        "model.compile(optimizer='adam', loss='mean_squared_error')\n",
        "model.fit(X_train, y_train, epochs=200, batch_size=8)\n",
        "\n",
        "# Generate future indices for prediction\n",
        "X_future = np.arange(df['Months_since_start'].iloc[-1] + 1, df['Months_since_start'].iloc[-1] + 1 + num_months)\n",
        "X_future = X_future.reshape(-1, 1, 1)  # Reshape for LSTM input\n",
        "\n",
        "# Generate predictions\n",
        "y_pred_normalized = model.predict(X_future)\n",
        "\n",
        "# Inverse transform predictions to get actual prices\n",
        "y_pred = scaler.inverse_transform(y_pred_normalized)\n",
        "\n",
        "# Ensure predictions are non-negative\n",
        "y_pred = np.maximum(y_pred, 0)\n",
        "\n",
        "# Compute confidence interval bounds\n",
        "confidence_level = 0.80  # Set confidence level\n",
        "z_score = 1.96  # Adjusted z-score for desired confidence level\n",
        "std_dev = np.std(y_pred_normalized)  # Compute standard deviation\n",
        "margin_of_error = z_score * std_dev  # Margin of error\n",
        "lower_bound = y_pred - margin_of_error\n",
        "upper_bound = y_pred + margin_of_error\n",
        "\n",
        "# Generate date range for the predictions\n",
        "dates = pd.date_range(start=start_date, periods=num_months, freq='MS')\n",
        "\n",
        "# Create a DataFrame for the predictions\n",
        "predictions_df = pd.DataFrame({\n",
        "    'Date': dates,\n",
        "    'Forecasted Price': y_pred.flatten(),\n",
        "    'Lower Bound': lower_bound.flatten(),\n",
        "    'Upper Bound': upper_bound.flatten()\n",
        "})\n",
        "\n",
        "# Save the predictions to an Excel file\n",
        "predictions_df.to_excel('Predictions.xlsx', index=False)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UUgB5JRgOVey",
        "outputId": "037485c7-90e1-46cf-c1cc-3f98e2099bd3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/200\n",
            "19/19 [==============================] - 12s 18ms/step - loss: 0.0662\n",
            "Epoch 2/200\n",
            "19/19 [==============================] - 0s 20ms/step - loss: 0.0466\n",
            "Epoch 3/200\n",
            "19/19 [==============================] - 0s 25ms/step - loss: 0.0393\n",
            "Epoch 4/200\n",
            "19/19 [==============================] - 0s 21ms/step - loss: 0.0359\n",
            "Epoch 5/200\n",
            "19/19 [==============================] - 0s 20ms/step - loss: 0.0340\n",
            "Epoch 6/200\n",
            "19/19 [==============================] - 0s 22ms/step - loss: 0.0320\n",
            "Epoch 7/200\n",
            "19/19 [==============================] - 0s 19ms/step - loss: 0.0321\n",
            "Epoch 8/200\n",
            "19/19 [==============================] - 0s 21ms/step - loss: 0.0351\n",
            "Epoch 9/200\n",
            "19/19 [==============================] - 0s 23ms/step - loss: 0.0236\n",
            "Epoch 10/200\n",
            "19/19 [==============================] - 0s 19ms/step - loss: 0.0323\n",
            "Epoch 11/200\n",
            "19/19 [==============================] - 0s 22ms/step - loss: 0.0263\n",
            "Epoch 12/200\n",
            "19/19 [==============================] - 0s 17ms/step - loss: 0.0320\n",
            "Epoch 13/200\n",
            "19/19 [==============================] - 0s 21ms/step - loss: 0.0311\n",
            "Epoch 14/200\n",
            "19/19 [==============================] - 0s 23ms/step - loss: 0.0286\n",
            "Epoch 15/200\n",
            "19/19 [==============================] - 0s 22ms/step - loss: 0.0289\n",
            "Epoch 16/200\n",
            "19/19 [==============================] - 0s 22ms/step - loss: 0.0266\n",
            "Epoch 17/200\n",
            "19/19 [==============================] - 0s 17ms/step - loss: 0.0228\n",
            "Epoch 18/200\n",
            "19/19 [==============================] - 0s 20ms/step - loss: 0.0232\n",
            "Epoch 19/200\n",
            "19/19 [==============================] - 0s 22ms/step - loss: 0.0285\n",
            "Epoch 20/200\n",
            "19/19 [==============================] - 0s 23ms/step - loss: 0.0300\n",
            "Epoch 21/200\n",
            "19/19 [==============================] - 0s 23ms/step - loss: 0.0259\n",
            "Epoch 22/200\n",
            "19/19 [==============================] - 0s 22ms/step - loss: 0.0253\n",
            "Epoch 23/200\n",
            "19/19 [==============================] - 0s 17ms/step - loss: 0.0307\n",
            "Epoch 24/200\n",
            "19/19 [==============================] - 1s 30ms/step - loss: 0.0283\n",
            "Epoch 25/200\n",
            "19/19 [==============================] - 1s 33ms/step - loss: 0.0242\n",
            "Epoch 26/200\n",
            "19/19 [==============================] - 1s 31ms/step - loss: 0.0218\n",
            "Epoch 27/200\n",
            "19/19 [==============================] - 1s 40ms/step - loss: 0.0250\n",
            "Epoch 28/200\n",
            "19/19 [==============================] - 1s 38ms/step - loss: 0.0237\n",
            "Epoch 29/200\n",
            "19/19 [==============================] - 0s 25ms/step - loss: 0.0240\n",
            "Epoch 30/200\n",
            "19/19 [==============================] - 0s 26ms/step - loss: 0.0283\n",
            "Epoch 31/200\n",
            "19/19 [==============================] - 0s 25ms/step - loss: 0.0205\n",
            "Epoch 32/200\n",
            "19/19 [==============================] - 0s 18ms/step - loss: 0.0202\n",
            "Epoch 33/200\n",
            "19/19 [==============================] - 0s 23ms/step - loss: 0.0220\n",
            "Epoch 34/200\n",
            "19/19 [==============================] - 0s 22ms/step - loss: 0.0240\n",
            "Epoch 35/200\n",
            "19/19 [==============================] - 0s 19ms/step - loss: 0.0290\n",
            "Epoch 36/200\n",
            "19/19 [==============================] - 0s 22ms/step - loss: 0.0281\n",
            "Epoch 37/200\n",
            "19/19 [==============================] - 0s 20ms/step - loss: 0.0305\n",
            "Epoch 38/200\n",
            "19/19 [==============================] - 0s 20ms/step - loss: 0.0293\n",
            "Epoch 39/200\n",
            "19/19 [==============================] - 0s 21ms/step - loss: 0.0310\n",
            "Epoch 40/200\n",
            "19/19 [==============================] - 0s 21ms/step - loss: 0.0234\n",
            "Epoch 41/200\n",
            "19/19 [==============================] - 0s 22ms/step - loss: 0.0237\n",
            "Epoch 42/200\n",
            "19/19 [==============================] - 0s 22ms/step - loss: 0.0251\n",
            "Epoch 43/200\n",
            "19/19 [==============================] - 0s 22ms/step - loss: 0.0256\n",
            "Epoch 44/200\n",
            "19/19 [==============================] - 0s 21ms/step - loss: 0.0254\n",
            "Epoch 45/200\n",
            "19/19 [==============================] - 0s 22ms/step - loss: 0.0257\n",
            "Epoch 46/200\n",
            "19/19 [==============================] - 0s 22ms/step - loss: 0.0236\n",
            "Epoch 47/200\n",
            "19/19 [==============================] - 0s 21ms/step - loss: 0.0220\n",
            "Epoch 48/200\n",
            "19/19 [==============================] - 0s 23ms/step - loss: 0.0219\n",
            "Epoch 49/200\n",
            "19/19 [==============================] - 0s 22ms/step - loss: 0.0250\n",
            "Epoch 50/200\n",
            "19/19 [==============================] - 0s 20ms/step - loss: 0.0239\n",
            "Epoch 51/200\n",
            "19/19 [==============================] - 0s 18ms/step - loss: 0.0261\n",
            "Epoch 52/200\n",
            "19/19 [==============================] - 0s 21ms/step - loss: 0.0228\n",
            "Epoch 53/200\n",
            "19/19 [==============================] - 0s 22ms/step - loss: 0.0280\n",
            "Epoch 54/200\n",
            "19/19 [==============================] - 0s 21ms/step - loss: 0.0284\n",
            "Epoch 55/200\n",
            "19/19 [==============================] - 1s 28ms/step - loss: 0.0233\n",
            "Epoch 56/200\n",
            "19/19 [==============================] - 0s 21ms/step - loss: 0.0266\n",
            "Epoch 57/200\n",
            "19/19 [==============================] - 0s 21ms/step - loss: 0.0264\n",
            "Epoch 58/200\n",
            "19/19 [==============================] - 0s 24ms/step - loss: 0.0258\n",
            "Epoch 59/200\n",
            "19/19 [==============================] - 0s 21ms/step - loss: 0.0250\n",
            "Epoch 60/200\n",
            "19/19 [==============================] - 0s 21ms/step - loss: 0.0191\n",
            "Epoch 61/200\n",
            "19/19 [==============================] - 0s 20ms/step - loss: 0.0269\n",
            "Epoch 62/200\n",
            "19/19 [==============================] - 0s 21ms/step - loss: 0.0294\n",
            "Epoch 63/200\n",
            "19/19 [==============================] - 0s 21ms/step - loss: 0.0277\n",
            "Epoch 64/200\n",
            "19/19 [==============================] - 0s 20ms/step - loss: 0.0269\n",
            "Epoch 65/200\n",
            "19/19 [==============================] - 0s 20ms/step - loss: 0.0214\n",
            "Epoch 66/200\n",
            "19/19 [==============================] - 0s 12ms/step - loss: 0.0211\n",
            "Epoch 67/200\n",
            "19/19 [==============================] - 0s 12ms/step - loss: 0.0217\n",
            "Epoch 68/200\n",
            "19/19 [==============================] - 0s 12ms/step - loss: 0.0223\n",
            "Epoch 69/200\n",
            "19/19 [==============================] - 0s 12ms/step - loss: 0.0299\n",
            "Epoch 70/200\n",
            "19/19 [==============================] - 0s 12ms/step - loss: 0.0186\n",
            "Epoch 71/200\n",
            "19/19 [==============================] - 0s 11ms/step - loss: 0.0239\n",
            "Epoch 72/200\n",
            "19/19 [==============================] - 0s 11ms/step - loss: 0.0242\n",
            "Epoch 73/200\n",
            "19/19 [==============================] - 0s 11ms/step - loss: 0.0250\n",
            "Epoch 74/200\n",
            "19/19 [==============================] - 0s 11ms/step - loss: 0.0255\n",
            "Epoch 75/200\n",
            "19/19 [==============================] - 0s 13ms/step - loss: 0.0272\n",
            "Epoch 76/200\n",
            "19/19 [==============================] - 0s 11ms/step - loss: 0.0211\n",
            "Epoch 77/200\n",
            "19/19 [==============================] - 0s 11ms/step - loss: 0.0187\n",
            "Epoch 78/200\n",
            "19/19 [==============================] - 0s 11ms/step - loss: 0.0256\n",
            "Epoch 79/200\n",
            "19/19 [==============================] - 0s 13ms/step - loss: 0.0183\n",
            "Epoch 80/200\n",
            "19/19 [==============================] - 0s 12ms/step - loss: 0.0238\n",
            "Epoch 81/200\n",
            "19/19 [==============================] - 0s 11ms/step - loss: 0.0202\n",
            "Epoch 82/200\n",
            "19/19 [==============================] - 0s 12ms/step - loss: 0.0263\n",
            "Epoch 83/200\n",
            "19/19 [==============================] - 0s 11ms/step - loss: 0.0260\n",
            "Epoch 84/200\n",
            "19/19 [==============================] - 0s 13ms/step - loss: 0.0190\n",
            "Epoch 85/200\n",
            "19/19 [==============================] - 0s 12ms/step - loss: 0.0192\n",
            "Epoch 86/200\n",
            "19/19 [==============================] - 0s 12ms/step - loss: 0.0223\n",
            "Epoch 87/200\n",
            "19/19 [==============================] - 0s 11ms/step - loss: 0.0236\n",
            "Epoch 88/200\n",
            "19/19 [==============================] - 0s 12ms/step - loss: 0.0265\n",
            "Epoch 89/200\n",
            "19/19 [==============================] - 0s 11ms/step - loss: 0.0232\n",
            "Epoch 90/200\n",
            "19/19 [==============================] - 0s 11ms/step - loss: 0.0212\n",
            "Epoch 91/200\n",
            "19/19 [==============================] - 0s 11ms/step - loss: 0.0140\n",
            "Epoch 92/200\n",
            "19/19 [==============================] - 0s 11ms/step - loss: 0.0232\n",
            "Epoch 93/200\n",
            "19/19 [==============================] - 0s 12ms/step - loss: 0.0238\n",
            "Epoch 94/200\n",
            "19/19 [==============================] - 0s 12ms/step - loss: 0.0194\n",
            "Epoch 95/200\n",
            "19/19 [==============================] - 0s 11ms/step - loss: 0.0190\n",
            "Epoch 96/200\n",
            "19/19 [==============================] - 0s 12ms/step - loss: 0.0196\n",
            "Epoch 97/200\n",
            "19/19 [==============================] - 0s 12ms/step - loss: 0.0278\n",
            "Epoch 98/200\n",
            "19/19 [==============================] - 0s 11ms/step - loss: 0.0209\n",
            "Epoch 99/200\n",
            "19/19 [==============================] - 0s 12ms/step - loss: 0.0188\n",
            "Epoch 100/200\n",
            "19/19 [==============================] - 0s 12ms/step - loss: 0.0187\n",
            "Epoch 101/200\n",
            "19/19 [==============================] - 0s 12ms/step - loss: 0.0193\n",
            "Epoch 102/200\n",
            "19/19 [==============================] - 0s 12ms/step - loss: 0.0221\n",
            "Epoch 103/200\n",
            "19/19 [==============================] - 0s 13ms/step - loss: 0.0217\n",
            "Epoch 104/200\n",
            "19/19 [==============================] - 0s 11ms/step - loss: 0.0234\n",
            "Epoch 105/200\n",
            "19/19 [==============================] - 0s 12ms/step - loss: 0.0231\n",
            "Epoch 106/200\n",
            "19/19 [==============================] - 0s 12ms/step - loss: 0.0193\n",
            "Epoch 107/200\n",
            "19/19 [==============================] - 0s 12ms/step - loss: 0.0237\n",
            "Epoch 108/200\n",
            "19/19 [==============================] - 0s 12ms/step - loss: 0.0149\n",
            "Epoch 109/200\n",
            "19/19 [==============================] - 0s 19ms/step - loss: 0.0208\n",
            "Epoch 110/200\n",
            "19/19 [==============================] - 0s 23ms/step - loss: 0.0186\n",
            "Epoch 111/200\n",
            "19/19 [==============================] - 0s 20ms/step - loss: 0.0158\n",
            "Epoch 112/200\n",
            "19/19 [==============================] - 0s 20ms/step - loss: 0.0202\n",
            "Epoch 113/200\n",
            "19/19 [==============================] - 0s 20ms/step - loss: 0.0244\n",
            "Epoch 114/200\n",
            "19/19 [==============================] - 0s 20ms/step - loss: 0.0204\n",
            "Epoch 115/200\n",
            "19/19 [==============================] - 0s 21ms/step - loss: 0.0230\n",
            "Epoch 116/200\n",
            "19/19 [==============================] - 0s 21ms/step - loss: 0.0130\n",
            "Epoch 117/200\n",
            "19/19 [==============================] - 0s 20ms/step - loss: 0.0189\n",
            "Epoch 118/200\n",
            "19/19 [==============================] - 0s 22ms/step - loss: 0.0188\n",
            "Epoch 119/200\n",
            "19/19 [==============================] - 0s 15ms/step - loss: 0.0224\n",
            "Epoch 120/200\n",
            "19/19 [==============================] - 0s 11ms/step - loss: 0.0146\n",
            "Epoch 121/200\n",
            "19/19 [==============================] - 0s 12ms/step - loss: 0.0173\n",
            "Epoch 122/200\n",
            "19/19 [==============================] - 0s 11ms/step - loss: 0.0139\n",
            "Epoch 123/200\n",
            "19/19 [==============================] - 0s 11ms/step - loss: 0.0184\n",
            "Epoch 124/200\n",
            "19/19 [==============================] - 0s 11ms/step - loss: 0.0178\n",
            "Epoch 125/200\n",
            "19/19 [==============================] - 0s 12ms/step - loss: 0.0199\n",
            "Epoch 126/200\n",
            "19/19 [==============================] - 0s 12ms/step - loss: 0.0184\n",
            "Epoch 127/200\n",
            "19/19 [==============================] - 0s 11ms/step - loss: 0.0204\n",
            "Epoch 128/200\n",
            "19/19 [==============================] - 0s 11ms/step - loss: 0.0182\n",
            "Epoch 129/200\n",
            "19/19 [==============================] - 0s 12ms/step - loss: 0.0168\n",
            "Epoch 130/200\n",
            "19/19 [==============================] - 0s 12ms/step - loss: 0.0259\n",
            "Epoch 131/200\n",
            "19/19 [==============================] - 0s 12ms/step - loss: 0.0176\n",
            "Epoch 132/200\n",
            "19/19 [==============================] - 0s 11ms/step - loss: 0.0157\n",
            "Epoch 133/200\n",
            "19/19 [==============================] - 0s 12ms/step - loss: 0.0193\n",
            "Epoch 134/200\n",
            "19/19 [==============================] - 0s 12ms/step - loss: 0.0207\n",
            "Epoch 135/200\n",
            "19/19 [==============================] - 0s 12ms/step - loss: 0.0175\n",
            "Epoch 136/200\n",
            "19/19 [==============================] - 0s 12ms/step - loss: 0.0188\n",
            "Epoch 137/200\n",
            "19/19 [==============================] - 0s 11ms/step - loss: 0.0151\n",
            "Epoch 138/200\n",
            "19/19 [==============================] - 0s 12ms/step - loss: 0.0195\n",
            "Epoch 139/200\n",
            "19/19 [==============================] - 0s 12ms/step - loss: 0.0191\n",
            "Epoch 140/200\n",
            "19/19 [==============================] - 0s 12ms/step - loss: 0.0180\n",
            "Epoch 141/200\n",
            "19/19 [==============================] - 0s 11ms/step - loss: 0.0129\n",
            "Epoch 142/200\n",
            "19/19 [==============================] - 0s 12ms/step - loss: 0.0142\n",
            "Epoch 143/200\n",
            "19/19 [==============================] - 0s 12ms/step - loss: 0.0174\n",
            "Epoch 144/200\n",
            "19/19 [==============================] - 0s 13ms/step - loss: 0.0171\n",
            "Epoch 145/200\n",
            "19/19 [==============================] - 0s 11ms/step - loss: 0.0174\n",
            "Epoch 146/200\n",
            "19/19 [==============================] - 0s 12ms/step - loss: 0.0166\n",
            "Epoch 147/200\n",
            "19/19 [==============================] - 0s 12ms/step - loss: 0.0179\n",
            "Epoch 148/200\n",
            "19/19 [==============================] - 0s 12ms/step - loss: 0.0170\n",
            "Epoch 149/200\n",
            "19/19 [==============================] - 0s 12ms/step - loss: 0.0170\n",
            "Epoch 150/200\n",
            "19/19 [==============================] - 0s 11ms/step - loss: 0.0171\n",
            "Epoch 151/200\n",
            "19/19 [==============================] - 0s 12ms/step - loss: 0.0201\n",
            "Epoch 152/200\n",
            "19/19 [==============================] - 0s 12ms/step - loss: 0.0183\n",
            "Epoch 153/200\n",
            "19/19 [==============================] - 0s 14ms/step - loss: 0.0167\n",
            "Epoch 154/200\n",
            "19/19 [==============================] - 0s 13ms/step - loss: 0.0178\n",
            "Epoch 155/200\n",
            "19/19 [==============================] - 0s 12ms/step - loss: 0.0177\n",
            "Epoch 156/200\n",
            "19/19 [==============================] - 0s 12ms/step - loss: 0.0158\n",
            "Epoch 157/200\n",
            "19/19 [==============================] - 0s 13ms/step - loss: 0.0220\n",
            "Epoch 158/200\n",
            "19/19 [==============================] - 0s 13ms/step - loss: 0.0149\n",
            "Epoch 159/200\n",
            "19/19 [==============================] - 0s 12ms/step - loss: 0.0172\n",
            "Epoch 160/200\n",
            "19/19 [==============================] - 0s 12ms/step - loss: 0.0175\n",
            "Epoch 161/200\n",
            "19/19 [==============================] - 0s 13ms/step - loss: 0.0166\n",
            "Epoch 162/200\n",
            "19/19 [==============================] - 0s 20ms/step - loss: 0.0172\n",
            "Epoch 163/200\n",
            "19/19 [==============================] - 0s 21ms/step - loss: 0.0176\n",
            "Epoch 164/200\n",
            "19/19 [==============================] - 0s 20ms/step - loss: 0.0210\n",
            "Epoch 165/200\n",
            "19/19 [==============================] - 0s 20ms/step - loss: 0.0147\n",
            "Epoch 166/200\n",
            "19/19 [==============================] - 0s 21ms/step - loss: 0.0134\n",
            "Epoch 167/200\n",
            "19/19 [==============================] - 0s 20ms/step - loss: 0.0152\n",
            "Epoch 168/200\n",
            "19/19 [==============================] - 0s 21ms/step - loss: 0.0140\n",
            "Epoch 169/200\n",
            "19/19 [==============================] - 0s 21ms/step - loss: 0.0191\n",
            "Epoch 170/200\n",
            "19/19 [==============================] - 0s 20ms/step - loss: 0.0133\n",
            "Epoch 171/200\n",
            "19/19 [==============================] - 0s 20ms/step - loss: 0.0155\n",
            "Epoch 172/200\n",
            "19/19 [==============================] - 0s 20ms/step - loss: 0.0117\n",
            "Epoch 173/200\n",
            "19/19 [==============================] - 0s 12ms/step - loss: 0.0209\n",
            "Epoch 174/200\n",
            "19/19 [==============================] - 0s 12ms/step - loss: 0.0159\n",
            "Epoch 175/200\n",
            "19/19 [==============================] - 0s 12ms/step - loss: 0.0178\n",
            "Epoch 176/200\n",
            "19/19 [==============================] - 0s 14ms/step - loss: 0.0214\n",
            "Epoch 177/200\n",
            "19/19 [==============================] - 0s 13ms/step - loss: 0.0178\n",
            "Epoch 178/200\n",
            "19/19 [==============================] - 0s 12ms/step - loss: 0.0162\n",
            "Epoch 179/200\n",
            "19/19 [==============================] - 0s 12ms/step - loss: 0.0170\n",
            "Epoch 180/200\n",
            "19/19 [==============================] - 0s 12ms/step - loss: 0.0224\n",
            "Epoch 181/200\n",
            "19/19 [==============================] - 0s 13ms/step - loss: 0.0197\n",
            "Epoch 182/200\n",
            "19/19 [==============================] - 0s 12ms/step - loss: 0.0124\n",
            "Epoch 183/200\n",
            "19/19 [==============================] - 0s 12ms/step - loss: 0.0151\n",
            "Epoch 184/200\n",
            "19/19 [==============================] - 0s 12ms/step - loss: 0.0159\n",
            "Epoch 185/200\n",
            "19/19 [==============================] - 0s 13ms/step - loss: 0.0151\n",
            "Epoch 186/200\n",
            "19/19 [==============================] - 0s 12ms/step - loss: 0.0204\n",
            "Epoch 187/200\n",
            "19/19 [==============================] - 0s 12ms/step - loss: 0.0170\n",
            "Epoch 188/200\n",
            "19/19 [==============================] - 0s 12ms/step - loss: 0.0141\n",
            "Epoch 189/200\n",
            "19/19 [==============================] - 0s 13ms/step - loss: 0.0147\n",
            "Epoch 190/200\n",
            "19/19 [==============================] - 0s 12ms/step - loss: 0.0157\n",
            "Epoch 191/200\n",
            "19/19 [==============================] - 0s 12ms/step - loss: 0.0174\n",
            "Epoch 192/200\n",
            "19/19 [==============================] - 0s 12ms/step - loss: 0.0160\n",
            "Epoch 193/200\n",
            "19/19 [==============================] - 0s 12ms/step - loss: 0.0176\n",
            "Epoch 194/200\n",
            "19/19 [==============================] - 0s 12ms/step - loss: 0.0143\n",
            "Epoch 195/200\n",
            "19/19 [==============================] - 0s 11ms/step - loss: 0.0142\n",
            "Epoch 196/200\n",
            "19/19 [==============================] - 0s 12ms/step - loss: 0.0132\n",
            "Epoch 197/200\n",
            "19/19 [==============================] - 0s 12ms/step - loss: 0.0164\n",
            "Epoch 198/200\n",
            "19/19 [==============================] - 0s 13ms/step - loss: 0.0174\n",
            "Epoch 199/200\n",
            "19/19 [==============================] - 0s 12ms/step - loss: 0.0205\n",
            "Epoch 200/200\n",
            "19/19 [==============================] - 0s 12ms/step - loss: 0.0149\n",
            "2/2 [==============================] - 0s 9ms/step\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from datetime import datetime\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import LSTM, Dense, Dropout\n",
        "\n",
        "# Read the dataset\n",
        "df = pd.read_excel('LNG (High).xlsx')\n",
        "\n",
        "# Function to calculate the number of months between two dates\n",
        "def months_between(start_date, end_date):\n",
        "    start_date = datetime.strptime(start_date, \"%Y-%m-%d\")\n",
        "    end_date = datetime.strptime(end_date, \"%Y-%m-%d\")\n",
        "    return (end_date.year - start_date.year) * 12 + end_date.month - start_date.month + 1\n",
        "\n",
        "# Define the date range\n",
        "start_date = '2024-04-01'\n",
        "end_date = '2028-12-01'\n",
        "\n",
        "# Calculate the number of months to predict\n",
        "num_months = months_between(start_date, end_date)\n",
        "\n",
        "# Ensure data is sorted by date\n",
        "df['Date'] = pd.to_datetime(df['Date'], format='%b-%y')\n",
        "df = df.sort_values(by=\"Date\", ascending=True)\n",
        "\n",
        "# Normalize the data\n",
        "scaler = MinMaxScaler(feature_range=(0, 1))\n",
        "df['Price_normalized'] = scaler.fit_transform(df['Price'].values.reshape(-1,1))\n",
        "\n",
        "# Create a new feature representing the number of months since start date\n",
        "df['Months_since_start'] = (df['Date'] - pd.to_datetime(start_date)).dt.days / 30\n",
        "\n",
        "# Prepare data for training\n",
        "X_train = df['Months_since_start'].values.reshape(-1, 1, 1)\n",
        "y_train = df['Price_normalized'].values\n",
        "\n",
        "# Define and train the LSTM model with increased dropout rate\n",
        "model = Sequential()\n",
        "model.add(LSTM(256, activation='relu', return_sequences=True, input_shape=(1, 1)))\n",
        "model.add(Dropout(0.5))  # Increase dropout rate\n",
        "model.add(LSTM(128, activation='relu', return_sequences=True))\n",
        "model.add(Dropout(0.5))  # Increase dropout rate\n",
        "model.add(LSTM(64, activation='relu'))\n",
        "model.add(Dropout(0.5))  # Increase dropout rate\n",
        "model.add(Dense(32, activation='relu'))\n",
        "model.add(Dense(1, activation='relu'))\n",
        "model.compile(optimizer='adam', loss='mean_squared_error')\n",
        "model.fit(X_train, y_train, epochs=200, batch_size=8)\n",
        "\n",
        "# Generate future indices for prediction\n",
        "X_future = np.arange(df['Months_since_start'].iloc[-1] + 1, df['Months_since_start'].iloc[-1] + 1 + num_months)\n",
        "X_future = X_future.reshape(-1, 1, 1)  # Reshape for LSTM input\n",
        "\n",
        "# Generate predictions\n",
        "y_pred_normalized = model.predict(X_future)\n",
        "\n",
        "# Inverse transform predictions to get actual prices\n",
        "y_pred = scaler.inverse_transform(y_pred_normalized)\n",
        "\n",
        "# Ensure predictions are non-negative\n",
        "y_pred = np.maximum(y_pred, 0)\n",
        "\n",
        "# Compute confidence interval bounds\n",
        "confidence_level = 0.80  # Set confidence level\n",
        "z_score = 1.96  # Adjusted z-score for desired confidence level\n",
        "std_dev = np.std(y_pred_normalized)  # Compute standard deviation\n",
        "margin_of_error = z_score * std_dev  # Margin of error\n",
        "lower_bound = y_pred - margin_of_error\n",
        "upper_bound = y_pred + margin_of_error\n",
        "\n",
        "# Generate date range for the predictions\n",
        "dates = pd.date_range(start=start_date, periods=num_months, freq='MS')\n",
        "\n",
        "# Create a DataFrame for the predictions\n",
        "predictions_df = pd.DataFrame({\n",
        "    'Date': dates,\n",
        "    'Forecasted Price': y_pred.flatten(),\n",
        "    'Lower Bound': lower_bound.flatten(),\n",
        "    'Upper Bound': upper_bound.flatten()\n",
        "})\n",
        "\n",
        "# Specify the path to save the Excel file\n",
        "file_path = r'C:\\Users\\Admin\\Downloads\\Predictions.xlsx'\n",
        "\n",
        "# Save the predictions to an Excel file\n",
        "predictions_df.to_excel(file_path, index=False)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 578
        },
        "id": "IsPznIJ4PN8Q",
        "outputId": "9f4d7e5d-5e19-44bb-a8da-8da76ec04b99"
      },
      "outputs": [
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 1000x600 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Plotting the trends of the dataset and the forecasted values\n",
        "plt.figure(figsize=(10, 6))\n",
        "\n",
        "# Plot actual data\n",
        "plt.plot(df['Date'], df['Price'], label='Actual Price', color='blue')\n",
        "\n",
        "# Plot forecasted values\n",
        "plt.plot(predictions_df['Date'], predictions_df['Forecasted Price'], label='Forecasted Price', color='red')\n",
        "\n",
        "# Plot confidence intervals\n",
        "plt.fill_between(predictions_df['Date'], predictions_df['Lower Bound'], predictions_df['Upper Bound'], color='gray', alpha=0.3)\n",
        "\n",
        "plt.title('Actual vs Forecasted Prices')\n",
        "plt.xlabel('Date')\n",
        "plt.ylabel('Price')\n",
        "plt.legend()\n",
        "plt.grid(True)\n",
        "plt.xticks(rotation=45)\n",
        "plt.tight_layout()\n",
        "\n",
        "# Show plot\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 46,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 578
        },
        "id": "-e3i3quFSQrr",
        "outputId": "3eb6555f-619d-4a59-c385-5115166c3f55"
      },
      "outputs": [
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 1000x600 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Plotting the trends of the dataset and the forecasted values\n",
        "plt.figure(figsize=(10, 6))\n",
        "\n",
        "# Plot actual data\n",
        "plt.plot(df['Date'], df['Price'], label='Actual Price', color='blue')\n",
        "\n",
        "# Plot forecasted values\n",
        "plt.plot(predictions_df['Date'], predictions_df['Forecasted Price'], label='Forecasted Price', color='red')\n",
        "\n",
        "# Plot confidence intervals\n",
        "plt.fill_between(predictions_df['Date'], predictions_df['Lower Bound'], predictions_df['Upper Bound'], color='gray', alpha=0.3)\n",
        "\n",
        "plt.title('Actual vs Forecasted Prices')\n",
        "plt.xlabel('Date')\n",
        "plt.ylabel('Price')\n",
        "plt.legend()\n",
        "plt.grid(True)\n",
        "plt.xticks(rotation=45)\n",
        "plt.tight_layout()\n",
        "\n",
        "# Show plot\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 47,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 642
        },
        "id": "yeV3QYV5TLLk",
        "outputId": "ef9f6349-e683-4c2e-80e6-68441a6ece1b"
      },
      "outputs": [
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 1200x800 with 4 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "from statsmodels.tsa.seasonal import seasonal_decompose\n",
        "\n",
        "# Perform seasonal decomposition on the actual prices\n",
        "decomposition = seasonal_decompose(df['Price'], model='additive', period=12)  # Assuming a seasonal period of 12 months (1 year)\n",
        "\n",
        "# Plot the seasonal decomposition\n",
        "plt.figure(figsize=(12, 8))\n",
        "\n",
        "# Original time series\n",
        "plt.subplot(4, 1, 1)\n",
        "plt.plot(df['Date'], df['Price'], label='Original', color='blue')\n",
        "plt.title('Original Series')\n",
        "\n",
        "# Trend component\n",
        "plt.subplot(4, 1, 2)\n",
        "plt.plot(df['Date'], decomposition.trend, label='Trend', color='green')\n",
        "plt.title('Trend Component')\n",
        "\n",
        "# Seasonal component\n",
        "plt.subplot(4, 1, 3)\n",
        "plt.plot(df['Date'], decomposition.seasonal, label='Seasonal', color='red')\n",
        "plt.title('Seasonal Component')\n",
        "\n",
        "# Residual component\n",
        "plt.subplot(4, 1, 4)\n",
        "plt.plot(df['Date'], decomposition.resid, label='Residual', color='purple')\n",
        "plt.title('Residual Component')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pqiAa86RUY5i"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
